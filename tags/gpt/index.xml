<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>GPT on 奔跑的蜗牛</title>
        <link>https://ntopic.cn/tags/gpt/</link>
        <description>Recent content in GPT on 奔跑的蜗牛</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 15 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://ntopic.cn/tags/gpt/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>GPT-4o正式发布：视频语音推理交互丝滑到吓人，将向所有用户开放</title>
        <link>https://ntopic.cn/p/2024051501/</link>
        <pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024051501/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024051501/01.jpg" alt="Featured image of post GPT-4o正式发布：视频语音推理交互丝滑到吓人，将向所有用户开放" /&gt;&lt;p&gt;报道地址：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Xur3IUYf7PPOx1SCTuVPFg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/Xur3IUYf7PPOx1SCTuVPFg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布会视频：&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=DQacCB9tDaw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=DQacCB9tDaw&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GTP-4o 官网：&lt;a class=&#34;link&#34; href=&#34;https://openai.com/index/hello-gpt-4o/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://openai.com/index/hello-gpt-4o/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051501/01.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;2024 年 4 月 14 日，一场不到 30 分钟的发布会，将又一次大大改变 AI 行业和我们未来的生活，也会让无数 AI 初创公司焦头烂额。&lt;/p&gt;
&lt;p&gt;这真不是标题党，因为这是 OpenAI 的发布会。&lt;/p&gt;
&lt;p&gt;OpenAI 正式发布了 GPT-4o，其中的「o」代表「omni」（即全面、全能的意思），这个模型同时具备&lt;strong&gt;文本&lt;/strong&gt;、&lt;strong&gt;图片&lt;/strong&gt;、&lt;strong&gt;视频&lt;/strong&gt;和&lt;strong&gt;语音&lt;/strong&gt;方面的能力，甚至就是 GPT-5 的一个初期版本。&lt;/p&gt;
&lt;p&gt;更重要的是，这个 GPT-4 级别的模型，将向所有用户开放，并且未来几周内先向 ChatGPT Plus 推送。我们先给大家一次性总结这场发布会的亮点，更多功能解析请看发布会视频。&lt;/p&gt;
&lt;p&gt;发布会要点： 1.新的 GPT-4o 模型：打通任何文本、音频和图像的输入，相互之间可以直接生成，无需中间转换
2.GPT-4o 语音延迟大幅降低，能在 232 毫秒内回应音频输入，平均为 320 毫秒，这与对话中人类的响应时间相似
3.GPT-4o 向所有用户免费开放（指日可待）
4.GPT-4o API，比 GPT 4-Turbo 快 2 倍，价格便宜 50% 5.惊艳的实时语音助手演示：对话更像人、能实时翻译，识别表情，可以通过摄像头识别画面写代码分析图表
6.ChatGPT 新 UI，更简洁 7.一个新的 ChatGPT 桌面应用程序，适用于 macOS，Windows 版本今年晚些时候推出&lt;/p&gt;
&lt;p&gt;这些功能早在预热阶段就被 Altman 形容为「感觉像魔法」，既然全世界 AI 模型都在「赶超 GPT-4」，那 OpenAI 也要从武器库掏出点真家伙。&lt;/p&gt;
&lt;p&gt;当然，还轮不到 GPT-5 登场。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://ntopic.cn/p/2024051501/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ntopic.cn/p/2024051501&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
