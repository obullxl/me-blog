<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>大模型 on 奔跑的蜗牛</title>
        <link>https://ntopic.cn/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link>
        <description>Recent content in 大模型 on 奔跑的蜗牛</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 09 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://ntopic.cn/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>DeepSeek vs. Qwen 大模型编程能力比拼，谁更适合作为你的 AI 辅助编程助手？</title>
        <link>https://ntopic.cn/p/2025020901/</link>
        <pubDate>Sun, 09 Feb 2025 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2025020901/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2025020901/00.jpg" alt="Featured image of post DeepSeek vs. Qwen 大模型编程能力比拼，谁更适合作为你的 AI 辅助编程助手？" /&gt;&lt;p&gt;整个春节假期，DeepSeek 与《哪吒 2》的消息接连不断，看完我总有种莫名的激动。一边是 DeepSeek 在基础技术领域的深耕细作，另一边则是《哪吒 2》对用户产品的精心打磨，两者多年来的默默努力和不懈追求，终于在今年春节实现了一飞冲天、一鸣惊人的突破！&lt;/p&gt;
&lt;p&gt;老牛同学作为一名长期使用 Qwen 大模型Token服务的用户，目前余额所剩无几了，对购买的服务主要就三个追求：&lt;strong&gt;价格&lt;/strong&gt;、&lt;strong&gt;效率&lt;/strong&gt;、&lt;strong&gt;效果&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;接下来，老牛同学将根据自己使用大模型的实际情况，对&lt;strong&gt;DeepSeek&lt;/strong&gt;和&lt;strong&gt;Qwen&lt;/strong&gt;分别进行以下几个方面的测验，哪个得分高，老牛同学后续就用哪个的 Token 服务。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;价格：说实话，现在大模型厂商都很卷，价格都很实惠。同时，Token 数量与分词算法相关，因此价格只要不超过 50%，老牛同学觉得都差多不。&lt;/li&gt;
&lt;li&gt;效率：敢作为服务拿出来卖，老牛同学觉得效率都不会差；同时，模型产出内容不一样，这里就没有一个严格标准，因此暂不做比较。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;效果&lt;/strong&gt;，这是老牛同学最关心的点，只有满足需求的服务，才是需要的服务。&lt;strong&gt;编程&lt;/strong&gt;是老牛同学使用大模型服务最多的地方，因此将通过&lt;strong&gt;Web 页面&lt;/strong&gt;、&lt;strong&gt;Python&lt;/strong&gt;、&lt;strong&gt;微信小程序&lt;/strong&gt;和&lt;strong&gt;Cocos 小游戏&lt;/strong&gt;这 4 个方面编程结果进行评测。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;为了消除历史消息对上下文的影响，每次编程老牛同学都使用全新的会话。&lt;/li&gt;
&lt;li&gt;本次编程评测编程代码结果，老牛同学全部上传共享，大家可通过打开“&lt;strong&gt;老牛同学&lt;/strong&gt;”微信小程序-&amp;gt;点击“&lt;strong&gt;更多&lt;/strong&gt;”Tab-&amp;gt;“&lt;strong&gt;源代码&lt;/strong&gt;”获取下载链接进行复验：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/CX.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信小程序：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;qwen-和-deepseek-服务价格deepseek-更实惠&#34;&gt;Qwen 和 DeepSeek 服务价格（DeepSeek 更实惠）&lt;/h1&gt;
&lt;p&gt;老牛同学将以&lt;strong&gt;Qwen-Max-Latest&lt;/strong&gt;和&lt;strong&gt;DeepSeek-Chat&lt;/strong&gt;进行比较（Token 数量统一为&lt;strong&gt;百万&lt;/strong&gt;），以下是 2 个大模型官网公布的价格：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Qwen 价格：输入**¥2.4**，输出**¥9.6**&lt;/li&gt;
&lt;li&gt;DeepSeek 价格：输入缓存命中**¥0.5**，缓存未命中**¥2**，输出**¥8**&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2025020901/11.jpg&#34;
	width=&#34;1515&#34;
	height=&#34;444&#34;
	srcset=&#34;https://ntopic.cn/p/2025020901/11_huff2a968c98514115d4d9f452a168360f_60221_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2025020901/11_huff2a968c98514115d4d9f452a168360f_60221_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Qwen价格&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;341&#34;
		data-flex-basis=&#34;818px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2025020901/12.jpg&#34;
	width=&#34;1446&#34;
	height=&#34;456&#34;
	srcset=&#34;https://ntopic.cn/p/2025020901/12_hu9c2f94a349e6a4fca04046005ae8131a_55994_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2025020901/12_hu9c2f94a349e6a4fca04046005ae8131a_55994_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;DeepSeek价格&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;317&#34;
		data-flex-basis=&#34;761px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;虽然 Qwen 和 DeepSeek 采用的分词算法可能不一样，但是考虑到都是以&lt;strong&gt;百万&lt;/strong&gt;为单位，这些差异基本可以忽略。&lt;/p&gt;
&lt;p&gt;从上述官网价格来看：&lt;strong&gt;DeepSeek 更实惠&lt;/strong&gt;！&lt;/p&gt;
&lt;h1 id=&#34;qwen-和-deepseek-编程能力&#34;&gt;Qwen 和 DeepSeek 编程能力&lt;/h1&gt;
&lt;p&gt;接下来，我们开始进行编程评测，分别通过&lt;strong&gt;Web 页面&lt;/strong&gt;、&lt;strong&gt;Python&lt;/strong&gt;、&lt;strong&gt;微信小程序&lt;/strong&gt;和&lt;strong&gt;Cocos 小游戏&lt;/strong&gt;这 4 个方面编程进行评测。&lt;/p&gt;
&lt;h2 id=&#34;web-页面编程qwen-胜出&#34;&gt;Web 页面编程（Qwen 胜出）&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;计算器&lt;/strong&gt;是一个很好的 Web 程序样例，老牛同学就选择它作为考题，提示词如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;写一个**计算器**静态Web页面，计算器的风格参考Apple手机自带的计算器App。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;对于CSS样式，请尽量复用现有的CSS框架，比如BootStrap、Tailwind CSS等等。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2025020901/21.jpg&#34;
	width=&#34;2515&#34;
	height=&#34;1533&#34;
	srcset=&#34;https://ntopic.cn/p/2025020901/21_hu22433e8b365837e2e9acfcad8e77a004_334410_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2025020901/21_hu22433e8b365837e2e9acfcad8e77a004_334410_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;计算器编程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;164&#34;
		data-flex-basis=&#34;393px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;最终，老牛同学复制 2 个模型的输出 HTML 代码，通过浏览器打开：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2025020901/22.jpg&#34;
	width=&#34;1947&#34;
	height=&#34;1044&#34;
	srcset=&#34;https://ntopic.cn/p/2025020901/22_hue657b10ee68a78495654889aef0ad2de_106452_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2025020901/22_hue657b10ee68a78495654889aef0ad2de_106452_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Web编程结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;447px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;2 个模型的 Web 编程结果分析：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;风格：Qwen 更接近 Apple 手机自带的计算器。&lt;/li&gt;
&lt;li&gt;功能：对于基本的加、减、乘、除功能，Qwen 输入框只展示了计算结果，没有显示过程算式；而 DeepSeek 点击无反应，也没有结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结，老牛同学对 Web 页面编程评测结论：&lt;strong&gt;Qwen 胜出&lt;/strong&gt;！&lt;/p&gt;
&lt;h2 id=&#34;python-编程qwen-胜出&#34;&gt;Python 编程（Qwen 胜出）&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;贪吃蛇&lt;/strong&gt;是一款经典的单机游戏，也是很多一部分学习 Python 编程技术的第一个完整程序，我们就以它作为考题，提示词如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;使用Python，写一个带有GUI界面的**贪吃蛇**小游戏，要求：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1. 游戏开始，有“开始”操作界面，用户点击开始游戏
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2. 游戏过程中，在界面底部中间，展示当前分数
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;3. 游戏结束，有一个结束页面，页面展示游戏分数，并有“重新开始”操作界面
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2025020901/23.jpg&#34;
	width=&#34;2512&#34;
	height=&#34;1152&#34;
	srcset=&#34;https://ntopic.cn/p/2025020901/23_hu9312c8f69ceb477329a51b83f01c6c46_264351_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2025020901/23_hu9312c8f69ceb477329a51b83f01c6c46_264351_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;贪吃蛇编程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;218&#34;
		data-flex-basis=&#34;523px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;最终，老牛同学在本机分别运行这 2 个小游戏，界面如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2025020901/24.jpg&#34;
	width=&#34;1506&#34;
	height=&#34;694&#34;
	srcset=&#34;https://ntopic.cn/p/2025020901/24_hu5b7b15ae4d69d6baf970768e158dc115_51961_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2025020901/24_hu5b7b15ae4d69d6baf970768e158dc115_51961_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Python编程结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;217&#34;
		data-flex-basis=&#34;520px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对于最终编程结果，评测分析如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;功能：2 个大模型的结果，均能跑起来，有开始界面，正常展示。&lt;/li&gt;
&lt;li&gt;游戏：Qwen 蛇的速度比较适中，基本还能玩起来。而 DeepSeek 蛇速度则很快，老牛同学手速没有那么快，基本玩不起来。&lt;/li&gt;
&lt;li&gt;结果：Qwen 能正常展示中文，而 DeepSeek 展示就是乱码了（缺少&lt;code&gt;ttf&lt;/code&gt;字体文件）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结，Python 编程评测结果：&lt;strong&gt;Qwen 胜出&lt;/strong&gt;！&lt;/p&gt;
&lt;h2 id=&#34;微信小程序编程势均力敌&#34;&gt;微信小程序编程（势均力敌）&lt;/h2&gt;
&lt;p&gt;接下来，我们进行微信小程序编程评测，老牛同学感觉比上面 2 个编程要稍微难一点：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;写一个微信小程序页面，页面样式参考**微信**手机App中“我”Tab的样式。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;对于页面样式，请尽量复用现有成熟的框架，比如weui等。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2025020901/25.jpg&#34;
	width=&#34;2520&#34;
	height=&#34;1473&#34;
	srcset=&#34;https://ntopic.cn/p/2025020901/25_hu9edad9e84aa6f83b43c441e07c46e144_323929_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2025020901/25_hu9edad9e84aa6f83b43c441e07c46e144_323929_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;小程序代码&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;410px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对于&lt;strong&gt;weui&lt;/strong&gt;框架的&lt;code&gt;app.wxss&lt;/code&gt;文件：Qwen 给的地址文件不存在，而 DeepSeek 给的是一个样例地址。老牛同学修复这个问题之后，最终小程序页面样式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2025020901/26.jpg&#34;
	width=&#34;1278&#34;
	height=&#34;1011&#34;
	srcset=&#34;https://ntopic.cn/p/2025020901/26_hu0ad3ba640c3aee1c0a609406fa1cb591_102800_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2025020901/26_hu0ad3ba640c3aee1c0a609406fa1cb591_102800_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;小程序页面&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;303px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;从最终小程序页面效果来看：&lt;strong&gt;Qwen&lt;/strong&gt;和&lt;strong&gt;DeepSeek&lt;/strong&gt;表现基本一致！&lt;/p&gt;
&lt;p&gt;但有个&lt;strong&gt;问题&lt;/strong&gt;：Qwen 和 DeepSeek 都是直接引用&lt;strong&gt;weui&lt;/strong&gt;框架样式，这样势必会增加小程序包大小&lt;strong&gt;170KB&lt;/strong&gt;左右。而&lt;strong&gt;weui&lt;/strong&gt;最佳使用方式是作为扩展组件库的方式引入，这样就不会增加包大小了。&lt;/p&gt;
&lt;h2 id=&#34;cocos-小游戏编程qwen-略胜&#34;&gt;Cocos 小游戏编程（Qwen 略胜）&lt;/h2&gt;
&lt;p&gt;最后，来一个 Cocos 小游戏编程。今年春节，老牛同学从 0 基础开始学习，使用 Cocos Creator 做了一款微信小游戏。过程中遇到了不少问题，我把其中一个问题拿出来作为考题：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;我正在使用Cocos Creator 3.8.5研发一款微信小游戏，在一个`ts`组件类中，我需要一个名为`prefabMap`、类型是`{[key: string]:Prefab}`映射的属性，如下TypeScript代码：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;@ccclass(&amp;#39;WallView&amp;#39;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;export class WallView extends Component {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    // 预制体映射
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    private prefabMap: { [key: string]: Prefab } = {};
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;我希望可以通过“属性管理器”来设置**prefabMap**这个属性，包括映射`string`类型的Key和映射`Prefab`类型的Value，请帮忙实现这个代码。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2025020901/27.jpg&#34;
	width=&#34;2490&#34;
	height=&#34;1387&#34;
	srcset=&#34;https://ntopic.cn/p/2025020901/27_hu230c4bdbae45f4e4cc6ad90de7a9346d_287255_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2025020901/27_hu230c4bdbae45f4e4cc6ad90de7a9346d_287255_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Cocos小游戏代码&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;430px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;从上面代码来看，&lt;strong&gt;Qwen&lt;/strong&gt;和&lt;strong&gt;DeepSeek&lt;/strong&gt;大模型思路基本一致：先定义一个 KeyValue 类/接口，通过“属性管理器”设置这个 KeyValue 列表，然后再组件启动&lt;code&gt;start&lt;/code&gt;之后把 KeyValue 列表转化为映射对象。&lt;/p&gt;
&lt;p&gt;它们两者的编程思路没有问题，可是编写的代码却是不生效的，均存在问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Qwen&lt;/strong&gt;的问题：代码已经非常接近目标，一步之遥，可 Cocos 无法识别&lt;code&gt;KeyValuePair&lt;/code&gt;这个类。有两种办法可以解决：&lt;code&gt;KeyValuePair&lt;/code&gt;类增加注解&lt;code&gt;@ccclass(&#39;KeyValuePair&#39;)&lt;/code&gt;，或者增加一行代码&lt;code&gt;@ccclass(&#39;KeyValuePair&#39;)(KeyValuePair)&lt;/code&gt;均可。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;的问题：相比 Qwen 来说，问题就多一些了，离目标也就更远一些：&lt;code&gt;PrefabKeyValue&lt;/code&gt;是一个接口，Cocos 根本无法识别，同时内部的&lt;code&gt;key&lt;/code&gt;和&lt;code&gt;value&lt;/code&gt;没有&lt;code&gt;@property&lt;/code&gt;注解，在“属性管理器”中也无法做到嵌套配置，&lt;code&gt;prefabList&lt;/code&gt;也就无法达成目标了。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从上面分析来看，Qwen 更接近目标，因此 &lt;strong&gt;Qwen 略胜一筹&lt;/strong&gt;！&lt;/p&gt;
&lt;h1 id=&#34;最后简单总结&#34;&gt;最后，简单总结&lt;/h1&gt;
&lt;p&gt;综合上面分析和评测，我们可以看出：&lt;strong&gt;DeepSeek&lt;/strong&gt;在价格上更优惠，而&lt;strong&gt;Qwen&lt;/strong&gt;在编程效果上更胜一筹！&lt;/p&gt;
&lt;p&gt;看到这儿，我相信大家和老牛同学一样，开始犯嘀咕：当前火爆全球、如日中天、大红大紫的&lt;strong&gt;DeepSeek&lt;/strong&gt;大模型，竟然在编程效果上不及&lt;strong&gt;Qwen&lt;/strong&gt;大模型？&lt;/p&gt;
&lt;p&gt;从结果看，是的。也许是&lt;strong&gt;DeepSeek&lt;/strong&gt;火爆点并不在编程效果上，也行是的提示词待优化，也许是所举样例不具备代表性，也许是需要我们再给 DeepSeek 一些时日……&lt;/p&gt;
&lt;p&gt;但无论如何，老牛同学目前已经明确，接下来续费大模型 Token 调用费用，该往哪个平台了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;提示：&lt;/strong&gt; 以上 2 个大模型辅助编程的源码，老牛同学已经上传（除微信小程序中，除修正了&lt;code&gt;app.wxss&lt;/code&gt;样式文件的路径之外，老牛同学承诺对大模型编程结果未做任何一个字符的修改），大家可以下载复验（打开“&lt;strong&gt;老牛同学&lt;/strong&gt;”微信小程序-&amp;gt;点击“&lt;strong&gt;更多&lt;/strong&gt;”Tab-&amp;gt;“&lt;strong&gt;源代码&lt;/strong&gt;”获取下载链接）。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cocos 3D 小游戏：&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/TlgNKvGYMuGMmU0dIBPn4A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;01.技术选型&lt;/a&gt; 丨 &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/qlOYpjREXBKb7vl1kuujlg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;02.研发流程&lt;/a&gt; 丨 &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/V3CIhswW3CVcTY1aPaALTw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;03.小游戏框架&lt;/a&gt;丨 &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/8f3GZNd7qjwIhfTcsVruYQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;04.核心架构设计&lt;/a&gt;丨 &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/8jxPxJ2-9UnFsLMGh9h0fQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;05.分包构建发布&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;Transformers 框架序列：&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/lAAIfl0YJRNrppp5-Vuusw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;01.包和对象加载中的设计巧思与实用技巧&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/WIbbrkf1HjVC1CtBNcU8Ow&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;02.AutoModel 初始化及 Qwen2.5 模型加载全流程&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Shg30uUFByM0tKTi0rETfg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;03.Qwen2.5 大模型的 AutoTokenizer 技术细节&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/GnoHXsIYKYFU1Xo4u5sE1w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;04.Qwen2.5/GPT 分词流程与 BPE 分词算法技术细节详解&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/qL9vpmNIM1eO9_lQq7QwlA&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;05.嵌入（Embedding）机制和 Word2Vec 实战&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/B0__TRnlI7zgwn0OhguvXA&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;06.位置嵌入（Positional Embedding）&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;Pipeline NLP 任务序列：&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/FR4384AZV2FE2xtweSh9bA&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;零·概述&lt;/a&gt; 丨 &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/uN2BFIOxDFEh4T-W7tsPbg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;01.文本转音频&lt;/a&gt; 丨 &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/9ccEDNfeGNf_Q9pO0Usg2w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;02.文本分类&lt;/a&gt; 丨 &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/r2uFCwPZaMeDL_eiQsEmIQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;03.词元分类和命名实体识别&lt;/a&gt; 丨 &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/vOLVxRircw5wM1_rCqoAfg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;04.问答&lt;/a&gt; 丨 &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Q0fWdw3ACVzQFldBScZ2Fw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;05.表格问答&lt;/a&gt; | &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hMFCgYovHPVFOjOoihaUHw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;06.填充蒙版&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;往期推荐文章：&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/F-CUuaZwmqt6X7QkI_IrVA&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Cline 免费插件 + Qwen2.5 大模型，零经验也能开发“对联王”微信小程序&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/vraegr_5AJG7bPo6mBgvbQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用 Cursor + Qwen2.5 大模型 零经验研发微信小程序：自由构建个性化节拍器应用实战&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Mq8CvZKdpokbj3mK-h_SAQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bolt.new 用一句话快速构建全栈应用：本地部署与应用实战（Ollama/Qwen2.5 等）&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/8f3xna9TRmxMDaY_cQhy8Q&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Qwen2.5-Coder 模型和 CrewAI 多智能体框架，实现智能编程系统的实战教程&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/KM-Z6FtVfaySewRTmvEc6w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;vLLM CPU 和 GPU 模式署和推理 Qwen2 等大语言模型详细教程&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/PpY3k3kReKfQdeOJyrB6aw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Qwen2/Lllama3 等大模型，部署团队私有化 RAG 知识库系统的详细教程（Docker+AnythingLLM）&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/vt1EXVWtwm6ltZVYtB4-Tg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用 Llama3/Qwen2 等开源大模型，部署团队私有化 Code Copilot 和使用教程&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/eq6K8_s9uX459OeUcRPEug&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Qwen2 大模型微调技术详细教程（LoRA 参数高效微调和 SwanLab 可视化监控）&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/9ldLuh3YLvx8oWvwnrSGUA&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 长音频合成和本地部署 2 种方式，让你的“儿童绘本”发声的实战教程&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>太卷了，阿里云免费1个月大模型算力额度，玩转Llama3.1/Qwen2等训练推理</title>
        <link>https://ntopic.cn/p/2024072601/</link>
        <pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024072601/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024072601/00.png" alt="Featured image of post 太卷了，阿里云免费1个月大模型算力额度，玩转Llama3.1/Qwen2等训练推理" /&gt;&lt;p&gt;早上收到朋友转发的阿里云公众号推文，阿里云为用户免费提供 1 个月的训练推理等算力额度（&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/BoWoRPsI3sOM3To0BHSQHw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;上阿里云，免费玩转 Llama 405B 「超大杯」！&lt;/a&gt;）。想想上周老牛同学为了制作微调技术教程，演示训练&lt;strong&gt;Qwen2-0.5B&lt;/strong&gt;小尺寸大模型就跑了一个晚上（&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/eq6K8_s9uX459OeUcRPEug&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Qwen2 大模型微调技术详细教程（LoRA 参数高效微调和 SwanLab 可视化监控）&lt;/a&gt;），如今阿里云竟然免费提供 1 个月训练推理算力，而且还支持&lt;strong&gt;Llama3.1-405B&lt;/strong&gt;超大尺寸模型，标题和内容确实把老牛同学给够吸住了。&lt;/p&gt;
&lt;p&gt;虽然老牛同学非常相信阿里云在中国市场的地位，但还是有那么一点点担心是标题党，因此老牛同学决定验证一下，走一遍完整开通和使用流程，最后给出自己的感受给大家做个参考。&lt;/p&gt;
&lt;h1 id=&#34;开通阿里云百炼服务&#34;&gt;开通阿里云百炼服务&lt;/h1&gt;
&lt;p&gt;推文写得很清楚，免费额度是为阿里云百炼平台用户提供的，因此先开通注册：&lt;a class=&#34;link&#34; href=&#34;https://www.aliyun.com/product/bailian&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.aliyun.com/product/bailian&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;说实话，取名真的很重要，不仅要好听好记还要切实际功能。比如&lt;strong&gt;千问&lt;/strong&gt;：作为你的人工智能助理，随你问，我都能答；&lt;strong&gt;百炼&lt;/strong&gt;：千锤百炼，大模型训练微调，就是不断打磨和调整优化过程。&lt;/p&gt;
&lt;p&gt;阿里云百炼：是基于通义大模型、行业大模型以及三方大模型的一站式大模型开发平台。面向企业客户和个人开发者，提供完整的模型服务工具和全链路应用开发套件，预置丰富的能力插件，提供 API 及 SDK 等便捷的集成方式，高效完成大模型应用构建。&lt;/p&gt;
&lt;p&gt;产品定价：阿里云百炼大模型服务平台在调用 API 后将产生计量和计费。各个领域的模型采用不同的计量单元，不同模型单独制定各自的计费单价和免费额度等规则。（&lt;strong&gt;特别注意&lt;/strong&gt;：不同模型是单独计价和单价免费额度规则，算力额度有可能针对不同模型不一样！）&lt;/p&gt;
&lt;p&gt;点击“&lt;strong&gt;立即开通&lt;/strong&gt;”橙色大按钮，按照提示，一步一步完成注册即可：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024072601/01.png&#34;
	width=&#34;1300&#34;
	height=&#34;379&#34;
	srcset=&#34;https://ntopic.cn/p/2024072601/01_huc6bb699390736bd8e19955e453dac925_103356_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024072601/01_huc6bb699390736bd8e19955e453dac925_103356_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;开通阿里云百炼平台服务&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;343&#34;
		data-flex-basis=&#34;823px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们可以直接通过支付宝、淘宝等方式登录（老牛同学使用支付宝扫描登录）。登录成功，需要同意“&lt;strong&gt;阿里云百炼服务协议&lt;/strong&gt;”，我们主要是用于学习和研究，肯定不会干那些超纲的事情，无脑点击“&lt;strong&gt;同意&lt;/strong&gt;”按钮就行了。&lt;/p&gt;
&lt;p&gt;然后，我们就进入了百炼平台控制台首页：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024072601/02.png&#34;
	width=&#34;1462&#34;
	height=&#34;1027&#34;
	srcset=&#34;https://ntopic.cn/p/2024072601/02_hu18b3b15db9b0d842d13eac9defb5bddc_118349_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024072601/02_hu18b3b15db9b0d842d13eac9defb5bddc_118349_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;百炼平台控制台首页&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;341px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;看到“&lt;strong&gt;免费额度：100/100 次&lt;/strong&gt;”小字样，老牛同学之前的担心加重了一点，回头想想还是继续往下看看，毕竟是阿里云，应该是不能随便开玩笑的。&lt;/p&gt;
&lt;p&gt;点击“&lt;strong&gt;去开通 →&lt;/strong&gt;”按钮，又来个弹框确认开通。不过支持的模型倒是挺多的，支持 139 个推理（包括 Llama3.1-405B 大模型）、17 个部署和 14 个训练，应该来说我们对学习和研究类需求足够了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024072601/03.png&#34;
	width=&#34;1120&#34;
	height=&#34;798&#34;
	srcset=&#34;https://ntopic.cn/p/2024072601/03_hubae089f470d53c74a947b98d417b7452_55467_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024072601/03_hubae089f470d53c74a947b98d417b7452_55467_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;确认开通百炼大模型服务&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;140&#34;
		data-flex-basis=&#34;336px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;勾选“我已阅读并同意《模型管理服务协议》”，然后点击“&lt;strong&gt;确认开通&lt;/strong&gt;”按钮，整个开通流程就结束了！&lt;/p&gt;
&lt;h1 id=&#34;使用-api-调用推理服务&#34;&gt;使用 API 调用推理服务&lt;/h1&gt;
&lt;p&gt;首先体验一下大模型的&lt;strong&gt;推理&lt;/strong&gt;服务，选择“&lt;strong&gt;模型广场&lt;/strong&gt;”，选择任意一个模型（如：&lt;strong&gt;通义千问-Max&lt;/strong&gt;），点击“API 调用示例”：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024072601/04.png&#34;
	width=&#34;1597&#34;
	height=&#34;898&#34;
	srcset=&#34;https://ntopic.cn/p/2024072601/04_hu2e11266e317acd31591282f24347f4be_50519_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024072601/04_hu2e11266e317acd31591282f24347f4be_50519_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;选择模型进行API推理&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看到，API 调用示例提供了&lt;strong&gt;Python&lt;/strong&gt;、&lt;strong&gt;Java&lt;/strong&gt;和&lt;strong&gt;Curl&lt;/strong&gt;共 3 种方式，对于我们来说也应该足够了（老牛同学就不演示了）。&lt;/p&gt;
&lt;p&gt;最关键的是，点击“&lt;strong&gt;模型详情&lt;/strong&gt;”，可以看到计费方式和&lt;strong&gt;免费额度&lt;/strong&gt;信息：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024072601/05.png&#34;
	width=&#34;1008&#34;
	height=&#34;1108&#34;
	srcset=&#34;https://ntopic.cn/p/2024072601/05_hu1d4ce3f52f733baffdeac217e63fd0bb_61282_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024072601/05_hu1d4ce3f52f733baffdeac217e63fd0bb_61282_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;模型详情-免费额度&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;90&#34;
		data-flex-basis=&#34;218px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看到，免费额度信息如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;免费的 Token 数量有限制（如：通义千问-Max 是 100 万个）&lt;/li&gt;
&lt;li&gt;之前推文中提到的，免费 1 个月，是指这些免费额度仅 1 个月&lt;strong&gt;有效期&lt;/strong&gt;，不是老牛同学想象的免费使用 1 个月！&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;到这里，老牛同学感觉有一点点失望了，但是老牛同学对推理要求不多，在看看模型训练如何免费的。&lt;/p&gt;
&lt;h1 id=&#34;使用百炼平台进行模型训练&#34;&gt;使用百炼平台进行模型训练&lt;/h1&gt;
&lt;p&gt;选择“&lt;strong&gt;模型工具&lt;/strong&gt;”-“&lt;strong&gt;模型调优&lt;/strong&gt;”，然后点击“&lt;strong&gt;训练新模型&lt;/strong&gt;”按钮，然后在弹框选择“&lt;strong&gt;高效训练&lt;/strong&gt;”（就是老牛同学上周文章中的微调）&lt;/p&gt;
&lt;p&gt;点击“&lt;strong&gt;下一步&lt;/strong&gt;”，选择“&lt;strong&gt;预置模型&lt;/strong&gt;”，在下拉框中选择“&lt;strong&gt;通义千问-开源版-7B&lt;/strong&gt;”模型（模型没有强制要求）&lt;/p&gt;
&lt;p&gt;点击“&lt;strong&gt;下一步&lt;/strong&gt;”，需要选择训练数据集，因之前没有训练过，还没有数据集，因此我们点击“&lt;strong&gt;管理训练集&lt;/strong&gt;”增加数据集&lt;/p&gt;
&lt;p&gt;数据集是&lt;code&gt;jsonl&lt;/code&gt;文件，单个 JSON 的格式需要符合 ChatML 格式，样例如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;messages&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;You are a helpful assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;谁在文艺复兴时期绘制人体?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;文艺复兴时期是一个关于艺术、文化和学术的复兴运动，在这个时期，许多艺术家都绘制了人体。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}]}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;因此，老牛同学上周微调用的文本分类的原始数据集需要格式化处理一下（评论区有最终文件链接），Python 代码如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;json&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 训练数据集文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;BAS_DATA_DIR&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;D:\ModelSpace\Qwen2&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;RAW_TRAIN_FILE_PATH&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BAS_DATA_DIR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;zh_cls_fudan-news&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;train.jsonl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;NEW_TRAIN_FILE_PATH&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BAS_DATA_DIR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;train-ChatML.jsonl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 将原始数据集转换为ChatML格式的新数据集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;message_list&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 读取原JSONL文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RAW_TRAIN_FILE_PATH&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;line&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 解析每一行原始数据（每一行均是一个JSON格式）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;catagory&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;category&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;output&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;message_part_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;You are a helpful assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;message_part_2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;你是一个文本分类领域的专家，你会接收到一段文本和几个潜在的分类选项列表，请输出文本内容的正确分类。&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;分类选项列表:&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;catagory&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;message_part_3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;s2&#34;&gt;&amp;#34;messages&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message_part_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message_part_2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message_part_3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;message_list&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 保存处理后的JSONL文件，每行也是一个JSON格式&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;NEW_TRAIN_FILE_PATH&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;w&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message_list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dumps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ensure_ascii&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果大家不想对原始的文件进行处理了，可以到评论区直接下载老牛同学已经处理好的数据集文件。&lt;/p&gt;
&lt;p&gt;在新打开页面，点击“&lt;strong&gt;新增数据集&lt;/strong&gt;”，勾选“&lt;strong&gt;训练集&lt;/strong&gt;”（文件最大支持 20MB），然后处理好的文件上次即可（裁剪一下，留下 1000 行）。&lt;/p&gt;
&lt;p&gt;导入成功之后，可以查看数据样例，还可以单行进行处理：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024072601/06.png&#34;
	width=&#34;2361&#34;
	height=&#34;1285&#34;
	srcset=&#34;https://ntopic.cn/p/2024072601/06_hu85a5f218203189b1bb0778334ee76941_88500_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024072601/06_hu85a5f218203189b1bb0778334ee76941_88500_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;训练数据集样例&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;440px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;确认无误之后，点击“&lt;strong&gt;发布&lt;/strong&gt;”数据集，后面就可以使用了。&lt;/p&gt;
&lt;p&gt;然后我们继续回到刚才模型训练页面，选择我们创建的数据集，操作菜单：模型工具-模型调优，选择刚才发布的训练数据集：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024072601/07.png&#34;
	width=&#34;1020&#34;
	height=&#34;649&#34;
	srcset=&#34;https://ntopic.cn/p/2024072601/07_hub02b734523a4aad593b758066b5127ea_18007_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024072601/07_hub02b734523a4aad593b758066b5127ea_18007_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;选择训练数据集&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;157&#34;
		data-flex-basis=&#34;377px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;点击“&lt;strong&gt;下一步&lt;/strong&gt;”，验证数据，选择“&lt;strong&gt;自动切分&lt;/strong&gt;”，我们就不单独创建数据集了。&lt;/p&gt;
&lt;p&gt;在“&lt;strong&gt;混合训练&lt;/strong&gt;”选择中，针对&lt;strong&gt;中文-对话&lt;/strong&gt;和&lt;strong&gt;中文-通用&lt;/strong&gt;均选择&lt;code&gt;0.5&lt;/code&gt;倍（因为我们训练集都是中文，就简单点点设置了）&lt;/p&gt;
&lt;p&gt;最后，可以看到本次模型训练的详情和预估费用：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024072601/08.png&#34;
	width=&#34;1011&#34;
	height=&#34;1413&#34;
	srcset=&#34;https://ntopic.cn/p/2024072601/08_hu94f63677e967d8e51eb83f874919e180_59517_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024072601/08_hu94f63677e967d8e51eb83f874919e180_59517_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;高效参数训练费用预估&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;71&#34;
		data-flex-basis=&#34;171px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;点击“&lt;strong&gt;开始训练&lt;/strong&gt;”就是开始训练了，预估费用不足&lt;strong&gt;50 元&lt;/strong&gt;还算不错，比老牛同学自己电脑训练所用的电费感觉贵不了多少！&lt;/p&gt;
&lt;h1 id=&#34;最后想谈点大模型产品的感想&#34;&gt;最后：想谈点大模型产品的感想&lt;/h1&gt;
&lt;p&gt;最近和朋友聊天，聊到最近很火爆的大模型，目前市面上有那么多感觉非常惊艳的开源大模型，利用这些开源大模型来创业岂不美哉？！&lt;/p&gt;
&lt;p&gt;朋友对自己的想法自信满满，滔滔不绝介绍自己的创意，其中之一就是：基于大语言模型研发一个老年人伴侣 APP，专门解决老年人孤单无人陪伴的问题，背景是经调研机构研究和评测，中国老龄化逐渐严重，老年人服务市场巨大，等等……&lt;/p&gt;
&lt;p&gt;老牛同学听了一会儿实在没有忍住，强制打断给出判断：&lt;strong&gt;行不通&lt;/strong&gt;，极有可能被大模型厂商&lt;strong&gt;碾压&lt;/strong&gt;，没有生存空间！&lt;/p&gt;
&lt;p&gt;下面是老牛同学的一些不成熟的想法判断示意图：凡是大模型厂商正在做、未来可能会做的事情，小团体、创业团队等如果不想被他们&lt;strong&gt;碾压&lt;/strong&gt;的话，趁早不要做！！！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024072601/09.png&#34;
	width=&#34;1122&#34;
	height=&#34;496&#34;
	srcset=&#34;https://ntopic.cn/p/2024072601/09_hu48584a7613a14d2806324ba93c816aaf_16542_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024072601/09_hu48584a7613a14d2806324ba93c816aaf_16542_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;老牛同学胡乱的想法&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;226&#34;
		data-flex-basis=&#34;542px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;想想看，如果存在一个巨大的大模型市场，那些大模型厂商会不涉猎吗？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;阿里云为了拉新用户使用百炼平台，推广百炼平台，提供免费的算力额度，这些额度难道不是钱吗？大模型厂商之间都已经卷成这样了，小团体还敢挡路？&lt;/li&gt;
&lt;li&gt;大模型厂商他们基本是要人有人、要技术有技术、要资源有资源、要卡有卡，而小团体呢，大多情况只是有一个创意想法而已！&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么，创业小团体的出路在哪儿呢：细分领域，那些大模型厂商看不上的领域、那些和大模型厂商前进方向不冲突的领域。&lt;/p&gt;
&lt;p&gt;比如&lt;strong&gt;准爸准妈&lt;/strong&gt;领域：有没有可能，根据准妈的产检信息，利用大模型预判孩子出生日期、时间、体重、性别等，以便准爸准妈提前做好准备？&lt;/p&gt;
&lt;p&gt;比如&lt;strong&gt;护肤品&lt;/strong&gt;领域：有没有可能，根据女性皮肤照片，利用大模型推荐最合适的护肤品？&lt;/p&gt;
&lt;p&gt;等等，以上只是老牛同学的一些胡思乱想，若有不适宜之处，请帮忙指正，老牛同学第一时间修正或者删除本文，谢谢大家！&lt;/p&gt;
&lt;p&gt;最后的最后，回应本文开头，对阿里云百炼推文做个总结：虽然有那么一点点标题党嫌疑，但总体还是&lt;strong&gt;诚意满满&lt;/strong&gt;（单模型，100 万 Token，有效期 30 天），试问国内还有别家这么干吗？如果我们只是作为一个学习者、体验者或者临时使用者，Token 数量和有效期我想也完全足够。&lt;/p&gt;
&lt;p&gt;因此，如果你只是想体验一下大模型、或者产品上线之前的联调、或者临时小需求需要使用大模型服务，这个免费的羊毛就是为你准备的，抓紧大胆的去薅吧！&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/eq6K8_s9uX459OeUcRPEug&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Qwen2 大模型微调技术详细教程（LoRA 参数高效微调和 SwanLab 可视化监控）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/NYTQVBC4ug73o_VdQy-TeQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LivePortrait 数字人：开源的图生视频模型，本地部署和专业视频制作详细教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/PpY3k3kReKfQdeOJyrB6aw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Qwen2/Lllama3 等大模型，部署团队私有化 RAG 知识库系统的详细教程（Docker+AnythingLLM）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/vt1EXVWtwm6ltZVYtB4-Tg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用 Llama3/Qwen2 等开源大模型，部署团队私有化 Code Copilot 和使用教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署 GLM-4-9B 清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API 使用和搭建 WebUI 界面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/majDONtuAUzN2SAaYWxH1Q&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ollama 完整教程：本地 LLM 管理、WebUI 对话、Python/Java 客户端 API 应用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>基于 Qwen2 大模型微调技术详细教程（LoRA 参数高效微调和 SwanLab 可视化监控）</title>
        <link>https://ntopic.cn/p/2024071801/</link>
        <pubDate>Thu, 18 Jul 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024071801/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024071801/00.png" alt="Featured image of post 基于 Qwen2 大模型微调技术详细教程（LoRA 参数高效微调和 SwanLab 可视化监控）" /&gt;&lt;p&gt;老牛同学在之前的介绍大模型 Prompt 提示词的文章中（&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;），曾把大模型比作成一位无所不能无所不知且不知疲惫的“大师”。我们在日常工作、学习中等一些通用知识方面的问题，通常情况下，我们均可通过 Prompt 提示词就能从“大师”那里得到期望的结果。&lt;/p&gt;
&lt;p&gt;但是，在某些垂直场景的特定任务（包括：个性化服务、内部私有数据等）中，这位“大师”可能就不一定能胜任了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;数据隐私安全：&lt;/strong&gt; 保密项目、创业团体和企业内部数据是需要保证&lt;strong&gt;绝对安全&lt;/strong&gt;的，“大师”的知识来自预训练的公开数据，在推理时就缺乏这方面知识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prompt 长度和截取：&lt;/strong&gt; 使用清晰详细的 Prompt 提示词，确实能帮助“大师”理解我们需求，从而更好的输出结果。但是大模型对输入序列的长度有限制，超长会被截断，同时超长的 Prompt 提示意味着推理成本更高、推理效率更低，可能达不到预期的效果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;个性化需求：&lt;/strong&gt; 预训练的大模型，其对问题的理解和输出方式基本固定，无法满足个性化的需求。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个时候，我们可以通过标记好的结构化数据，让“大师”进一步学习（即：微调），通过调整“大师”的知识（即：调整大模型参数），达到处理特定任务的能力。&lt;/p&gt;
&lt;p&gt;根据我们需要调整的大模型的参数量，微调技术大致可以分为 2 种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;全量微调&lt;/strong&gt; 即&lt;strong&gt;FFT&lt;/strong&gt;(Full Fine-Tuning)，它使用特定领域的数据集对模型的&lt;strong&gt;所有参数&lt;/strong&gt;进行调整，微调的参数量跟预训练时一样多，训练成本和资源会很高，同时可能因数据集等原因出现过拟合问题，导致发生&lt;strong&gt;灾难性遗忘&lt;/strong&gt;(Catastrophic Forgetting)，即我们可能会让大模型在某个领域的能力变的更好，但也可能会让原来其它表现好领域的能力变差。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;参数高效微调&lt;/strong&gt; 即&lt;strong&gt;PEFT&lt;/strong&gt;(Parameter-Efficient Fine-Tuning)，它仅更新模型中的小&lt;strong&gt;部分参数&lt;/strong&gt;，保持大部分预训练权重不变，在保持模型性能的同时减少所需的计算资源和存储空间，可在有效避免过拟合问题的同时，还有助于保留模型在广泛任务上的通用知识（即：泛化能力）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;LoRA&lt;/strong&gt;(Low-Rank Adaptation)是一种高效的大模型&lt;strong&gt;PEFT&lt;/strong&gt;微调技术，它是通过在预训练模型的关键层（如全连接层和自注意力层）之间添加低秩矩阵来完成微调。这些低秩矩阵的引入使得模型能够适应新的任务，而无需改变原有的大量参数。由于低秩矩阵的参数数量远小于原有层的参数数量，这就大大减少了需要训练的参数总数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LoRA&lt;/strong&gt;的优势在于，即使在资源有限的情况下，也可以有效地对大型预训练模型进行微调，使其适应各种下游任务，如文本分类、命名实体识别等。此外，由于 LoRA 的微调通常只需要较少的数据，这也使得它成为小数据集场景下的一个有力工具。&lt;/p&gt;
&lt;p&gt;老牛同学将通过本教程，基于&lt;strong&gt;Qwen2-0.5B&lt;/strong&gt;开源的预训练大模型，和大家一起进行一次大模型&lt;strong&gt;文本分类&lt;/strong&gt;能力的微调。在 AI 蓬勃发展的今天，老牛同学期望能通过本教程，与大家一起在我们的 AI 知识库里新增储备微调知识，逐步做到&lt;strong&gt;肚里有货，从容不迫&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;完成一次完整的大模型微调，大致需要以下几个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;环境准备：&lt;/strong&gt; 主要是 Python 依赖库安装&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据集准备：&lt;/strong&gt; 针对特定任务，准备相关的数据，数据内容包含&lt;strong&gt;Prompt 提示词&lt;/strong&gt;和&lt;strong&gt;输出&lt;/strong&gt;即可&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;准备大模型：&lt;/strong&gt; 我们可以通过 HF、ModelScope 等下载预训练大模型权重&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;大模型微调：&lt;/strong&gt; 包括加载大模型、数据集格式化处理、LoRA 参数准备等。最后，微调过程我们通过&lt;strong&gt;swanlab&lt;/strong&gt;可视化界面查看&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;环境准备和安装依赖包&#34;&gt;环境准备和安装依赖包&lt;/h1&gt;
&lt;p&gt;首先，我们需要通过&lt;strong&gt;Miniconda&lt;/strong&gt;安装 Python 依赖库：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 切换环境&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate PY3.12.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 安装依赖库&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install transformers datasets peft accelerate modelscope swanlab
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果我们还没有安装好&lt;strong&gt;Miniconda&lt;/strong&gt;包管理工具，请先移步此文完成大模型基础环境配置：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/P_ufvz4MWVSqv_VM-rJp9w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;大模型应用研发基础环境配置（Miniconda、Python、Jupyter Lab、Ollama 等）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以上 6 个库的主要用途简单介绍：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;transformers&lt;/strong&gt; HuggingFace 出品的深度学习框架，是 NLP（自然语言处理）领域最流行的训练与推理框架。在本教程中主要用于加载模型、训练以及推理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;datasets&lt;/strong&gt; HuggingFace 出品的数据集工具，在本教程中主要用于加载数据集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;peft&lt;/strong&gt; HuggingFace 出品的微调工具，是一个流行的实现 LoRA 和其他微调技术的库。本教程中主要用于微调训练，与微调后模型推理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;accelerate&lt;/strong&gt; HuggingFace 出品的帮助简化分布式训练和混合精度训练的库。本教程中主要用于支持混合精度训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;modelscope&lt;/strong&gt; ModelScope 库使开发人员能够通过丰富的 API 设计执行推理、训练和评估，从而促进跨不同 AI 领域的最先进模型的统一体验。代码中将主要用于在国内环境中下载 Qwen 大模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;swanlab&lt;/strong&gt; 西安电子科技大学出品，深度学习实验管理与训练的可视化工具，可记录整个实验的超参数、指标、训练环境、Python 版本等，并通过可视化图表展示，帮助我们分析训练的结果。本教程中主要用于记录指标和可视化界面。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;数据集准备和处理&#34;&gt;数据集准备和处理&lt;/h1&gt;
&lt;p&gt;ModelScope 上有很多公开免费的数据集供我们使用：&lt;a class=&#34;link&#34; href=&#34;https://modelscope.cn/datasets&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;datasets&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本教程我们使用的是一个开放性问题进行分类的数据集：&lt;a class=&#34;link&#34; href=&#34;https://modelscope.cn/datasets/swift/zh_cls_fudan-news&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;zh_cls_fudan-news&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs install
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://www.modelscope.cn/datasets/swift/zh_cls_fudan-news.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;下载完成之后，我们会看到 2 个后缀为&lt;code&gt;.jsonl&lt;/code&gt;的文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;zh_cls_fudan-news
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── README.md
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── dataset_infos.json
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── test.jsonl
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;└── train.jsonl
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;.jsonl&lt;/code&gt;文件一般存储的是多行文本，每一行文本是一个 JSON 格式内容，即是多行 JSON 格式内容组合的文件。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;train.jsonl&lt;/code&gt;是训练的输入文件，而&lt;code&gt;test.jsonl&lt;/code&gt;则是训练的验证文件。他们每行 JSON 格式内容都包含&lt;code&gt;text&lt;/code&gt;、&lt;code&gt;category&lt;/code&gt;和&lt;code&gt;output&lt;/code&gt;共 3 个属性，分代表模型输入、可选的分类列表和最终模型输出的分类。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071801/01.png&#34;
	width=&#34;1750&#34;
	height=&#34;636&#34;
	srcset=&#34;https://ntopic.cn/p/2024071801/01_hud75250e07fd5bea56c06f9093b0dbfb9_119056_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071801/01_hud75250e07fd5bea56c06f9093b0dbfb9_119056_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;数据集样例&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;275&#34;
		data-flex-basis=&#34;660px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们对大模型微调的目标，就是希望微调后的大模型能够根据&lt;code&gt;text&lt;/code&gt;和&lt;code&gt;category&lt;/code&gt;组成的提示词，输出正确的&lt;code&gt;output&lt;/code&gt;分类。&lt;/p&gt;
&lt;h1 id=&#34;预训练大模型准备&#34;&gt;预训练大模型准备&lt;/h1&gt;
&lt;p&gt;本教程中，老牛同学使用的是&lt;strong&gt;Qwen2-0.5B&lt;/strong&gt;模型，我们把大模型下载到本地（目录：&lt;code&gt;Qwen2-0.5B&lt;/code&gt;）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs install
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://www.modelscope.cn/qwen/Qwen2-0.5B.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果 Git 克隆失败中断，可以继续克隆下载：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; Qwen2-0.5B
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs pull
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071801/02.png&#34;
	width=&#34;1533&#34;
	height=&#34;837&#34;
	srcset=&#34;https://ntopic.cn/p/2024071801/02_hu9e5bedf258faaf8f4e6bcf02f939a954_215546_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071801/02_hu9e5bedf258faaf8f4e6bcf02f939a954_215546_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Qwen2-0.5B模型权重文件&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;439px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;大模型微调&#34;&gt;大模型微调&lt;/h1&gt;
&lt;p&gt;大模型微调包括：包括加载大模型、数据集格式化处理、LoRA 参数准备等。最后，微调过程我们通过&lt;strong&gt;SwanLab&lt;/strong&gt;可视化界面监控整个微调过程。&lt;/p&gt;
&lt;h2 id=&#34;微调可视化配置&#34;&gt;微调可视化配置&lt;/h2&gt;
&lt;p&gt;我们使用&lt;strong&gt;SwanLab&lt;/strong&gt;来监控整个训练过程，并评估最终的模型效果。如果是第一次使用 SwanLab，则需要注册 SwanLab 账号：&lt;a class=&#34;link&#34; href=&#34;https://swanlab.cn&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://swanlab.cn&lt;/a&gt;，注册成功之后，在&lt;strong&gt;用户设置&lt;/strong&gt;页面复制&lt;strong&gt;API Key&lt;/strong&gt;，在训练开始时需要用到。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071801/03.png&#34;
	width=&#34;1891&#34;
	height=&#34;897&#34;
	srcset=&#34;https://ntopic.cn/p/2024071801/03_hu07537c82fb0b6f77f371850dbf0e736b_61952_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071801/03_hu07537c82fb0b6f77f371850dbf0e736b_61952_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SwanLab API Key获取&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;210&#34;
		data-flex-basis=&#34;505px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;为了便于我们查看我们微调的数据，我们还需要创建一个&lt;strong&gt;项目&lt;/strong&gt;（项目名称：&lt;code&gt;Qwen2-FineTuning&lt;/code&gt;）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071801/04.png&#34;
	width=&#34;678&#34;
	height=&#34;610&#34;
	srcset=&#34;https://ntopic.cn/p/2024071801/04_hu06a6a3a1055c2772d2cf5ce010bffb23_21797_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071801/04_hu06a6a3a1055c2772d2cf5ce010bffb23_21797_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SwanLob创建项目&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;111&#34;
		data-flex-basis=&#34;266px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;大模型加载设置和微调&#34;&gt;大模型加载、设置和微调&lt;/h2&gt;
&lt;p&gt;由于微调涉及到好几步，老牛同学&lt;strong&gt;强烈建议&lt;/strong&gt;大家使用&lt;strong&gt;Jupyter Lab&lt;/strong&gt;工具进行代码调试和验证，它可以把整个代码分成多个区块，单个区块可以多次执行。若还没有配置&lt;strong&gt;Jupyter Lab&lt;/strong&gt;工具，建议先移步此文完成大模型基础环境配置：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/P_ufvz4MWVSqv_VM-rJp9w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;大模型应用研发基础环境配置（Miniconda、Python、Jupyter Lab、Ollama 等）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;因为涉及到不同的代码片段，老牛同学直接粘贴完整代码，通过代码注释和代码后面进行说明（文件名：&lt;code&gt;Qwen2-0.5B-train.py&lt;/code&gt;，完整的代码和数据，老牛同学在&lt;strong&gt;评论区&lt;/strong&gt;提供仓库地址）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;  1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 98
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 99
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;100
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;101
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;102
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;103
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;104
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;105
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;106
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;107
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;108
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;109
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;110
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;111
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;112
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;113
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;114
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;115
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;116
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;117
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;118
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;119
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;120
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;121
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;122
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;123
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;124
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;125
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;126
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;127
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;128
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;129
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;130
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;131
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;132
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;133
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;134
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;135
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;136
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;137
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;138
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;139
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;140
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;141
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;142
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;143
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;144
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;145
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;146
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;147
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;148
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;149
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;150
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;151
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;152
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;153
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;154
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;155
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;156
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;157
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;158
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;159
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;160
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;161
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;162
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;163
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;164
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;165
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;166
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;167
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;168
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;169
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;170
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;171
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;172
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;173
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;174
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;175
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Qwen2-0.5B-train.py&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;json&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;datasets&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dataset&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;modelscope&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AutoTokenizer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;swanlab.integration.huggingface&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SwanLabCallback&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;peft&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LoraConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TaskType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;get_peft_model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;transformers&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AutoModelForCausalLM&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TrainingArguments&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Trainer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataCollatorForSeq2Seq&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;swanlab&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 权重根目录&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;BASE_DIR&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;D:\ModelSpace\Qwen2&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 设备名称&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cuda&amp;#39;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cuda&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;is_available&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cpu&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# device = torch.device(&amp;#39;cuda&amp;#39; if torch.cuda.is_available() else &amp;#39;cpu&amp;#39;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 数据集处理函数，包括：训练数据集和测试数据集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;dataset_jsonl_transfer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;origin_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;new_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    将原始数据集转换为大模型微调所需数据格式的新数据集
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 读取原JSONL文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;origin_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;line&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;c1&#34;&gt;# 解析每一行原始数据（每一行均是一个JSON格式）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;catagory&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;category&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;output&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;文本:&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;,分类选项列表:&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;catagory&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;output&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 保存处理后的JSONL文件，每行也是一个JSON格式&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;new_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;w&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dumps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ensure_ascii&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 在使用数据集训练大模型之前，对每行数据进行预处理&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;process_func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;example&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    将数据集进行预处理
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;MAX_LENGTH&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;384&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;instruction&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;lt;|im_start|&amp;gt;system&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;你是一个文本分类领域的专家，你会接收到一段文本和几个潜在的分类选项列表，请输出文本内容的正确分类&amp;lt;|im_end|&amp;gt;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;lt;|im_start|&amp;gt;user&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;example&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;input&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;lt;|im_end|&amp;gt;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;lt;|im_start|&amp;gt;assistant&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;add_special_tokens&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# add_special_tokens 不在开头加 special_tokens&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;example&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;output&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;add_special_tokens&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;instruction&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;input_ids&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;input_ids&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pad_token_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;attention_mask&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;instruction&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;attention_mask&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;attention_mask&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 因为eos token咱们也是要关注的所以 补充为1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;instruction&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;input_ids&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;input_ids&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pad_token_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MAX_LENGTH&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 做一个截断&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MAX_LENGTH&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;attention_mask&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MAX_LENGTH&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MAX_LENGTH&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;input_ids&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;attention_mask&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention_mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;labels&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 加载预训练模型和分词器&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model_dir&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Qwen2-0.5B&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_pretrained&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;use_fast&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;trust_remote_code&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AutoModelForCausalLM&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_pretrained&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device_map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch_dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bfloat16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enable_input_require_grads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 开启梯度检查点时，要执行该方法&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 加载、处理数据集和测试集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_dataset_path&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;zh_cls_fudan-news&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;train.jsonl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_dataset_path&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;zh_cls_fudan-news&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;test.jsonl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_jsonl_new_path&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;train.jsonl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_jsonl_new_path&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;test.jsonl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exists&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_jsonl_new_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;dataset_jsonl_transfer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_dataset_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_jsonl_new_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exists&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_jsonl_new_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;dataset_jsonl_transfer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_dataset_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_jsonl_new_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 得到微调数据集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_jsonl_new_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lines&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_ds&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_pandas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_dataset&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_ds&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;process_func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;remove_columns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_ds&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;column_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建LoRA配置&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;config&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LoraConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;task_type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TaskType&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CAUSAL_LM&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;target_modules&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;q_proj&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;k_proj&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;v_proj&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;o_proj&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;gate_proj&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;up_proj&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;down_proj&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;inference_mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 训练模式&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Lora 秩&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;lora_alpha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Lora alaph，具体作用参见 Lora 原理&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;lora_dropout&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Dropout 比例&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 将LoRA应用于模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;get_peft_model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建微调参数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TrainingArguments&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;output_dir&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;output&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Qwen2-0.5B&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;per_device_train_batch_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;gradient_accumulation_steps&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;logging_steps&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;num_train_epochs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;save_steps&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;learning_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1e-4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;save_on_each_node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;gradient_checkpointing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;report_to&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;none&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# SwanLab微调过程回调数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;swanlab_callback&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SwanLabCallback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;project&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Qwen2-FineTuning&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;experiment_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Qwen2-0.5B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;trainer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Trainer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;train_dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;data_collator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataCollatorForSeq2Seq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;callbacks&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;swanlab_callback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 开始微调&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;trainer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 模型结果结果评估&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;predict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apply_chat_template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;tokenize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;add_generation_prompt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;model_inputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;return_tensors&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;pt&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;generated_ids&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;generate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;model_inputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;max_new_tokens&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;generated_ids&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;output_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;output_ids&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model_inputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generated_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch_decode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;generated_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;skip_special_tokens&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 模型评估：获取测试集的前10条测试数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_jsonl_new_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lines&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_text_list&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iterrows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;instruction&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;你是一个文本分类领域的专家，你会接收到一段文本和几个潜在的分类选项列表，请输出文本内容的正确分类&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;input_value&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;input&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;instruction&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_value&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tokenizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;result_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n\n&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n\n&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;test_text_list&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;swanlab&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;caption&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;swanlab&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Prediction&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_text_list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;swanlab&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;以上就是大模型微调的全部代码，微调的总体流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先，我们通过&lt;strong&gt;PyTorch&lt;/strong&gt;库检查 CUDA 是否可用，优先使用 CUDA 设备，否则退回 CPU 设备&lt;/li&gt;
&lt;li&gt;然后，定义了 2 个函数：分别是数据集预处理函数、单行数据预处理函数（主要用于把原始数据集映射成大模型微调的数据内容）&lt;/li&gt;
&lt;li&gt;接着准备开始微调了，首先加载预训练模型和分词器，&lt;code&gt;trust_remote_code=True&lt;/code&gt;代表从本地磁盘加载模型权重&lt;/li&gt;
&lt;li&gt;然后使用定义好的函数，处理原始数据集，并处理为微调数据集&lt;/li&gt;
&lt;li&gt;接着创建&lt;strong&gt;LoRA&lt;/strong&gt;配置，并把&lt;strong&gt;LoRA&lt;/strong&gt;配置应用于预训练模型&lt;/li&gt;
&lt;li&gt;接下来创建微调参数（&lt;code&gt;output_dir=&amp;quot;./output/Qwen2-0.5B&amp;quot;&lt;/code&gt;代表微调之后的权重文件目录），并设置&lt;strong&gt;SwanLab&lt;/strong&gt;回调函数&lt;/li&gt;
&lt;li&gt;最后，启动微调：&lt;code&gt;trainer.train()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;微调完成之后，我们通过 10 条测试数据，对模型进行了评估验证&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从原始数据集映射成大模型数据集进度、速度和耗时（共 4000 条数据）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071801/05.png&#34;
	width=&#34;1272&#34;
	height=&#34;559&#34;
	srcset=&#34;https://ntopic.cn/p/2024071801/05_hucc20901b7b38ccca603d82b4f3bf1656_85018_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071801/05_hucc20901b7b38ccca603d82b4f3bf1656_85018_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;微调数据集处理&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;227&#34;
		data-flex-basis=&#34;546px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们启动模型微调后，SwanLab 需要我们输入&lt;strong&gt;API Key&lt;/strong&gt;，输入即可。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071801/06.png&#34;
	width=&#34;1149&#34;
	height=&#34;283&#34;
	srcset=&#34;https://ntopic.cn/p/2024071801/06_huea4ba3bc13c16c553aafce69cb55b220_29443_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071801/06_huea4ba3bc13c16c553aafce69cb55b220_29443_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;输入SwanLab API Key&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;406&#34;
		data-flex-basis=&#34;974px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;查看微调进展&#34;&gt;查看微调进展&lt;/h2&gt;
&lt;p&gt;我们可以在&lt;strong&gt;Jupyter Lab&lt;/strong&gt;中直接开启看板，非常方便的查看微调情况。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071801/07.png&#34;
	width=&#34;1810&#34;
	height=&#34;1189&#34;
	srcset=&#34;https://ntopic.cn/p/2024071801/07_hu8be26a6b1959df1a9e107197ab4fc0eb_75375_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071801/07_hu8be26a6b1959df1a9e107197ab4fc0eb_75375_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SwanLab查看微调进展&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;152&#34;
		data-flex-basis=&#34;365px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;微调完成，可以看到在测试样例评估上，微调后&lt;strong&gt;Qwen2&lt;/strong&gt;大模型能够给出&lt;strong&gt;准确&lt;/strong&gt;的文本分类：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071801/08.png&#34;
	width=&#34;1471&#34;
	height=&#34;1156&#34;
	srcset=&#34;https://ntopic.cn/p/2024071801/08_hu5099bf14f047fd074f148579e5d8a4e2_300381_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071801/08_hu5099bf14f047fd074f148579e5d8a4e2_300381_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;微调结果验证&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;127&#34;
		data-flex-basis=&#34;305px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;至此，我们已经完成了&lt;strong&gt;Qwen2-0.5B&lt;/strong&gt;大模型的微调工作，接下来就可以使用微调后模型完成特定任务了（文本分类）！&lt;/p&gt;
&lt;p&gt;本教程所有的源代码，老牛同学展示在评论区，大家可以获取源文件进行模型微调！&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/NYTQVBC4ug73o_VdQy-TeQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LivePortrait 数字人：开源的图生视频模型，本地部署和专业视频制作详细教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/PpY3k3kReKfQdeOJyrB6aw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Qwen2/Lllama3 等大模型，部署团队私有化 RAG 知识库系统的详细教程（Docker+AnythingLLM）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/vt1EXVWtwm6ltZVYtB4-Tg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用 Llama3/Qwen2 等开源大模型，部署团队私有化 Code Copilot 和使用教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署 GLM-4-9B 清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API 使用和搭建 WebUI 界面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/majDONtuAUzN2SAaYWxH1Q&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ollama 完整教程：本地 LLM 管理、WebUI 对话、Python/Java 客户端 API 应用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>LivePortrait 数字人：开源的图生视频模型，本地部署和专业视频制作详细教程</title>
        <link>https://ntopic.cn/p/2024071401/</link>
        <pubDate>Sun, 14 Jul 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024071401/</guid>
        <description>&lt;img src="https://modelscope.cn/api/v1/models/AI-ModelScope/LivePortrait/repo?Revision=master&amp;FilePath=.%2Fdocs%2Fshowcase2.gif&amp;View=true" alt="Featured image of post LivePortrait 数字人：开源的图生视频模型，本地部署和专业视频制作详细教程" /&gt;&lt;p&gt;&lt;img src=&#34;https://modelscope.cn/api/v1/models/AI-ModelScope/LivePortrait/repo?Revision=master&amp;amp;FilePath=.%2Fdocs%2Fshowcase2.gif&amp;amp;View=true&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://modelscope.cn/api/v1/models/AI-ModelScope/LivePortrait/repo?Revision=master&amp;amp;FilePath=.%2Fdocs%2Finference.gif&amp;amp;View=true&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;脸部动画&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;看到上面面部表情动态图片，是不是感觉挺有有意思？它就是通过快手、中科大和复旦大学联合研发的&lt;strong&gt;图生视频&lt;/strong&gt;开源大模型&lt;strong&gt;LivePortrait&lt;/strong&gt;（灵动人像）生成的视频。通过&lt;strong&gt;LivePortrait&lt;/strong&gt;大模型，我们只需要一张人脸正面图片和一段文字或音频，即可制作专业的视频内容，例如产品介绍、教学课程、趣味视频等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071401/01.png&#34;
	width=&#34;1269&#34;
	height=&#34;843&#34;
	srcset=&#34;https://ntopic.cn/p/2024071401/01_huffff23f2c8945e9c618d1dd3cbab41dc_1989557_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071401/01_huffff23f2c8945e9c618d1dd3cbab41dc_1989557_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;同步的面部表情&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;361px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;有关&lt;strong&gt;LivePortrait&lt;/strong&gt;更多的展示样例参见：&lt;a class=&#34;link&#34; href=&#34;https://liveportrait.github.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://liveportrait.github.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;老牛同学将和大家一起，在本地部署&lt;strong&gt;LivePortrait&lt;/strong&gt;图生视频大模型，并且生成我们自己的视频。本文将包括以下几部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基础环境准备：与我们之前部署 LLM 大模型不同，&lt;strong&gt;LivePortrait&lt;/strong&gt;涉及到音频和视频等多媒体数据的处理，因此环境要稍微复杂一点&lt;/li&gt;
&lt;li&gt;LivePortrait 配置：包括大模型权重文件下载、配置等&lt;/li&gt;
&lt;li&gt;LivePortrait 使用：包括通过图片生成视频、Web 界面可视化生成视频等（建议配合 GPU 进行使用，老牛同学&lt;strong&gt;纯 CPU&lt;/strong&gt;推理速度较慢）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;LivePortrait 理论研究，可以参见论文：&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2407.03168&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/pdf/2407.03168&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;liveportrait-基础环境准备&#34;&gt;LivePortrait 基础环境准备&lt;/h2&gt;
&lt;p&gt;基础环境准备分为以下 3 步：克隆 GitHub 示例源代码、安装 Python 依赖包和下载配置&lt;strong&gt;FFmpeg&lt;/strong&gt;音视频工具库&lt;/p&gt;
&lt;p&gt;【第一步：下载 GitHub 示例源码】&lt;/p&gt;
&lt;p&gt;GitHub 示例源码下载目录：&lt;code&gt;LivePortrait&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/KwaiVGI/LivePortrait
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;特别注意：&lt;/strong&gt; 示例代码克隆成功之后，我们可以看到示例源码目录&lt;code&gt;LivePortrait&lt;/code&gt;下，有个&lt;code&gt;pretrained_weights&lt;/code&gt;空目录，它就是用来存放预训练权重文件的目录，接下来的我们会下载权重文件！&lt;/p&gt;
&lt;p&gt;【第二步：安装 Python 依赖包】&lt;/p&gt;
&lt;p&gt;切换到 GitHub 示例源码目录：&lt;code&gt;cd LivePortrait&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 激活环境：特别注意Python版本为3.9.18，其他版本可能不支持（老牛同学3.12就不支持）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create -n LivePortrait &lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;3.9.18
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate LivePortrait
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 安装依赖包&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果&lt;strong&gt;Miniconda&lt;/strong&gt;还未完成安装，建议先提前安装好：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/P_ufvz4MWVSqv_VM-rJp9w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;大模型应用研发基础环境配置（Miniconda、Python、Jupyter Lab、Ollama 等）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;【第三步：下载和配置 FFmpeg 音视频工具库】&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FFmpeg&lt;/strong&gt; 是一个非常强大的开源软件工具库，主要用于处理多媒体数据，包括音频和视频的编码、解码、转码、复用、解复用、流媒体传输以及播放等。&lt;/p&gt;
&lt;p&gt;我们可以通过 FFmpeg 官网下载：&lt;a class=&#34;link&#34; href=&#34;https://ffmpeg.org/download.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ffmpeg.org/download.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;或者，老牛同学已经下载好了，放到了百度网盘（评论区也有地址）：&lt;a class=&#34;link&#34; href=&#34;https://pan.baidu.com/s/1IYutMbJGJSxLVY56-h4IPg?pwd=LNTX&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pan.baidu.com/s/1IYutMbJGJSxLVY56-h4IPg?pwd=LNTX&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载安装好之后，把 FFmpeg 目录设置在&lt;code&gt;PATH&lt;/code&gt;环境变量中，同时执行命令进行检测：&lt;code&gt;ffmpeg -version&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt;ffmpeg -version
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ffmpeg version 7.0.1-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;built with gcc 13.2.0 (Rev5, Built by MSYS2 project)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;libavutil      59.  8.100 / 59.  8.100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;libavcodec     61.  3.100 / 61.  3.100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;libavformat    61.  1.100 / 61.  1.100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;libavdevice    61.  1.100 / 61.  1.100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;libavfilter    10.  1.100 / 10.  1.100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;libswscale      8.  1.100 /  8.  1.100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;libswresample   5.  1.100 /  5.  1.100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;libpostproc    58.  1.100 / 58.  1.100
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;liveportrait-模型权重下载和配置&#34;&gt;LivePortrait 模型权重下载和配置&lt;/h2&gt;
&lt;p&gt;我们可以通过多种方式下载预训练权重文件，包括 HF 和云盘等：&lt;/p&gt;
&lt;p&gt;【方式一：HF 下载权重文件】&lt;/p&gt;
&lt;p&gt;由于文件比较大，Git 无法直接下载，首先需要设置 Git 大文件环境：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后克隆权重文件，下载的目录：&lt;code&gt;pretrained_weights&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://www.modelscope.cn/AI-ModelScope/LivePortrait.git pretrained_weights
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;由于文件比较大，Git 在克隆过程中可能会中断，我们可以通过 Git 命令重试：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 切换到权重文件目录&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; pretrained_weights
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 继续中断下载&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs pull
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;【方式二：百度云盘或 Google Drive 下载】&lt;/p&gt;
&lt;p&gt;百度云盘：&lt;a class=&#34;link&#34; href=&#34;https://pan.baidu.com/s/1MGctWmNla_vZxDbEp2Dtzw?pwd=z5cn&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pan.baidu.com/s/1MGctWmNla_vZxDbEp2Dtzw?pwd=z5cn&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Google 云盘：&lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/drive/folders/1UtKgzKjFAOmZkhNK-OYT0caJ_w2XAnib&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://drive.google.com/drive/folders/1UtKgzKjFAOmZkhNK-OYT0caJ_w2XAnib&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特别注意：&lt;/strong&gt; 我们通过 Git 或者云盘下载到完整的权重文件之后，确认一下它的目录结构如下所示：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pretrained_weights
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── insightface
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│   └── models
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│       └── buffalo_l
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│           ├── 2d106det.onnx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│           └── det_10g.onnx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;└── liveportrait
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ├── base_models
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    │   ├── appearance_feature_extractor.pth
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    │   ├── motion_extractor.pth
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    │   ├── spade_generator.pth
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    │   └── warping_module.pth
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ├── landmark.onnx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    └── retargeting_models
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        └── stitching_retargeting_module.pth
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;最后，把&lt;code&gt;pretrained_weights&lt;/code&gt;目录下的&lt;code&gt;insightface&lt;/code&gt;和&lt;code&gt;liveportrait&lt;/code&gt;这 2 个目录和文件全部复制到 GitHub 实例源码的&lt;code&gt;pretrained_weights&lt;/code&gt;目录下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小提示：&lt;/strong&gt; 如果我们使用的是 MacOS 或者 Linux 操作系统，也可以尝试通过软链接来代替文件复制（因老牛同学是 Windows 系统，在这里无法展示，请大家尝试）！&lt;/p&gt;
&lt;h2 id=&#34;使用-liveportrait-生成视频&#34;&gt;使用 LivePortrait 生成视频&lt;/h2&gt;
&lt;p&gt;我们可以通过终端命令行或者 Web 可视化界面 2 种方式来使用 LivePortrait 生成视频：&lt;/p&gt;
&lt;p&gt;【&lt;strong&gt;方式一：&lt;/strong&gt; 使用终端命令行生成视频】&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;打开终端，切换到 GitHub 示例源码目录：&lt;code&gt;cd LivePortrait&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;激活 Python 环境：&lt;code&gt;conda activate LivePortrait&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;经老牛同学测试，还需要安装额外 Python 依赖包：&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 额外依赖包&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install tyro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install patch_ng
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 安装依赖包：如果前面已安装则可忽略（特别注意Python版本：3.9.18）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;执行 Python 程序：在 GitHub 示例源码中，&lt;code&gt;inference.py&lt;/code&gt;就是我们的大模型推理函数入口&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;打开终端，切换到 GitHub 示例源码目录&lt;code&gt;cd LivePortrait&lt;/code&gt;，然后推理执行：&lt;code&gt;python inference.py&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可能的报错：&lt;/strong&gt; 如果出现如下报错，请用&lt;strong&gt;Miniconda&lt;/strong&gt;设置 Python &lt;code&gt;3.9.18&lt;/code&gt; 版本的环境：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ValueError: mutable default &amp;lt;class &amp;#39;numpy.ndarray&amp;#39;&amp;gt; for field mask_crop is not allowed: use default_factory
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;可能的报错：&lt;/strong&gt; 如果出现如下报错，默认需要 GPU 进行推理，如果我们有 GPU 则需要正确安装 GPU 驱动，或者我们可以强制&lt;strong&gt;CPU&lt;/strong&gt;运行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;【&lt;strong&gt;强制 CPU 运行&lt;/strong&gt;】我们可以通过 &lt;strong&gt;&amp;ndash;flag-force-cpu&lt;/strong&gt; 参数强制使用 CPU 推理：&lt;code&gt;python inference.py --flag-force-cpu&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果内存或者卡内存足够，最终会在 GitHub 源码目录中生成了最终视频文件：&lt;code&gt;./animations/s6--d0_concat.mp4&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;很不幸，老牛同学&lt;strong&gt;16GB&lt;/strong&gt;内存不足，导致最终生成视频失败（预计至少 22GB 内存）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;RuntimeError: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6383992832 bytes.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;根据官方文档，我们可以通过以下几个参数，来设置人像正脸图片、面部动画和生成视频目录：&lt;code&gt;python inference.py --flag-force-cpu -s ./assets/examples/source/s6.jpg -d ./assets/examples/driving/d0.mp4 -o animations&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;【&lt;strong&gt;方式二：&lt;/strong&gt; 通过 Web 界面生成视频】&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;打开终端，切换到 GitHub 示例源码目录：&lt;code&gt;cd LivePortrait&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;激活 Python 环境：&lt;code&gt;conda activate LivePortrait&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;启动 Web 界面：&lt;code&gt;python app.py --flag-force-cpu&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;....
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FaceAnalysisDIY warmup time: 0.163s                                                                      face_analysis_diy.py:79
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Running on local URL:  http://127.0.0.1:8890
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们通过浏览器打开地址：&lt;a class=&#34;link&#34; href=&#34;http://127.0.0.1:8890&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://127.0.0.1:8890&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071401/02.png&#34;
	width=&#34;1990&#34;
	height=&#34;1039&#34;
	srcset=&#34;https://ntopic.cn/p/2024071401/02_hu544d20252cfe081bf4a6d1d532764fbf_554330_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071401/02_hu544d20252cfe081bf4a6d1d532764fbf_554330_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Web可视化界面&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;459px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们可以直接使用实例源码的头像图片和头部动画，也可以选择自己的图片或头部动画，还可以点击&lt;strong&gt;摄像头&lt;/strong&gt;图标，&lt;strong&gt;拍摄和录制&lt;/strong&gt;我们自己的正脸和面部视频，之后点击**🚀 Animate**按钮即开始生成视频。&lt;/p&gt;
&lt;h1 id=&#34;没有-gpu-在线体验&#34;&gt;没有 GPU 在线体验&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;LivePortrait&lt;/strong&gt;开源的图生视频模型，可以让更多个人、小团体和企业等能轻松部署使用，以生成自己的数字化人物视频。&lt;strong&gt;LivePortrait&lt;/strong&gt;能显著降低了数字化人物创建的门槛，预示着实时视频处理领域的巨大潜力，同时也会在技术和应用层面推动了图生视频技术的快速发展，包括在&lt;strong&gt;视频会议&lt;/strong&gt;、&lt;strong&gt;社交媒体直播&lt;/strong&gt;以及&lt;strong&gt;实时游戏动画&lt;/strong&gt;等实时应用场景中展现了巨大的应用潜力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LivePortrait&lt;/strong&gt;开源的图生视频模型不仅在技术上取得了重要进展，也对图生视频的商业应用和社会影响提出了新的思考。随着技术的进一步成熟和社会应用的深入，未来图生视频技术将在多个领域展现更广阔的应用前景。&lt;/p&gt;
&lt;p&gt;ModelScope 模搭社区提供了在线体验 Web 界面，如果我们没有 GPU 本地部署推理太慢了，也可以去体验一下：&lt;a class=&#34;link&#34; href=&#34;https://modelscope.cn/studios/DAMOXR/LivePortrait&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://modelscope.cn/studios/DAMOXR/LivePortrait&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024071401/03.png&#34;
	width=&#34;1629&#34;
	height=&#34;1122&#34;
	srcset=&#34;https://ntopic.cn/p/2024071401/03_hu4e0fe2d5804d3aeef224153a049d37a7_1748065_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024071401/03_hu4e0fe2d5804d3aeef224153a049d37a7_1748065_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;LivePortrait使用体验&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;348px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/PpY3k3kReKfQdeOJyrB6aw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Qwen2/Lllama3 等大模型，部署团队私有化 RAG 知识库系统的详细教程（Docker+AnythingLLM）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/vt1EXVWtwm6ltZVYtB4-Tg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用 Llama3/Qwen2 等开源大模型，部署团队私有化 Code Copilot 和使用教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署 GLM-4-9B 清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API 使用和搭建 WebUI 界面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/majDONtuAUzN2SAaYWxH1Q&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ollama 完整教程：本地 LLM 管理、WebUI 对话、Python/Java 客户端 API 应用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>阿里Qwen2-72B大模型已是开源榜的王者，为什么还要推出其他参数模型，被其他模型打榜？</title>
        <link>https://ntopic.cn/p/2024070401/</link>
        <pubDate>Thu, 04 Jul 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024070401/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024070401/00.png" alt="Featured image of post 阿里Qwen2-72B大模型已是开源榜的王者，为什么还要推出其他参数模型，被其他模型打榜？" /&gt;&lt;p&gt;6 月 27 日，全球知名的开源平台 Hugging Face 的联合创始人兼首席执行官 Clem 在社交平台激动宣布，阿里 &lt;strong&gt;Qwen2-72B&lt;/strong&gt; 成为了开源模型排行榜的王者。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024070401/01.png&#34;
	width=&#34;554&#34;
	height=&#34;419&#34;
	srcset=&#34;https://ntopic.cn/p/2024070401/01_hu270b854608a715a6ecd608a754ec480a_125206_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024070401/01_hu270b854608a715a6ecd608a754ec480a_125206_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Clem社交平台消息&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;132&#34;
		data-flex-basis=&#34;317px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;这是一件大好事，说明了我们在大模型领域从先前的追赶，逐渐走向了领导，未来完全有可能会引领着全球开源模型的发展潮流，这是我们的骄傲！&lt;/p&gt;
&lt;p&gt;不过话说回来，&lt;strong&gt;Qwen2&lt;/strong&gt; 序列有 5 个参数版本，分别是 &lt;strong&gt;Qwen2-0.5B&lt;/strong&gt;、&lt;strong&gt;Qwen2-1.5B&lt;/strong&gt;、&lt;strong&gt;Qwen2-7B&lt;/strong&gt;、&lt;strong&gt;Qwen2-57B-A14B&lt;/strong&gt; 和 &lt;strong&gt;Qwen2-72B&lt;/strong&gt;。本次排行榜第一的是 &lt;strong&gt;Qwen2-72B&lt;/strong&gt; 参数版本，那么其他参数版本的评测结果如何呢？老牛同学查看了 Qwen2 的官方文档，有一些比较评测：&lt;a class=&#34;link&#34; href=&#34;https://qwenlm.github.io/zh/blog/qwen2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://qwenlm.github.io/zh/blog/qwen2/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Qwen2-72B&lt;/strong&gt; 如 Clem 宣布一样，包括自然语言理解、知识、代码、数学及多语言等多项能力上均显著超越当前领先的模型：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024070401/02.png&#34;
	width=&#34;5333&#34;
	height=&#34;3000&#34;
	srcset=&#34;https://ntopic.cn/p/2024070401/02_hu142dd24e0e4692d96d331a27b1b66b8d_1831299_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024070401/02_hu142dd24e0e4692d96d331a27b1b66b8d_1831299_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Qwen2-72B评测结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;而 &lt;strong&gt;Qwen2-7B&lt;/strong&gt; 模型在&lt;strong&gt;自然语言理解&lt;/strong&gt; 和 &lt;strong&gt;数学&lt;/strong&gt; 方面均有点落后了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024070401/03.png&#34;
	width=&#34;2304&#34;
	height=&#34;902&#34;
	srcset=&#34;https://ntopic.cn/p/2024070401/03_hu66f53dbe145d71753d55dcb7041106ca_512520_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024070401/03_hu66f53dbe145d71753d55dcb7041106ca_512520_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Qwen2-7B评测结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;255&#34;
		data-flex-basis=&#34;613px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;其他参数版本没有评测结果，老牛同学猜测是其他参与评测的大模型没有对等的参数版本，因此无法进行比较，或者评测结果不相上下，也就没有必要把结果放出来了。&lt;/p&gt;
&lt;h2 id=&#34;老牛同学的疑问&#34;&gt;老牛同学的疑问&lt;/h2&gt;
&lt;p&gt;那么老牛同学的问题来了：&lt;strong&gt;阿里 Qwen2-72B 大模型已是开源榜的王者，为什么还要推出其他参数模型，被其他模型打榜？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;老牛同学带着这个问题咨询了几位同事，也问了&lt;strong&gt;Qwen2-7B&lt;/strong&gt;大模型，他们的回答均有一定道理，但老牛同学猜测，Qwen 这么做的核心目的只有一个：&lt;strong&gt;丰富 Qwen 大模型生态&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;【&lt;strong&gt;原因一：&lt;/strong&gt; 训练 Qwen 中小尺寸参数成本并不高】&lt;/p&gt;
&lt;p&gt;以阿里人才储备、基础设施和高层 &lt;strong&gt;All in AI&lt;/strong&gt; 的决心和投入，训练 Qwen 中小参数版本的模型应该不是什么难事，顺手即可做的事情，相对来说成本并不高&lt;/p&gt;
&lt;p&gt;【&lt;strong&gt;原因二：&lt;/strong&gt; 快速进行迭代和模型参数优化演进】&lt;/p&gt;
&lt;p&gt;通过快速发布多个尺寸的模型，可以让内外部的技术究人员分析和探索模型的参数规模与性能之间的关系，以便能找到最佳的平衡点，最终不断推动优化和演进 Qwen 系列大模型&lt;/p&gt;
&lt;p&gt;【&lt;strong&gt;原因三：&lt;/strong&gt; 构建和丰富 Qwen 大模型全场景生态】&lt;/p&gt;
&lt;p&gt;老牛同学认为这是最为&lt;strong&gt;关键&lt;/strong&gt;的一点，开源不是目的、打榜争第一也应该不是目的，它们都只是&lt;strong&gt;构建并丰富生态&lt;/strong&gt;的策略！老牛同学和大家一起来回顾 2 件事情：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Windows XP 生态：&lt;/strong&gt; 我们还记得二零零几年的时候，满大街 &lt;strong&gt;Windows XP&lt;/strong&gt; 的盗版操作系统吗？操作系统激活竟然也可以是路边打印小店的一大业务。那么，盗版这么多，微软为什么不管管？是他不知道吗，还是根本管不了？老牛同学觉得都不是，应该是微软故意放任不管：微软要赚的是企业的钱，包括 IT 公司、电脑厂商等，个人的钱不太好赚；同时，使用 Windows 操作系统的个人越多，会带动 Windows 生态发展（使用技巧和攻略、研发各种各样的软件等），进而能拉动更多使用的个人，同时对于企业来说意味着熟练的工人也越多，企业为降低成本，自然就愿意采购 Windows 正版授权，最终还是微软赚钱了！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;阿里云 OS 生态：&lt;/strong&gt; 老牛同学在二零一几年的时候看到过一张图片，图片展示的是当时的阿里 CTO 王坚博士在报告台上擦眼泪。传说是王坚博士在给一群高管做汇报，汇报内容是阿里云和手机操作系统（云 OS）。云计算在当时的中国没有任何一家企业有布局，但王坚博士坚信云计算和云 OS 的未来，他作为第一个吃螃蟹的人，在技术研发和基础设施等方面的投入成本都非常巨大，受到了一些高管和投资人的质疑，因此他边做着汇报边流着委屈的流泪。辛亏当时马老师力排众议，支持王坚博士的想法，如今阿里云在国内技术或市场上称第二，应该没有其他云能自信的称第一了。&lt;/p&gt;
&lt;p&gt;反观 &lt;strong&gt;云 OS&lt;/strong&gt; 我们几乎感知不到了，很大一个原因是 &lt;strong&gt;没有生态&lt;/strong&gt;：云 OS 曾经和国内的一些手机厂商合作推出过一些手机品牌（如 &lt;strong&gt;小辣椒&lt;/strong&gt;、&lt;strong&gt;大黄蜂&lt;/strong&gt;等），和比较大的厂商 &lt;strong&gt;宏基&lt;/strong&gt; 的合作新闻发布会，后者也因 Google Android 的压力不得不放弃合作。Google 对云 OS 抄袭 Android 的 API 代码的状告一直不断。老牛同时当时咨询过一位负责云 OS 短信模块的技术同学，为什么云 OS 的 API 需要和 Android 保持一致，是技术能力不够吗？技术同学告诉老牛同学，操作系统都能研发出来，API 并没有什么技术难度，但是如果 API 不能和 Android 保持一致，那么已有的 Android APP 将无法接入，所以必须要兼容保持一致，否则没有了 Android 的生态，操作系统要推广就难于登天了。&lt;/p&gt;
&lt;p&gt;如今，&lt;strong&gt;云 OS&lt;/strong&gt; 虽然没有成为手机操作系统，但它却在车载（斑马网络）、智能家居（电视、天猫精灵等）等 OS 中大放异彩。&lt;/p&gt;
&lt;p&gt;而 Qwen 系列大模型的 &lt;strong&gt;Qwen2-0.5B&lt;/strong&gt;和&lt;strong&gt;Qwen2-1.5B&lt;/strong&gt;可在智能家居推理；&lt;strong&gt;Qwen2-7B&lt;/strong&gt;可用于个人、小团队等部署推理，个人业务不断发展，就可能购买云服务器部署，小团队业务进一步发展，也完全有可能购买 Qwen 推理服务，最终形成完美的闭环（感觉和&lt;strong&gt;Windows XP&lt;/strong&gt;有那么一点点类似）。&lt;/p&gt;
&lt;h2 id=&#34;最后纯属老牛同学个人观点请慎喷&#34;&gt;最后：纯属老牛同学个人观点，请慎喷&lt;/h2&gt;
&lt;p&gt;以上观点纯属老牛同学个人的猜测，若有不合理之处，欢迎留言讨论，若有冒犯之处，请联系老牛同学删除此文，非常感谢！&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习交流进步 👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署 GLM-4-9B 清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/bNxHM3B7HOLNvJtjwvt8iw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Phi-3 模型手机部署教程（微软发布的可与 GPT-3.5 媲美的小模型）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/u_Uw88dpQRgbtfI4_1OOwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Qwen2 阿里最强开源大模型（Qwen2-7B）本地部署、API 调用和 WebUI 对话机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Llama 3 搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/6C_YqZ2SQh0C1_631keVeg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google 发布了最新的开源大模型 Gemma 2，本地快速部署和体验&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ChatTTS 文本转语音模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API 使用和搭建 WebUI 界面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stable Diffusion 3 文生图模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Sax4z2k8Dvn82h15jf51Hw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Stable Diffusion 3 文生图“开源英雄”大模型本地部署和使用教程，轻松实现 AI 绘图自由&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大模型应用实战&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/vt1EXVWtwm6ltZVYtB4-Tg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用 Llama3/Qwen2 等开源大模型，部署团队私有化 Code Copilot 和使用教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/P_ufvz4MWVSqv_VM-rJp9w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;大模型应用研发基础环境配置（Miniconda、Python、Jupyter Lab、Ollama 等）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/m_O2OSoXWLL0PJurLCdzng&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;借助 AI 大模型，三分钟原创一部儿童故事短视频（附完整操作步骤）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python 小游戏&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hv2tE-yot_H04HCezxQWXg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI 已来，我与 AI 一起用 Python 编写了一个消消乐小游戏&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/tkTlt4rbFKQ73zudluPO1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python 游戏编程：一步步用 Python 打造经典贪吃蛇小游戏&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Google 发布了最新的开源大模型 Gemma 2，本地快速部署和体验</title>
        <link>https://ntopic.cn/p/2024070201/</link>
        <pubDate>Tue, 02 Jul 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024070201/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024070201/00.png" alt="Featured image of post Google 发布了最新的开源大模型 Gemma 2，本地快速部署和体验" /&gt;&lt;p&gt;Gemma 2 是 Google 最新发布的开源大语言模型。它有两种规模：&lt;strong&gt;90 亿&lt;/strong&gt;（9B）参数和 &lt;strong&gt;270 亿&lt;/strong&gt;（27B）参数，分别具有&lt;strong&gt;基础&lt;/strong&gt;（预训练）和&lt;strong&gt;指令调优&lt;/strong&gt;版本，拥有 8K Tokens 的上下文长度：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gemma-2-9b：&lt;/strong&gt; 90 亿参数基础模型版本&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gemma-2-9b-it：&lt;/strong&gt; 90 亿参数基础模型的指令调优版本&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gemma-2-27B：&lt;/strong&gt; 270 亿参数基础模型版本&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gemma-2-27B-it：&lt;/strong&gt; 270 亿参数基础模型的指令调优版本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024070201/01.png&#34;
	width=&#34;1689&#34;
	height=&#34;702&#34;
	srcset=&#34;https://ntopic.cn/p/2024070201/01_huc0c4e1950e8ea56d5272b8c68d576173_1058031_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024070201/01_huc0c4e1950e8ea56d5272b8c68d576173_1058031_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Gemma 2大模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;240&#34;
		data-flex-basis=&#34;577px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Gemma 2 模型的训练数据量约为其第一代的两倍，总计 13 万亿 Tokens（270 亿模型）和 8 万亿 Tokens（90 亿模型）的网页数据（主要是英语）、代码和数学数据。同时，相比较第一代，Gemma 2 的推理性能更高、效率更高，并在安全性方面取得了重大进步。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;许可协议：&lt;/strong&gt; Gemma 2 与第一代使用相同的许可证，这是一个允许再分发、微调、商业用途和衍生作品的宽松许可证。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;性能优异：&lt;/strong&gt; Gemma 2 27B 版本在同规模级别中性能最佳，甚至比两倍于其尺寸的机型更具竞争力。9B 版本的性能在同类产品中也处于领先地位，超过了 Llama 3 8B 和其他同规模的开放模型。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024070201/02.png&#34;
	width=&#34;1000&#34;
	height=&#34;562&#34;
	srcset=&#34;https://ntopic.cn/p/2024070201/02_hu8f408a2d11d5e81665e92e21d0e62dbd_111352_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024070201/02_hu8f408a2d11d5e81665e92e21d0e62dbd_111352_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Gemma 2评测对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;427px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;其他关于 Gemma 2 的介绍信息，可以参见 Google 官方博客：&lt;a class=&#34;link&#34; href=&#34;https://blog.google/technology/developers/google-gemma-2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.google/technology/developers/google-gemma-2/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Google 重磅发布产品，我们肯定需要体验以下。今天，老牛同学就和大家一起，分别通过 2 种方式在个人笔记本电脑本地部署和体验 &lt;strong&gt;Gemma2-9B&lt;/strong&gt; 大模型。&lt;/p&gt;
&lt;h2 id=&#34;方式一通过-ollama-部署大模型&#34;&gt;方式一：通过 Ollama 部署大模型&lt;/h2&gt;
&lt;p&gt;关于 Ollama 是什么以及它的使用方式，老牛同学前面的博文中有介绍，本文不在赘述，感兴趣的朋友可以看一下之前的博文。&lt;/p&gt;
&lt;p&gt;Ollama 管理和维护 Gemma 2 比较简单，主要流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;下载并安装 Ollama 软件（Windows/Linux/MacOS 均支持）：&lt;a class=&#34;link&#34; href=&#34;https://ollama.com/download&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ollama.com/download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;通过 Ollama 下载并启动 Gemma 2 大模型：&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run gemma2:9b
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;模型文件大小为 &lt;strong&gt;5.4GB&lt;/strong&gt; 左右，需要耐心等待模型下载完成。下载完成之后，Ollama 自动启动模型，就可以通过 Ollama 进行对话了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024070201/03.png&#34;
	width=&#34;1639&#34;
	height=&#34;700&#34;
	srcset=&#34;https://ntopic.cn/p/2024070201/03_hu95d5fa022cb76a43452306ec30e4292f_72955_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024070201/03_hu95d5fa022cb76a43452306ec30e4292f_72955_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Gemma 2对话界面&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;234&#34;
		data-flex-basis=&#34;561px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如果觉得通过控制台的方式对话体验不好，可以部署 WebUI 的方式与模型对话。WebUI 的部署方式，可以参见老牛同学之前的博文：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/P_ufvz4MWVSqv_VM-rJp9w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/P_ufvz4MWVSqv_VM-rJp9w&lt;/a&gt;，主要部署步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;下载并安装 Node.js 工具：&lt;a class=&#34;link&#34; href=&#34;https://nodejs.org/zh-cn&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://nodejs.org/zh-cn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;下载&lt;code&gt;ollama-webui&lt;/code&gt;工程代码：&lt;code&gt;git clone https://github.com/ollama-webui/ollama-webui-lite ollama-webui&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;切换&lt;code&gt;ollama-webui&lt;/code&gt;代码的目录：&lt;code&gt;cd ollama-webui&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;设置 Node.js 工具包镜像源（下载提速）：&lt;code&gt;npm config set registry http://mirrors.cloud.tencent.com/npm/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;安装 Node.js 依赖的工具包：&lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;最后，启动 Web 可视化界面：&lt;code&gt;npm run dev&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然后，通过浏览器打开 WebUI 对话界面了：&lt;a class=&#34;link&#34; href=&#34;http://localhost:3000/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024070201/04.png&#34;
	width=&#34;1849&#34;
	height=&#34;1431&#34;
	srcset=&#34;https://ntopic.cn/p/2024070201/04_huc01418b7783981310b3740fccc9ba825_206579_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024070201/04_huc01418b7783981310b3740fccc9ba825_206579_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;WebUI对话界面示例&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;310px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;方式二通过-gguf-部署大模型&#34;&gt;方式二：通过 GGUF 部署大模型&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;GGUF&lt;/strong&gt;模型文件格式是为了快速推理和优化内存使用而设计的，支持更复杂的令牌化过程和特殊令牌处理，能更好地应对多样化的语言模型需求。&lt;strong&gt;GGUF&lt;/strong&gt;就一个文件，也简化了模型交换和部署的过程，它对促进模型的普及和应用有着积极作用。&lt;/p&gt;
&lt;p&gt;GGUF 模型文件列表：&lt;a class=&#34;link&#34; href=&#34;https://modelscope.cn/models/LLM-Research/gemma-2-9b-it-GGUF/files&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://modelscope.cn/models/LLM-Research/gemma-2-9b-it-GGUF/files&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024070201/05.png&#34;
	width=&#34;705&#34;
	height=&#34;1131&#34;
	srcset=&#34;https://ntopic.cn/p/2024070201/05_hu7d700f8c9f468421316f1872bf9d2f39_104635_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024070201/05_hu7d700f8c9f468421316f1872bf9d2f39_104635_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GGUF 模型文件列表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;62&#34;
		data-flex-basis=&#34;149px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;GGUF 模型文件名称格式，如&lt;code&gt;gemma-2-9b-it-Q5_K_M.gguf&lt;/code&gt;等：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;it&lt;/strong&gt;代表本模型是对基线模型进行了微调，用于更好地理解和生成遵循指令（instruction-following）的文本，以提供符合要求的响应&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Q4/Q5 等&lt;/strong&gt;代表模型权重的量化位数（其中&lt;strong&gt;Q&lt;/strong&gt;是&lt;strong&gt;Quantization&lt;/strong&gt;的缩小，即量化），是一种模型压缩技术，用于减少模型大小，同时降低对计算资源的需求（特别是内存），但又尽量保持模型的性能；数字&lt;strong&gt;4&lt;/strong&gt;或&lt;strong&gt;5&lt;/strong&gt;则代表量化精度的位数（Q4 是 4 位，Q5 是 5 位等），精度越高模型体积和内存使用也会越大，但仍然远小于未量化的基线模型&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;K_M/K_S&lt;/strong&gt;代表了与注意力机制相关的特定配置，&lt;strong&gt;K_M&lt;/strong&gt; 可能是指 Key 的 Mask，即用来屏蔽某些位置的键值对，防止它们在注意力计算中被考虑；而 &lt;strong&gt;K_S&lt;/strong&gt; 可能是指 Key 的 Scale 或 Size，涉及到键向量缩放，这是在多头注意力机制中常见的操作，以稳定梯度&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;点击&lt;strong&gt;下载&lt;/strong&gt;图标即可下载，由于文件较大，浏览器的下载容易过程容易终端，重试可继续下载（假设下载本地的文件名为：&lt;code&gt;Gemma-2-9B-it-Q5_K_M.gguf&lt;/code&gt;）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;打开一个终端窗口，切换到 GGUF 文件所在目录：&lt;code&gt;cd Gemma2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;切换 Python 虚拟环境：&lt;code&gt;conda activate PY3.12&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;安装 Python 依赖包：&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install llama-cpp-python
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install openai
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install uvicorn
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install starlette
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install fastapi
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install sse_starlette
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install starlette_context
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install pydantic_settings
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;或者，我们也可以一把进行安装：&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;llama-cpp-python
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;openai
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;uvicorn
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;starlette
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;fastapi
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sse_starlette
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;starlette_context
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pydantic_settings
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;最后，启动大模型：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动Llama大模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python -m llama_cpp.server --host 0.0.0.0 --model ./Gemma-2-9B-it-Q5_K_M.gguf --n_ctx &lt;span class=&#34;m&#34;&gt;2048&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;模型启动命令中，&lt;code&gt;n_ctx 2048&lt;/code&gt;代表单次回话最大 Token 数量。&lt;/p&gt;
&lt;p&gt;启动成功，我们应该看到类似如下的信息：&lt;code&gt;INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/06.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Gemma 启动成功&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最后一步：&lt;/strong&gt; 我们使用 &lt;strong&gt;openai&lt;/strong&gt; 库在个人电脑上快速搭建客户端。Python 客户端代码（&lt;code&gt;Client.py&lt;/code&gt;）如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们使用&lt;strong&gt;OpenAI&lt;/strong&gt;接口来与 Gemma 交互，上面启动模型的最后，我们看到服务端 IP 是本地，端口是&lt;strong&gt;8000&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;接着，我们使用 2 条信息对历史记录进行初始化：第一个条是&lt;strong&gt;系统信息&lt;/strong&gt;，第二个条是要求模型自我介绍的&lt;strong&gt;用户提示&lt;/strong&gt;，为了避免长篇大论，我这里限制了回答的长度和字数&lt;/li&gt;
&lt;li&gt;接下来，通过&lt;code&gt;&amp;gt;&lt;/code&gt;提示符等待用户（即我们）输入，输入&lt;code&gt;bye&lt;/code&gt;、&lt;code&gt;quit&lt;/code&gt;和&lt;code&gt;exit&lt;/code&gt;任意一个即代表退出客户端&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Client.py&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;openai&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 注意服务端端口，因为是本地，所以不需要api_key&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base_url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:8000/v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;api_key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;EMPTY&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 对话历史：设定系统角色是一个只能助理，同时提交“自我介绍”问题&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;history&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;你是一个智能助理，你的回答总是正确的、有用的和内容非常精简.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;请用中文进行自我介绍，要求不能超过5句话，总字数不超过100个字。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[92;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 首次自我介绍完毕，接下来是等代码我们的提示&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;completions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;local-model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;stream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flush&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[91;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;userinput&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;gt; &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;userinput&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lower&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;bye&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;quit&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;exit&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]:&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 我们输入bye/quit/exit等均退出客户端&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[0mBYE BYE!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;userinput&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[92;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们打开一个 Terminal 终端，运行客户端：&lt;code&gt;python Client.py&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024070201/07.png&#34;
	width=&#34;1720&#34;
	height=&#34;441&#34;
	srcset=&#34;https://ntopic.cn/p/2024070201/07_hu614b48ac6240ec91d965e84d307b0bed_47523_480x0_resize_box_3.png 480w, https://ntopic.cn/p/2024070201/07_hu614b48ac6240ec91d965e84d307b0bed_47523_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Gemma 对话&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;390&#34;
		data-flex-basis=&#34;936px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;恭喜你，第二种方式也部署成功了，我们可以愉快地与大模型进行对话了，包括把大模型作为我们 &lt;strong&gt;Code Copilot&lt;/strong&gt; 的底层模型，部署我们团队私有化的 &lt;strong&gt;Code Copilot&lt;/strong&gt; 的底层模型，部署我们团队私有化的了：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/vt1EXVWtwm6ltZVYtB4-Tg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;个人或团队私有化 Code Copilot 部署和使用教程&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上是老牛同学和大家一起采用 2 种方式快速部署 Gemma 2 大模型，这 2 种方式是同样的方式，同样适用于其他大模型。&lt;/p&gt;
&lt;p&gt;相对来说，Ollama 部署配置比较简单，目前常见的大模型均支持 Ollama 推理协议（包括：Qwen/Lllama/Phi 等大模型），推荐使用；同时，GGUF 部署方式仅需要依赖一个模型文件，使用 Llama.cpp 框架进行推理，依赖也少部署也很方便，同样推荐使用。如何抉择，就看我们自己喜好了！&lt;/p&gt;
&lt;p&gt;Gemma 2 在内最近发布的开源大模型，可以看出当前大模型研究的趋势，即探索用更轻量级、更实用的模型来实现更强的性能，并确保易部署，以更好地满足不同用户的需求。老牛同学觉得未来低成本、定制化的垂直场景小模型将会越来越多，也会越来越受欢迎！&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习交流进步 👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Phi-3 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/bNxHM3B7HOLNvJtjwvt8iw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Phi-3 模型手机部署教程（微软发布的可与 GPT-3.5 媲美的小模型）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Qwen2-7B 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/u_Uw88dpQRgbtfI4_1OOwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Qwen2 阿里最强开源大模型（Qwen2-7B）本地部署、API 调用和 WebUI 对话机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Llama-3-8B 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Llama 3 搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GLM-4-9B 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署 GLM-4-9B 清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ChatTTS 文本转语音模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API 使用和搭建 WebUI 界面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stable Diffusion 3 文生图模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Sax4z2k8Dvn82h15jf51Hw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Stable Diffusion 3 文生图“开源英雄”大模型本地部署和使用教程，轻松实现 AI 绘图自由&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大模型应用实战&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/vt1EXVWtwm6ltZVYtB4-Tg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用 Llama3/Qwen2 等开源大模型，部署团队私有化 Code Copilot 和使用教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/P_ufvz4MWVSqv_VM-rJp9w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;大模型应用研发基础环境配置（Miniconda、Python、Jupyter Lab、Ollama 等）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/m_O2OSoXWLL0PJurLCdzng&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;借助 AI 大模型，三分钟原创一部儿童故事短视频（附完整操作步骤）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python 小游戏&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hv2tE-yot_H04HCezxQWXg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI 已来，我与 AI 一起用 Python 编写了一个消消乐小游戏&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/tkTlt4rbFKQ73zudluPO1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python 游戏编程：一步步用 Python 打造经典贪吃蛇小游戏&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Phi-3 模型手机部署教程（微软发布的可与GPT-3.5媲美的小模型）</title>
        <link>https://ntopic.cn/p/2024062301/</link>
        <pubDate>Sun, 23 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024062301/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024062301/00.jpg" alt="Featured image of post Phi-3 模型手机部署教程（微软发布的可与GPT-3.5媲美的小模型）" /&gt;&lt;p&gt;前面几篇博文，老牛同学和大家一起在个人电脑部署了&lt;strong&gt;Qwen2&lt;/strong&gt;、&lt;strong&gt;GLM4&lt;/strong&gt;、&lt;strong&gt;Llama3&lt;/strong&gt;、&lt;strong&gt;ChatTTS&lt;/strong&gt;和&lt;strong&gt;Stable Diffusion&lt;/strong&gt;等 LLM 大模型，也通过 API 和 WebUI 的方式完成了体验。&lt;/p&gt;
&lt;p&gt;但是这些大模型因为部署在个人电脑本地，不能够随时携带。如果能在手机上部署大模型的话，老牛同学感觉很有意义，手机与我们的生活更为密切相关，并且手机上也有大量的个人数据，与大模型交互起来也更加方便。同时，在手机上跑个大模型，还是很酷！&lt;/p&gt;
&lt;p&gt;老牛同学期望能通过本文，和大家一起完成这项很酷且有意义的事情。老牛同学用的是&lt;strong&gt;小米 10 Pro&lt;/strong&gt;手机，其配置参数如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024062301/01.jpg&#34;
	width=&#34;1080&#34;
	height=&#34;2340&#34;
	srcset=&#34;https://ntopic.cn/p/2024062301/01_huf9de8c070f651996b22bfe488baf7e14_274937_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024062301/01_huf9de8c070f651996b22bfe488baf7e14_274937_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;老牛同学手机配置&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;46&#34;
		data-flex-basis=&#34;110px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;选择-phi-3-微软开源模型&#34;&gt;选择 Phi-3 微软开源模型&lt;/h2&gt;
&lt;p&gt;受限于手机 CPU 和内存等硬件配置，我们要选择小语言模型（SLM）。其中，阿里开源了&lt;strong&gt;Qwen2-0.5B&lt;/strong&gt;和&lt;strong&gt;Qwen2-1.5B&lt;/strong&gt;两款小尺寸模型，微软了开源&lt;strong&gt;Phi-3 Mini&lt;/strong&gt;（&lt;strong&gt;3.8B&lt;/strong&gt;）和&lt;strong&gt;Phi-3 medium&lt;/strong&gt;（&lt;strong&gt;14B&lt;/strong&gt;）两款尺寸模型。&lt;/p&gt;
&lt;p&gt;由于之前我们在笔记本部署了&lt;strong&gt;Qwen2-7B&lt;/strong&gt;大模型，本次我们就在手机部署&lt;strong&gt;Phi-3 Mini&lt;/strong&gt;模型，顺便也体验一下不同科技公司的大模型产品，其效果可以媲美&lt;strong&gt;GPT-3.5&lt;/strong&gt;大模型：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024062301/11.jpg&#34;
	width=&#34;1080&#34;
	height=&#34;1136&#34;
	srcset=&#34;https://ntopic.cn/p/2024062301/11_hufca9c8e53812d6de8d893ed0b898ab7f_336127_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024062301/11_hufca9c8e53812d6de8d893ed0b898ab7f_336127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Phi-3性能评测报告&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;95&#34;
		data-flex-basis=&#34;228px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Qwen2-7B&lt;/strong&gt;本地部署：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/u_Uw88dpQRgbtfI4_1OOwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Qwen2 阿里最强开源大模型（Qwen2-7B）本地部署、API 调用和 WebUI 对话机器人&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;手机配置-linux-环境termux-应用&#34;&gt;手机配置 Linux 环境（Termux 应用）&lt;/h2&gt;
&lt;p&gt;小米等安卓手机的基于 Linux 内核的操作系统，但是我们无法像在 Linux 那样执行 Linux 命令，因此我首先得配置一下 Linux 环境。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Termux&lt;/strong&gt;是一个 Android 的终端模拟器，可以在 Android 设备上运行 Linux 命令和工具。&lt;strong&gt;Termux&lt;/strong&gt;的 Android APP 可通过官网下载并安装：&lt;a class=&#34;link&#34; href=&#34;https://github.com/termux/termux-app/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/termux/termux-app/releases&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当前官网的最新稳定版本：&lt;code&gt;v0.118.1 - 2024-06-18 00.05&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024062301/02.jpg&#34;
	width=&#34;1792&#34;
	height=&#34;1368&#34;
	srcset=&#34;https://ntopic.cn/p/2024062301/02_hu8929c3d33f0597ba0060fb44fae62288_262616_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024062301/02_hu8929c3d33f0597ba0060fb44fae62288_262616_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Termux安装文件&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;130&#34;
		data-flex-basis=&#34;314px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;请根据手机情况，下载对应的 apk 文件。老牛同学下载的 apk 文件：&lt;strong&gt;termux-app_v0.118.1+github-debug_universal.apk&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;apk 安装成功后，打开&lt;strong&gt;Termux&lt;/strong&gt;应用后，默认展示如下，就可以开始输入 Linux 命令了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024062301/03.jpg&#34;
	width=&#34;1080&#34;
	height=&#34;2340&#34;
	srcset=&#34;https://ntopic.cn/p/2024062301/03_hu38b15bc0bda6dc964e79f04dbde22382_304569_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024062301/03_hu38b15bc0bda6dc964e79f04dbde22382_304569_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Termux应用界面&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;46&#34;
		data-flex-basis=&#34;110px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;手机上安装-linux-操作系统&#34;&gt;手机上安装 Linux 操作系统&lt;/h2&gt;
&lt;p&gt;首先，我们安装&lt;strong&gt;proot-distro&lt;/strong&gt;系统管理工具，&lt;strong&gt;proot-distro&lt;/strong&gt;可以非常方便在 Termux 中&lt;strong&gt;安装&lt;/strong&gt;、&lt;strong&gt;卸载&lt;/strong&gt;和&lt;strong&gt;运行&lt;/strong&gt;Linux 的发行版本（包括：Ubuntu、Debian、Arch Linux 等）：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;友情提示：&lt;/strong&gt; 在手机中输入以下命令效率比较低，我们可以把命令发到微信，然后一条一条复制粘贴！&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pkg install proot-distro
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;proot-distro&lt;/strong&gt; 安装成功之后，我们安装&lt;strong&gt;Debian&lt;/strong&gt;操作系统：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;proot-distro install debian
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024062301/04.jpg&#34;
	width=&#34;1080&#34;
	height=&#34;2340&#34;
	srcset=&#34;https://ntopic.cn/p/2024062301/04_huea1eb21800f85aa4f475e6e988978d89_1188837_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024062301/04_huea1eb21800f85aa4f475e6e988978d89_1188837_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Debian安装成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;46&#34;
		data-flex-basis=&#34;110px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;最后，登录新安装的&lt;strong&gt;Debian&lt;/strong&gt;操作系统：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;proot-distro login debian
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;登录之后，自动启动了&lt;strong&gt;Shell&lt;/strong&gt;命令行终端：&lt;code&gt;root@localhost:~#&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;可以执行相关的 Linux 命令了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024062301/05.jpg&#34;
	width=&#34;2340&#34;
	height=&#34;1080&#34;
	srcset=&#34;https://ntopic.cn/p/2024062301/05_hu503792de75c28e8bf910255688f0d100_334989_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024062301/05_hu503792de75c28e8bf910255688f0d100_334989_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Debian系统命令&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;216&#34;
		data-flex-basis=&#34;520px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;通过-termux-安装-phi-3-模型&#34;&gt;通过 Termux 安装 Phi-3 模型&lt;/h2&gt;
&lt;p&gt;通过上面的操作，我们已经在手机上安装好了&lt;strong&gt;Debian&lt;/strong&gt;操作系统，接下来在&lt;strong&gt;Debian&lt;/strong&gt;操作系统中安装&lt;strong&gt;Phi-3 Mini&lt;/strong&gt;模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一步：&lt;/strong&gt; 在&lt;strong&gt;Debian&lt;/strong&gt;系统中安装&lt;strong&gt;Ollama&lt;/strong&gt;软件，没错，就是之前在个人电脑部署&lt;strong&gt;Llama3&lt;/strong&gt;、&lt;strong&gt;Qwen2&lt;/strong&gt;等大模型时，用于管理本地大模型的&lt;strong&gt;Ollama&lt;/strong&gt;软件。由于我们在手机上安装了&lt;strong&gt;Debian&lt;/strong&gt;系统，那么和电脑一样，&lt;strong&gt;Ollama&lt;/strong&gt;也可以管理&lt;strong&gt;Debian&lt;/strong&gt;系统本地部署的大模型：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 安装Ollama软件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -fsSL https://ollama.com/install.sh &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Ollama&lt;/strong&gt;安装成功输出信息如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024062301/06.jpg&#34;
	width=&#34;1080&#34;
	height=&#34;2340&#34;
	srcset=&#34;https://ntopic.cn/p/2024062301/06_hu7a830a0b321e84a755d8d7c217322a1c_2010366_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024062301/06_hu7a830a0b321e84a755d8d7c217322a1c_2010366_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ollama安装成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;46&#34;
		data-flex-basis=&#34;110px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二步：&lt;/strong&gt; 通过&lt;strong&gt;后台&lt;/strong&gt;启动&lt;strong&gt;Ollama&lt;/strong&gt;服务：&lt;code&gt;nohup ollama serve &amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我们用&lt;strong&gt;Ollama&lt;/strong&gt;命令，查看 Ollama 信息，如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查看版本：&lt;code&gt;ollama -v&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;查看本地模型列表：&lt;code&gt;ollama list&lt;/code&gt;（目前还没有部署模型，因此结果列表为&lt;strong&gt;空&lt;/strong&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第三步：&lt;/strong&gt; 通过&lt;strong&gt;Ollama&lt;/strong&gt;安装并启动&lt;strong&gt;Phi-3 Mini&lt;/strong&gt;模型：&lt;code&gt;ollama run phi3:mini&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Phi-3 Mini&lt;/strong&gt;模型文件总大小为&lt;strong&gt;2.4GB&lt;/strong&gt;左右，因此下载需要一点时间：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024062301/07.jpg&#34;
	width=&#34;1080&#34;
	height=&#34;2340&#34;
	srcset=&#34;https://ntopic.cn/p/2024062301/07_hu3cf50d426911112bcdb0ac26d4ee1b8e_565757_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024062301/07_hu3cf50d426911112bcdb0ac26d4ee1b8e_565757_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Phi-3 Mini安装成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;46&#34;
		data-flex-basis=&#34;110px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;到此，&lt;strong&gt;Phi-3 Mini&lt;/strong&gt;模型部署成功，我们可以体验手机上的大模型，比如：&lt;strong&gt;请用 100 个汉字解释一下，天空为什么是蓝色的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024062301/08.jpg&#34;
	width=&#34;1144&#34;
	height=&#34;1160&#34;
	srcset=&#34;https://ntopic.cn/p/2024062301/08_hua04b28422bbb4c6a12cc5f607adbb1af_300229_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024062301/08_hua04b28422bbb4c6a12cc5f607adbb1af_300229_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Phi-3 Mini模型推理&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;98&#34;
		data-flex-basis=&#34;236px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;相比电脑端，手机的算力弱太多，就算老牛同学用的是最小尺寸的模型（&lt;strong&gt;Phi-3 Mini&lt;/strong&gt;），其推理的速度还是慢得多。其内容的输出速度，比我手机打字都要慢。盯着屏幕，看着模型一个字一个字的输出，感觉也挺有趣 😁&lt;/p&gt;
&lt;p&gt;目前 AI 是大热门，各大公司推出的大模型参数一个比一个大，能力一个比一个厉害。但大模型训练和推理成本均比较高昂，在很大程度上限制了其发展，因此大模型 AI 应用相对较少，或者说对我们生活影响还很小，因此其还有很大的发展空间。&lt;/p&gt;
&lt;p&gt;而反观针对特定业务场景定制的小模型（比如&lt;strong&gt;Phi&lt;/strong&gt;定制等），其成本就低得多，就能更有效地应用于各种垂直场景。&lt;/p&gt;
&lt;p&gt;老牛同学觉得这种“&lt;strong&gt;小而美&lt;/strong&gt;”的 AI 模型将会越来越多，也会越来越受欢迎！&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步 👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Qwen2-7B 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/u_Uw88dpQRgbtfI4_1OOwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Qwen2 阿里最强开源大模型（Qwen2-7B）本地部署、API 调用和 WebUI 对话机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Llama-3-8B 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于 Llama 3 搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GLM-4-9B 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署 GLM-4-9B 清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ChatTTS 文本转语音模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API 使用和搭建 WebUI 界面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stable Diffusion 3 文生图模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Sax4z2k8Dvn82h15jf51Hw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Stable Diffusion 3 文生图“开源英雄”大模型本地部署和使用教程，轻松实现 AI 绘图自由&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大模型应用案例&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/m_O2OSoXWLL0PJurLCdzng&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;借助 AI 大模型，三分钟原创一部儿童故事短视频（附完整操作步骤）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python 小游戏&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hv2tE-yot_H04HCezxQWXg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI 已来，我与 AI 一起用 Python 编写了一个消消乐小游戏&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/tkTlt4rbFKQ73zudluPO1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python 游戏编程：一步步用 Python 打造经典贪吃蛇小游戏&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AI资讯·0622] Claude3.5超越GPT-4o，360推出AI搜索，OpenAI收购Rockset，华为发布大模型</title>
        <link>https://ntopic.cn/p/ai20240622/</link>
        <pubDate>Sat, 22 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240622/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240622/00.jpg" alt="Featured image of post [AI资讯·0622] Claude3.5超越GPT-4o，360推出AI搜索，OpenAI收购Rockset，华为发布大模型" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;「网红」周鸿祎，要为 AI 带货&lt;/li&gt;
&lt;li&gt;突发！OpenAI收购数据公司&lt;/li&gt;
&lt;li&gt;盘古5.0重磅发布！华为云大模型年度杀招来了，人形机器人现场整活&lt;/li&gt;
&lt;li&gt;GPT-4o一夜被赶超！Anthropic推出Claude 3.5，网友3分钟克隆马里奥游戏&lt;/li&gt;
&lt;li&gt;中国人自己的操作系统！余承东掏出纯血鸿蒙，华为AI大招硬刚苹果&lt;/li&gt;
&lt;li&gt;Claude3.5突然发布！GPT-4o不香了&lt;/li&gt;
&lt;li&gt;无论真实还是AI视频，「摩斯卡」都能重建恢复4D动态可渲染场景&lt;/li&gt;
&lt;li&gt;抢疯了，腾讯给大模型人才，定了一个前所未有的标准&lt;/li&gt;
&lt;li&gt;华为发布会杀疯了：盘古大模型跳级发布，编程语言仓颉首次亮相&lt;/li&gt;
&lt;li&gt;美政府再发AI禁令！限制美国人对华AI技术和产品投资&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;网红周鸿祎要为-ai-带货&#34;&gt;「网红」周鸿祎，要为 AI 带货&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240622/ai20240622-158.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240622/ai20240622-158_huf20e0a43bd8a54953a572be4309608ac_109571_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240622/ai20240622-158_huf20e0a43bd8a54953a572be4309608ac_109571_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;「网红」周鸿祎，要为 AI 带货&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;360集团创始人周鸿祎再次成为公众焦点，通过推出AI搜索、AI浏览器及AI甄选平台，旨在重塑国民级产品搜索与浏览器领域，并助力优秀中国AI产品的普及。周鸿祎强调不做“网红”，而是打造企业家IP以推广360品牌和优质中国产品。在AI战略中，360选择既做模型又做有强场景属性的应用，同时搭建桥梁连接用户与AI工具。其AI搜索采用多轮搜索技术，优化用户体验，并提供丰富多媒体内容及个性化服务；AI浏览器则升级为一站式AI问题解决工具箱，内置划重点、提炼简介等功能，支持视频全文生成、双语观看、网页转PPT等高效操作。此外，360AI甄选平台汇集了360自家产品、知名公司应用以及独立开发者作品，旨在降低普通用户接触AI的门槛，并通过周鸿祎个人流量为这些优秀AI工具提供曝光机会。此举不仅推动了AI在个人和中小企业端的应用发展，也为中国AI应用生态提供了重要支持。综上所述，360集团通过创新产品和服务，致力于成为新时代AI入口与普及者，旨在让普通人以低成本接触并使用AI技术，同时扶持国内AI开发者与应用生态。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4TGB5NH05119FMA.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;突发openai收购数据公司&#34;&gt;突发！OpenAI收购数据公司&lt;/h2&gt;
&lt;p&gt;OpenAI宣布收购实时分析数据库公司Rockset，以增强其产品中对实时数据的利用和访问能力，目标是支持更复杂的应用如实时推荐、动态聊天机器人、实时监控等，并扩大AI技术应用范围。收购旨在使AI更好地理解和操作数据，通过Rockset的技术实现数据分析速度的提升及成本降低。Rockset成立于2016年，提供快速搜索和分析数据库服务，曾获得多轮融资总额逾1亿美元。收购后，Rockset团队将加入OpenAI，共同推动AI与实时数据处理的融合创新。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J59ALCIN051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;盘古50重磅发布华为云大模型年度杀招来了人形机器人现场整活&#34;&gt;盘古5.0重磅发布！华为云大模型年度杀招来了，人形机器人现场整活&lt;/h2&gt;
&lt;p&gt;华为发布盘古大模型5.0，主打“云+端”独有策略及行业难题解决能力。该模型实现参数规格全覆盖，从十亿级到万亿级，支持多模态理解和生成，展现强思维与复杂推理能力。华为云同步发布了六大行业模型，如盘古钢铁、高铁、具身智能等，并提供升级服务，包括昇腾AI云、ModelArtsstudio、CodeArts等生产线的优化，以及首次揭秘的技术点，旨在打造“世界模型”，全面重塑云服务，助力解决行业难题。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J587U3NR051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;gpt-4o一夜被赶超anthropic推出claude-35网友3分钟克隆马里奥游戏&#34;&gt;GPT-4o一夜被赶超！Anthropic推出Claude 3.5，网友3分钟克隆马里奥游戏&lt;/h2&gt;
&lt;p&gt;一夜之间，Anthropic推出了新一代大模型Claude3.5Sonnet，在多项全球权威测评中超越了OpenAI的GPT-4o。Claude在推理、知识、编码能力及速度成本方面表现优异，刷新行业基准。用户可通过Claude网页和iOS程序免费试用，付费用户能更高速访问。AnthropicAPI、AmazonBedrock和GoogleCloud提供该模型，收费标准合理。Claude3.5Sonnet立即引起轰动，网友称其编程效率比GPT-4o高10倍，实现马里奥游戏克隆版仅需3分钟。Anthropic被视为OpenAI的有力竞争对手，Claude系列新品发布是对GPT-4o的直接挑战。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J57U4DTM051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;中国人自己的操作系统余承东掏出纯血鸿蒙华为ai大招硬刚苹果&#34;&gt;中国人自己的操作系统！余承东掏出纯血鸿蒙，华为AI大招硬刚苹果&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240622/ai20240622-166.jpg&#34;
	width=&#34;796&#34;
	height=&#34;498&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240622/ai20240622-166_hu556af553b923f839011f4bc12df64491_121175_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240622/ai20240622-166_hu556af553b923f839011f4bc12df64491_121175_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;中国人自己的操作系统！余承东掏出纯血鸿蒙，华为AI大招硬刚苹果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;纯血鸿蒙，华为HarmonyOSNEXT，中国自研操作系统新里程碑；余承东称其为中国内核制造历史转折点，10年成就欧美同行30年的成果。系统全面升级，性能提升30%，分布式软总线技术优化连接速度与功耗。强调人机交互、个性化专属和全场景智能，AI“核弹”HarmonyIntelligence震撼发布，AI生图、修复、多模态助手等能力嵌入系统，现场反响热烈。华为鸿蒙原生应用进入冲刺阶段，Beta版正式面向开发者启动，集结号吹响。生态设备数量已破9亿台，涵盖手机、平板、电视及车机等领域。终端AI技术成熟，NPU智能手机早于2017年发布，小艺用上大模型。华为发布自研编程语言“仓颉”，全场景、高性能、高安全特点明显，并提供AI辅助编程工具给开发者使用。全球首个端侧AI手机公司，代码行数达到1.1亿，华为贡献6200多万行。鸿蒙生态开发者数量已达254万人，OpenHarmony代码行数超过1.1亿，支持900多个服务意图框架，覆盖重点垂直领域的200多种意图。AI声音修复功能为语言障碍人群带来便利，小艺智能体知识量达万亿tokens，记忆感知场景超23个，推理成功率高。华为鸿蒙系统面向全场景智能操作系统升级，强调与苹果的对比，展现出遥遥领先的优势。5.5G商用元年到来，华为作为核心推动者和建设者。AI大模型赋能终端，万物互联时代全球链接设备数量将达2000亿部。HarmonyOSNEXT实现一个系统统一生态，手机、平板、手表及各类IoT设备皆可使用。鸿蒙原生智能强调新交互、个性化专属与全场景智能，与苹果“五大AI原则”有共通之处，如强调个性化和广泛适用性。华为承诺2024年第四季度正式版落地华为产品线。此次开发者大会，华为不仅展示了强大的自研能力，还发布了面向未来的操作系统创新和技术突破，展现出在AI领域的深度探索和应用，为全行业带来了新的期待与挑战。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J57NBFEJ051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;claude35突然发布gpt-4o不香了&#34;&gt;Claude3.5突然发布！GPT-4o不香了&lt;/h2&gt;
&lt;p&gt;Anthropic发布了Claude3.5Sonnet，首个3.5系列版本，在关键指标上超越GPT-4o，速度是前版两倍，成本仅五分之一。免费试用网页端和iOS程序，Pro订阅者享受更高速率限制。API价格：每百万输入Tokens3美元，输出Tokens15美元，200KTokens上下文窗口。年内还将发布Claude3.5Haiku和Claude3.5Opus。为安全测试严格把关。用户反馈代码能力惊艳，文本处理达研究生水平推理、本科生知识和编码标准，视觉能力最强，所有任务均超越前版。新功能Artifacts提供动态工作区，实时生成文档、代码、图像等，标志Claude从对话AI向协作工作环境进化。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J55TBQM10511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;无论真实还是ai视频摩斯卡都能重建恢复4d动态可渲染场景&#34;&gt;无论真实还是AI视频，「摩斯卡」都能重建恢复4D动态可渲染场景&lt;/h2&gt;
&lt;p&gt;本文介绍了一种名为MoSca的新系统，旨在从单目视频中重建可渲染的动态场景。MoSca利用神经信息处理技术，无需额外信息，能生成三维动态模型，适用于互联网上的各种视频内容。该系统克服了真实拍摄二维视频缺乏多视角信息和动态场景自由度高带来的挑战。MoSca采用了一种四维运动脚手架表示方法，通过融合基石模型输出的深度估计、长时间跟踪、光流估计等数据，简化复杂度高的动态变形问题。这种方法允许从单目视频中高效地恢复出物理世界的信息，并进行全局融合观测。实验结果显示，MoSca在多种数据集上表现优异，特别是在重建动态场景时展现出优越性能，支持高质量渲染并优于其他方法。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J57O1MV70511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;抢疯了腾讯给大模型人才定了一个前所未有的标准&#34;&gt;抢疯了，腾讯给大模型人才，定了一个前所未有的标准&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240622/ai20240622-170.jpg&#34;
	width=&#34;1080&#34;
	height=&#34;555&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240622/ai20240622-170_hu13da32116ed11aa70a4c6f54936fcc82_81313_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240622/ai20240622-170_hu13da32116ed11aa70a4c6f54936fcc82_81313_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;抢疯了，腾讯给大模型人才，定了一个前所未有的标准&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;467px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;科技公司竞争核心在于持续吸引顶尖AI人才，尤其是生成式AI领域的专家。OpenAI的成功归因于多年的技术探索、资金支持以及聚集的顶级AI研究人员。国内同样涌现了一批怀揣理想和技术热情的专业人士，致力于中文原生大模型的研发和优化，力求在世界范围内领先。以高研为例，他从学术研究转向实际应用，在腾讯参与并推动了混元大模型项目的研发，实现了文生图能力的重大突破，开源的混元-DiT模型在视觉生成效果上显著提升。傅志远则将AI应用于游戏体验优化，通过强化学习和多智能体系统的研究，改进游戏功能，并提高用户体验。王艾文专注于AIforScience领域，特别是在蛋白质组学研究中取得了重要成果，为科学发现提供了新视角。腾讯青云计划加大了对大模型领域人才的招募力度，强调长期价值，提供极具竞争力的条件吸引全球顶尖学子，旨在推动中国在大模型技术领域的快速发展和创新。整体而言，科技公司通过培养和吸纳AI人才，促进技术创新与应用落地，不仅推动了自身的发展，也助力国家层面的技术实力提升。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J57DQQQC0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;华为发布会杀疯了盘古大模型跳级发布编程语言仓颉首次亮相&#34;&gt;华为发布会杀疯了：盘古大模型跳级发布，编程语言仓颉首次亮相&lt;/h2&gt;
&lt;p&gt;华为发布盘古大模型5.0，涵盖十亿、百亿、千亿、万亿四种规模，强调多模态和强思维能力。现场演示搭载盘古的人形机器人完成复杂任务与学习场景，并应用于自动驾驶领域，生成符合物理规律的训练视频。鸿蒙系统也采用最新盘古大模型，增强智慧助手小艺的多模态能力。此外，华为揭秘盘古背后技术细节，包括数据、架构π和训练方法。盘古5.0四大升级点：覆盖不同应用需求、提升多模态理解与生成、强化思维链与策略搜索、在工业设计与建筑设计等领域展现广泛应用。鸿蒙系统进行全面升级，采用全新端云垂直整合架构，性能显著提升，并推出仓颉编程语言，面向全场景应用开发。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J59GBOP60511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;美政府再发ai禁令限制美国人对华ai技术和产品投资&#34;&gt;美政府再发AI禁令！限制美国人对华AI技术和产品投资&lt;/h2&gt;
&lt;p&gt;美国财政部宣布新禁令，禁止美国人对特定AI系统及使用特定计算能力的终端用途进行投资，即使在开发未被禁止的AI系统或芯片相关交易时也需上报。此政策旨在应对国家安全技术与产品上的投资，并针对半导体、量子信息技术和人工智能领域实施监管。具体细则将在8月4日后公布。该禁令是去年拜登签署的第14105号行政命令的执行，旨在限制中国在特定技术领域的投资活动，以防止资金流入可能威胁美国安全的技术发展。违反规定者将面临刑事和民事处罚，并可能撤销相关投资。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J59PI7UM0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Qwen2-7B 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/u_Uw88dpQRgbtfI4_1OOwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Qwen2 阿里最强开源大模型（Qwen2-7B）本地部署、API调用和WebUI对话机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Llama-3-8B 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GLM-4-9B 开源大模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ChatTTS 文本转语音模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API使用和搭建WebUI界面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stable Diffusion 3 文生图模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Sax4z2k8Dvn82h15jf51Hw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Stable Diffusion 3 文生图“开源英雄”大模型本地部署和使用教程，轻松实现AI绘图自由&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大模型应用案例&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/m_O2OSoXWLL0PJurLCdzng&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;借助AI大模型，三分钟原创一部儿童故事短视频（附完整操作步骤）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python 小游戏&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hv2tE-yot_H04HCezxQWXg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI已来，我与AI一起用Python编写了一个消消乐小游戏&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/tkTlt4rbFKQ73zudluPO1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python游戏编程：一步步用Python打造经典贪吃蛇小游戏&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AI资讯·0618] 快手AI模型可灵在质量优于Sora，OpenAI和谷歌发布新技术推动AI视频推理发展，Gemini1.5Pro在该榜单中表现突出</title>
        <link>https://ntopic.cn/p/ai20240618/</link>
        <pubDate>Mon, 17 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240618/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240618/ai20240618-156.jpg" alt="Featured image of post [AI资讯·0618] 快手AI模型可灵在质量优于Sora，OpenAI和谷歌发布新技术推动AI视频推理发展，Gemini1.5Pro在该榜单中表现突出" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;陕西推出AI千亿级发展计划，五大产业集群，智算超3000P&lt;/li&gt;
&lt;li&gt;试了快手的视频AI，竟然有点领先&lt;/li&gt;
&lt;li&gt;“技术故障”背刺巴菲特，金融大模型到底靠不靠谱？&lt;/li&gt;
&lt;li&gt;Gemini视频推理遥遥领先GPT-4o，首个视频多模态基准Video-MME&lt;/li&gt;
&lt;li&gt;国产视频大模型PixVerse发布运动笔刷，网友：效果超Runway&lt;/li&gt;
&lt;li&gt;AI研究的主要推动力是什么？ChatGPT团队科学家：算力成本下降&lt;/li&gt;
&lt;li&gt;LLM最全「怪癖」首曝光！马里兰OpenAI等30+学者祭出75页提示报告&lt;/li&gt;
&lt;li&gt;大模型「幻觉」全无？图神经网络成破解核心，精准预测因果消除「幻觉」&lt;/li&gt;
&lt;li&gt;为什么你的 iPhone，肯定用不上「苹果 AI」？&lt;/li&gt;
&lt;li&gt;答案抽取正确率达96.88%，xFinder断了大模型「作弊」的小心思&lt;/li&gt;
&lt;li&gt;3D 版 SORA 来了！DreamTech 推出全球首个原生 3D-DiT 大模型&lt;/li&gt;
&lt;li&gt;中国版Sora级视频大模型发布，打造“视频-Native”超级应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;陕西推出ai千亿级发展计划五大产业集群智算超3000p&#34;&gt;陕西推出AI千亿级发展计划，五大产业集群，智算超3000P&lt;/h2&gt;
&lt;p&gt;陕西省推出《加快推动人工智能产业发展实施方案（2024-2026年）》，旨在通过建设产业园、突破核心技术、打造产业集群等措施，实现人工智能产业的高质量发展。目标包括建设多个产业园区、引入国家级重点项目、新增制造业企业通过DCMM贯标认证等。方案聚焦算力供给、数据集成与大模型布局，实施“强基、创智、赋智、聚智”四大行动，以提升技术底座、培育主体、优化生态，并将陕西打造为具有重要影响力的人工智能产业聚集地。具体措施涉及强化算力、扩大数据供应、布局通用和行业大模型等，同时推动创新产品研发与成果转化，实现制造业全流程智能化升级。方案还规划建设产业集聚区，培育优势企业，并提供保障措施，包括统筹协调机制、试点示范推广、完善支撑体系及强化安全保障，以促进人工智能与实体经济深度融合，赋能新型工业化发展。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4GTGC5M051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;试了快手的视频ai竟然有点领先&#34;&gt;试了快手的视频AI，竟然有点领先&lt;/h2&gt;
&lt;p&gt;快手新AI模型&amp;quot;可灵&amp;quot;在外网火了，与Sora同台竞技，表现亮眼。在蚂蚁爬行、拉力赛车等场景中，可灵生成视频质量高，细节处理优于Sora。此外，可灵对中国元素理解更佳，适合中国用户。LumaAI同样能生成高质量两分钟视频，并有“电影感”和图片+提示词生成视频的功能。两款AI在吃播、电影感、物理世界理解等方面各有千秋，但快手的可灵AI在效果稳定性上表现更优。快手通过模仿Sora的技术路线并采用DiT架构提升模型性能，在视频数据丰富的背景下，实现了较好的效果。然而，商业化问题成为AI发展的瓶颈，大部分厂商难以找到盈利模式，高昂的成本和会员收费并未覆盖成本。尽管如此，快手凭借自身平台优势，可灵AI有潜力探索新的商业模式，如“发帖助手”等定位可能带来流量和收入。本文对两款AI进行了详细对比，并分析了AI发展面临的商业化挑战及快手的潜在机会。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4SN3TV6051196HN.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;技术故障背刺巴菲特金融大模型到底靠不靠谱&#34;&gt;“技术故障”背刺巴菲特，金融大模型到底靠不靠谱？&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240618/ai20240618-146.jpg&#34;
	width=&#34;640&#34;
	height=&#34;349&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240618/ai20240618-146_hud6eb3fe3e30583cc6b8245cea625e226_263098_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240618/ai20240618-146_hud6eb3fe3e30583cc6b8245cea625e226_263098_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;“技术故障”背刺巴菲特，金融大模型到底靠不靠谱？&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;440px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;金证科技携手英特尔打造金融领域大模型推理方案，通过组合式AI（大模型+小模型+工具）解决金融业务需求，K-GPT等大模型在特定任务中展现优势，同时优化成本与资源利用。英特尔至强®CPUMax系列处理器提供高带宽内存和内置英特尔®高级矩阵扩展引擎，大幅提高计算性能，支持高效推理和大规模矩阵运算。金证通过与英特尔合作，实现硬件、软件优化的深度融合，为金融行业应用大模型树立标杆，助力金融机构数字化转型，并在科技节中展示了AI技术的实际应用前景。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4TD7SB80511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;gemini视频推理遥遥领先gpt-4o首个视频多模态基准video-mme&#34;&gt;Gemini视频推理遥遥领先GPT-4o，首个视频多模态基准Video-MME&lt;/h2&gt;
&lt;p&gt;OpenAI和谷歌发布的新技术将AI视频推理推向新高度，但缺少全面评估大模型视频推理能力的标准。为弥补这一空白，Video-MME基准应运而生，全面评估多模态大模型的综合视频理解能力，并得到业界认可。Gemini1.5Pro在该榜单中表现突出，在视频理解和处理上占据主导地位，其性能超越了GPT-4o和GPT-4V/o等其他模型。Video-MME基准特点包括：覆盖不同长度、类型和模态的视频数据集，采用全人工标注确保高质量；评估时间维度广泛性、数据模态丰富性和视频类型的多样性。实验结果显示Gemini1.5Pro在长视频理解上表现优异，并支持音频输入，优于其他开源模型如VILA-1.5。尽管当前多模态大模型在长视频理解方面仍有进步空间，Video-MME基准的推出为评估和改进这些模型提供了重要工具。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4TCMD9V0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;国产视频大模型pixverse发布运动笔刷网友效果超runway&#34;&gt;国产视频大模型PixVerse发布运动笔刷，网友：效果超Runway&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240618/ai20240618-149.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240618/ai20240618-149_hu9efa8f5bad54b1fdb648cb2922b5e45a_305747_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240618/ai20240618-149_hu9efa8f5bad54b1fdb648cb2922b5e45a_305747_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;国产视频大模型PixVerse发布运动笔刷，网友：效果超Runway&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;MagicBrush运动笔刷工具因其能够精准控制视频元素运动方式、提升用户操作灵活性和可控性，在AI视频社区备受关注。该工具允许用户通过涂抹区域和绘制轨迹来调整视频中的物体动作，类似“神笔马良”的效果，实现在生成视频时如同修图般的精细操控。PixVerse是继Runway之后第二家发布类似功能的AI视频生成公司，其MagicBrush运动笔刷在多主体控制、画面含义理解等方面表现出色。用户能通过该工具实现多目标精准移动、遵循物理规律创造生动自然的场景，并且比Runway更灵活地绘制运动轨迹和自定义方向与距离。爱诗科技CEO王长虎在智源大会上介绍，PixVerse采用多种技术路线探索文生视频模型生成，包括Diffusion+Unet架构以及DiT架构。同时，公司着重于提升视频可控性，通过角色一致性（C2V）功能优化图像保真度和美学质量，并研发MagicBrush网络结构以简化交互层面并提高运动控制精度。爱诗科技专注于解决用户实际需求，如推出C2V功能实现连续、可控的视频生成，以及MagicBrush运动笔刷功能。这些创新使得PixVerse在竞争激烈的AI视频生成市场中脱颖而出，吸引了大量用户的积极反馈和使用，其产品用户体验和效果得到显著提升。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4T6F0A70512MLBG.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai研究的主要推动力是什么chatgpt团队科学家算力成本下降&#34;&gt;AI研究的主要推动力是什么？ChatGPT团队科学家：算力成本下降&lt;/h2&gt;
&lt;p&gt;AI研究的主要推动力是计算成本呈指数级下降及规模扩展。HyungWonChung通过分析Transformer的发展历史，阐述了编码器-解码器与仅解码器架构之间的差异及其对AI研究的意义。找到主要推动力后，理解它对于预测AI未来至关重要。Chung强调回顾过去架构的重要性，旨在提供一个统一视角，揭示哪些结构可能最终被规模扩展取代。他指出AI社区在添加结构方面做得很好，但在移除结构方面还需更多关注。计算成本的下降推动了AI研究的发展，使得更少结构的模型更具扩展性。通过理解历史中的关键结构选择及其原因，可以更好地洞察从过去到现在的变化，并据此预测未来方向。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4T4PO9P0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;llm最全怪癖首曝光马里兰openai等30学者祭出75页提示报告&#34;&gt;LLM最全「怪癖」首曝光！马里兰OpenAI等30+学者祭出75页提示报告&lt;/h2&gt;
&lt;p&gt;大语言模型(LLM)的提示技术研究揭示了其行为的怪异特性：重复内容可显著提高性能，而匿名化人名则导致准确性下降。马里兰大学等12所机构的30多位研究人员对LLM提示进行了大规模系统研究，发布了一篇详尽报告，覆盖4,797条记录筛选出1,565篇相关论文。报告中指出，奇奇怪怪的大语言模型在生成式AI行业中存在一些未被充分理解的现象。研究发现了以下现象：-重复内容：某些提示中的重复信息能显著提升LLM的性能。-包含人名：在提示中提及具体人物名字对准确性有重要影响。-示例选择与顺序敏感性：示例的选择和排列顺序对LLM的表现至关重要，甚至可能使准确率大幅波动。此外，研究还探讨了代码辅助推理、文本提示技术分类（如少样本学习、零样本推理等）、多语言和多模态提示方法。报告提出了一种全面的分类框架，并强调了在设计提示时的关键决策点。研究提出了提示工程过程，包括数据集上的推理、性能评估与提示模板修改三个步骤。还回顾了用于自动优化提示的技术策略，如答案工程，以及针对标注任务的LLM输出注释结果分析。报告总结了最常用的提示技术，指出少样本学习、零样本推理、高质量上下文提示示例和自洽等方法使用频率较高。同时，多模态提示也得到了发展，涵盖了图像、视频等不同形式的数据处理策略。这项研究为理解LLM的提示技术提供了全面视角，并揭示了这些模型在特定条件下的行为模式与敏感点。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4SURV8C0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;大模型幻觉全无图神经网络成破解核心精准预测因果消除幻觉&#34;&gt;大模型「幻觉」全无？图神经网络成破解核心，精准预测因果消除「幻觉」&lt;/h2&gt;
&lt;p&gt;AI初创公司Alembic宣布推出全新AI系统，彻底解决了大模型生成虚假信息的问题，实现了消除&amp;quot;幻觉&amp;quot;的目标。该系统能够在企业数据集中识别随时间变化的因果关系，而非仅限于相关性，确保输出确定性和谈论因果关系的能力。此前，AI模型在生成看似逼真文本时常产生错误或无意义信息，成为企业应用的主要障碍。Alembic通过安全可靠的技术手段，使AI系统能够从各种数据源摄取信息，并处理&amp;quot;可观测性和分类器&amp;quot;模块和几何数据组件。结果输入因果图神经网络（GNN），生成确定性预测及战略建议。公司建立了超级计算机基础设施并开发了新数字技术，将企业数据表示为时间感知图神经网络，以捕捉事件与数据点随时间形成的关联。AlembicAI不仅学习模式和相关性，还能识别推动业务成果的因果关系，高度预测未来行动影响，并推荐实现目标的最佳干预措施。展示分析复杂数据生成战略建议的过程表明了其技术实力。Alembic在财富500强企业中受到浓厚兴趣，获得Nvidia公司博士专家及未公开大客户认可，显示出市场潜力。然而，该公司面临挑战证明最终技术成果能超越早期试点，为大型企业提供准确结果。&amp;ldquo;无幻觉&amp;quot;方法可能成为关键卖点，也可能揭示研究突破与实际影响之间差距的警示故事。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4SUPGQ40511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;为什么你的-iphone肯定用不上苹果-ai&#34;&gt;为什么你的 iPhone，肯定用不上「苹果 AI」？&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240618/ai20240618-153.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240618/ai20240618-153_hu2051965c750be1d0aea689c47084f3ca_103769_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240618/ai20240618-153_hu2051965c750be1d0aea689c47084f3ca_103769_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;为什么你的 iPhone，肯定用不上「苹果 AI」？&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;硬件限制导致老款iPhone无法使用新AI功能。苹果追求设备上的隐私处理策略，强调在用户设备上直接执行AI任务以保护数据安全。AI模型需要足够的RAM空间运行，而老款手机的内存限制是主要问题之一。苹果AI功能仅限于特定机型，如新款iPhonePro系列及配备M1或更新芯片的iPad和Mac。尽管有理论上的逆向工程让部分AI功能在非标准硬件上运行，但实际效果有限。未来是否所有AI功能都能兼容更广泛的设备仍有待验证，预计首批AI功能将在iOS18发布时与新款iPhone一同推出，届时用户将能亲自体验苹果AI的实际价值和效果。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4SQVLCI05119FMA.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;答案抽取正确率达9688xfinder断了大模型作弊的小心思&#34;&gt;答案抽取正确率达96.88%，xFinder断了大模型「作弊」的小心思&lt;/h2&gt;
&lt;p&gt;大语言模型（LLM）发展迅速，引发了对公平性与可靠性的讨论。当前主要评估框架如OpenCompass等推动了进步，但专注于核心组件可信度的团队较少。上海算法创新研究院和中国人民大学的研究团队发布《xFinder》论文，深入分析LLM评估流程，重点评估答案抽取器在可靠性与一致性方面的表现。论文指出现有方法依赖正则表达式（RegEx）进行答案抽取，最佳准确率仅为74.38%，且容易被拟合影响结果。为解决这一问题，《xFinder》提出了一种新模型，具备高度鲁棒性，能更准确地抽取关键答案，显著优于当前最佳框架中的RegEx方法，并支持多样化题型评估。实现过程包括生成LLM响应、构建KAF数据集和训练xFinder。团队构建了包含26,900个训练样本的KAF数据集，用于有效训练模型。实验结果显示，在不同任务上，xFinder-qwen1505的平均提取准确率高达96.88%，远超最佳评估框架中的RegEx方法，并显著优于GPT-4。此外，《xFinder》在现实世界场景中对多种LLM进行了评估，证实了其高鲁棒性和泛化能力。实验揭示了关键发现：不同模型在不同框架下的排名差异大、xfinder一致性高、直接使用选项文本能提升排名的一致性。《xFinder》通过优化关键答案提取模块，显著提高了LLM评估的准确性和可靠性，并展现出了高度鲁棒性和泛化能力。未来研究将继续优化此方法并探索其他评估领域，为LLM性能评估提供更可靠的基础。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4T77AK10511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;3d-版-sora-来了dreamtech-推出全球首个原生-3d-dit-大模型&#34;&gt;3D 版 SORA 来了！DreamTech 推出全球首个原生 3D-DiT 大模型&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240618/ai20240618-156.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240618/ai20240618-156_hu39aaad0348e76c82767de365e5ef36d5_46223_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240618/ai20240618-156_hu39aaad0348e76c82767de365e5ef36d5_46223_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;3D 版 SORA 来了！DreamTech 推出全球首个原生 3D-DiT 大模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;全球首个原生三维生成大模型Direct3D由DreamTech发布，并公开了相关学术论文《直接立方体：通过三维潜扩散转换器的可扩展图像到三维生成》。Direct3D解决了高质量三维内容生成难题，采用3DDiffusionTransformer（3D-DiT）技术路线，不经过中间2D阶段直接生成三维模型。与传统2D-to-3Dlifting方法相比，Direct3D在原理上具有优势，但面临高效3D模型表征、训练架构和高质量大规模3D训练数据的挑战。Direct3D通过创新提出类似OpenAISORA的3DVAE来提取特征，采用改进优化后的DiT架构，并结合DreamTech自研的数据合成引擎生成大量高质量3D数据。实验验证显示，Direct3D在三维模型生成质量上超越主流2D升维方法，主要得益于高效表征、对齐模块和使用大规模高质量3D数据。技术架构上，Direct3D采用与OpenAISORA相似的DiT架构，符合ScalingLaw原则，通过增加参数量和训练数据量提升智能程度。在大语言模型、图像生成和视频生成领域中均得到验证。Direct3D是全球首个公开的3D内容生成方向上的DiT实践，展示了原生3D技术路线的优势。随着Direct3D推出，3D生成领域进入商用时代。与传统方案相比，Direct3D生成的3D模型质量达到商用级别，解决了几何结构、精度、表面细节和mesh面片数量等问题，适用于家用及工业打印机。模型参数量增加后，3D生成可应用于更多行业。基于Direct3D大模型，DreamTech推出了面向C端用户的Animeit!和面向创作者的3D内容创作平台两款尝鲜产品。Animeit!将用户输入转换为高质量二次元风格的3D人物形象，并具备骨骼节点用于动作绑定。另一款产品让用户通过文本描述或上传图片在短时间内获得高质量3D模型。DreamTech专注于3DAI技术，致力于提升全球AIGC创作者及消费者的体验，目标打造与真实世界无缝对接、实时互动的4D时空体验，实现通用人工智能（AGI）。公司汇集了全球顶尖AI人才，核心团队由英国两院院士、国家级青年人才以及多位深圳市高层次人才组成。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4T3B1FC0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;中国版sora级视频大模型发布打造视频-native超级应用&#34;&gt;中国版Sora级视频大模型发布，打造“视频-Native”超级应用&lt;/h2&gt;
&lt;p&gt;全球视频生成领域迎来新突破，中国首个超长时长、高性价比大模型“视界一粟YiSu”发布，标志着视频生成技术进入快速爆发期。此款模型在性能与成本之间达到极致平衡，拥有16秒原生超长时长，可生成至1分钟以上，具备强大运动表现力和物理世界理解能力。通过融入LLM和扩散模型的自研架构，极大优化了多模态融合、训练及推理效率，并实现了模型效果的极致优化。视界一粟YiSu基于极佳科技自研技术路线，超越DiT（DiffusionTransformer）基础，结合LLM与扩散模型优势，提供视频生成最佳方案。这一模型有望推动AI-Native和视频-Native爆款应用的诞生，为用户提供AI时代前所未有的体验价值。面向通用智能时代，视界一粟YiSu将加速实现长视频生成的大规模产品应用，其数据引擎能力对自动驾驶、通用机器人等物理世界通用智能具有关键作用。极佳科技世界级人工智能综合团队在技术与产业落地方面拥有丰富经验，通过打造基础模型和超级应用的智能闭环飞轮，推动行业走向通用智能时代。未来，视界一粟YiSu将助力更多创新技术和产品的发展，为用户提供更多价值，加速通用智能时代的到来。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4TF9AUQ0512MLBG.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;微信公众号老牛同学&#34;&gt;微信公众号：老牛同学&lt;/h2&gt;
&lt;h3 id=&#34;stable-diffusion开源大模型&#34;&gt;Stable Diffusion开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Sax4z2k8Dvn82h15jf51Hw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Stable Diffusion 3 文生图“开源英雄”大模型笔记本部署和使用教程，轻松实现AI绘图自由&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;qwen2-7b-开源大模型&#34;&gt;Qwen2-7B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/u_Uw88dpQRgbtfI4_1OOwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Qwen2 阿里最强开源大模型（Qwen2-7B）本地部署、API调用和WebUI对话机器人&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;llama3-8b-开源大模型&#34;&gt;Llama3-8B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;glm-4-9b-开源大模型&#34;&gt;GLM-4-9B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;chattts-文本转语音模型&#34;&gt;ChatTTS 文本转语音模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API使用和搭建WebUI界面&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;大模型应用&#34;&gt;大模型应用&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/m_O2OSoXWLL0PJurLCdzng&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;借助AI大模型，三分钟原创一部儿童故事短视频（附完整操作步骤）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;python-小游戏&#34;&gt;Python 小游戏&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hv2tE-yot_H04HCezxQWXg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI已来，我与AI一起用Python编写了一个消消乐小游戏&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/tkTlt4rbFKQ73zudluPO1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python游戏编程：一步步用Python打造经典贪吃蛇小游戏&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Stable Diffusion 3 大模型文生图“开源英雄”笔记本部署和使用教程，轻松实现AI绘图自由</title>
        <link>https://ntopic.cn/p/2024061701/</link>
        <pubDate>Mon, 17 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024061701/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024061701/00.jpg" alt="Featured image of post Stable Diffusion 3 大模型文生图“开源英雄”笔记本部署和使用教程，轻松实现AI绘图自由" /&gt;&lt;p&gt;备受期待的&lt;strong&gt;Stable Diffusion 3&lt;/strong&gt;（以下亦简称&lt;strong&gt;SD3&lt;/strong&gt;）如期向公众开源了（&lt;strong&gt;Stable Diffusion 3 Medium&lt;/strong&gt;），作为&lt;strong&gt;Stability AI&lt;/strong&gt;迄今为止最先进的文本生成图像的开源大模型，&lt;strong&gt;SD3&lt;/strong&gt;在图像质量、文本内容生成、复杂提示理解和资源效率方面有了显著提升，被誉为AI文生图领域的&lt;strong&gt;开源英雄&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stable Diffusion 3 Medium&lt;/strong&gt;特点包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型仅包含&lt;strong&gt;20亿&lt;/strong&gt;参数，具有体积小、适合在个人PC和笔记本电脑上运行的优点，所以我们也可以将其部署到自己的电脑上使用。&lt;/li&gt;
&lt;li&gt;图像质量整体提升，能生成照片般细节逼真、色彩鲜艳、光照自然的图像；能灵活适应多种风格，无需微调，仅通过提示词就能生成动漫、厚涂等风格化图像；具有 16 通道的 VAE，可以更好地表现手部以及面部细节。&lt;/li&gt;
&lt;li&gt;能够理解复杂的自然语言提示，如空间推理、构图元素、姿势动作、风格描述等。对于「第一瓶是蓝色的，标签是“1.5”，第二瓶是红色的，标签是“SDXL”，第三瓶是绿色的，标签是“SD3”」这样复杂的内容，SD3 依旧能准确生成，而且文本效果比 Midjourney 还要准确。&lt;/li&gt;
&lt;li&gt;通过 Diffusion Transformer 架构，SD3 Medium 在英文文本拼写、字距等方面更加正确合理。Stability AI 在发布 SD3 官方公告时，头图就是直接用 SD3 生成的，效果非常惊艳。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;特别注意：&lt;/strong&gt; 开源的&lt;strong&gt;Stable Diffusion 3 Medium&lt;/strong&gt;模型的授权范围是开放的非商业许可证，也就是说没有官方许可的情况下，模型不得用于商业用途（协议内容：&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/stabilityai/stable-diffusion-3-medium/blob/main/LICENSE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://huggingface.co/stabilityai/stable-diffusion-3-medium/blob/main/LICENSE&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;下载stable-diffusion-3-medium模型文件&#34;&gt;下载Stable Diffusion 3 Medium模型文件&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;SD3&lt;/strong&gt;的模型文件已经上传到了HF上，但是在下载之前需要先注册并填写一份表格，保证自己不会将&lt;strong&gt;SD3&lt;/strong&gt;用于商用用途。然而，注册和填写表格均需要有&lt;strong&gt;通畅&lt;/strong&gt;的网络，这对我们个人不是很友好：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061701/01.jpg&#34;
	width=&#34;1492&#34;
	height=&#34;408&#34;
	srcset=&#34;https://ntopic.cn/p/2024061701/01_hucdd97bec049297010b8373c4fdef8e3e_194224_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061701/01_hucdd97bec049297010b8373c4fdef8e3e_194224_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;注册或登录&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;365&#34;
		data-flex-basis=&#34;877px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;注册或者登录成功之后，我们需要填写表格：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061701/02.jpg&#34;
	width=&#34;1500&#34;
	height=&#34;1305&#34;
	srcset=&#34;https://ntopic.cn/p/2024061701/02_hu7a90481de075d061b3888e4511ee84cb_359064_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061701/02_hu7a90481de075d061b3888e4511ee84cb_359064_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;填写表格&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;114&#34;
		data-flex-basis=&#34;275px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;老牛同学担心，仅这2个前置的需要&lt;strong&gt;通畅网络&lt;/strong&gt;的操作步骤，就阻挡了一批&lt;strong&gt;SD3&lt;/strong&gt;的爱好者们，这是老牛同学不希望看到的结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;幸运的是：&lt;/strong&gt; ModelScope提供了一个可直接下载模型文件的镜像仓库，可直接跳过前面步骤（当然这有点违背&lt;strong&gt;Stability AI&lt;/strong&gt;的初衷，但考虑到我们仅用于学习和非商业用途，也算是殊途同归吧）：&lt;a class=&#34;link&#34; href=&#34;https://modelscope.cn/models/AI-ModelScope/stable-diffusion-3-medium/files&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://modelscope.cn/models/AI-ModelScope/stable-diffusion-3-medium/files&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本仓库有3个基础是模型文件，它们有不同的用途，初次使用建议全部下载到本地：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sd3_medium：4.34G，独立主模型，不包含文本编码器（即后面2个文件名带有&lt;strong&gt;clip&lt;/strong&gt;的模型）&lt;/li&gt;
&lt;li&gt;sd3_medium_incl_clips.safetensors：5.97G，包含 clip_g 和 clip_l 编码器&lt;/li&gt;
&lt;li&gt;sd3_medium_incl_clips_t5xxlfp8.safetensors：10.87G，包含 clip_g、clip_l 和 t5xxl_fp8 编码器&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;特别说明：&lt;/strong&gt; 以上3个模型文件，最后需要放到&lt;strong&gt;ComfyUI&lt;/strong&gt;的&lt;code&gt;./models/checkpoints&lt;/code&gt;文件夹中（关于&lt;strong&gt;ComfyUI&lt;/strong&gt;的使用下面章节介绍）&lt;/p&gt;
&lt;p&gt;另外，本仓库还有2个重要的文件夹，同样建议全部下载到本地：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;comfy_example_workflows：&lt;strong&gt;ComfyUI&lt;/strong&gt;工作流样例配置文件（关于&lt;strong&gt;ComfyUI&lt;/strong&gt;的使用下面章节介绍）&lt;/li&gt;
&lt;li&gt;text_encoders：文本编码器模型文件夹，最后模型文件最后也需要放到&lt;strong&gt;ComfyUI&lt;/strong&gt;的&lt;code&gt;./models/clip&lt;/code&gt;文件夹中（关于&lt;strong&gt;ComfyUI&lt;/strong&gt;的使用下面章节介绍）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因模型文件比较大，直接使用Git无法直接下载到本地，我们通过&lt;strong&gt;git-lfs&lt;/strong&gt;工具包下载：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;brew install git-lfs
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;通过Git复制模型文件到笔记本电脑（文件夹：&lt;code&gt;stable-diffusion-3-medium&lt;/code&gt;）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs install
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://www.modelscope.cn/AI-ModelScope/stable-diffusion-3-medium.git stable-diffusion-3-medium
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果因网络不佳等原因，下载可能会中断，我们可以通过以下命令在中断后多次执行继续下载，直到最终下载完成：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs pull
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061701/03.jpg&#34;
	width=&#34;1022&#34;
	height=&#34;1216&#34;
	srcset=&#34;https://ntopic.cn/p/2024061701/03_huc7cc27641537fe38809ac489d4a7b91b_249626_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061701/03_huc7cc27641537fe38809ac489d4a7b91b_249626_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;模型文件列表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;84&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;下载comfyui工作流可视化工具&#34;&gt;下载ComfyUI工作流可视化工具&lt;/h2&gt;
&lt;p&gt;上一章节，我们多次提到了&lt;strong&gt;ComfyUI&lt;/strong&gt;，它是&lt;strong&gt;Stable Diffusion&lt;/strong&gt;的工作流可视化工具之一，也是Stability AI官方推荐使用的可视化工具。&lt;/p&gt;
&lt;p&gt;我们下载最新的&lt;strong&gt;ComfyUI&lt;/strong&gt;到笔记本电脑（本地目录：&lt;code&gt;ComfyUI&lt;/code&gt;）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/comfyanonymous/ComfyUI.git ComfyUI
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;本次部署教程中，&lt;strong&gt;ComfyUI&lt;/strong&gt;中的&lt;code&gt;models&lt;/code&gt;文件夹需要包括下载的模型文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% tree ./models 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./models
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── checkpoints
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│   └── put_checkpoints_here
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── clip
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│   └── put_clip_or_text_encoder_models_here
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;......其它省略......
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;checkpoints&lt;/strong&gt;文件夹：是存放&lt;strong&gt;SD3&lt;/strong&gt;模型文件根目录下的&lt;code&gt;sd3_medium.safetensors&lt;/code&gt;、&lt;code&gt;sd3_medium_incl_clips.safetensors&lt;/code&gt;和&lt;code&gt;sd3_medium_incl_clips_t5xxlfp8.safetensors&lt;/code&gt;等模型文件的文件夹。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;clip&lt;/strong&gt;文件夹：是存放&lt;strong&gt;SD3&lt;/strong&gt;模型文件&lt;code&gt;text_encoders&lt;/code&gt;目录下的&lt;code&gt;clip_g.safetensors&lt;/code&gt;、&lt;code&gt;clip_l.safetensors&lt;/code&gt;、&lt;code&gt;t5xxl_fp8_e4m3fn.safetensors&lt;/code&gt;和&lt;code&gt;t5xxl_fp16.safetensors&lt;/code&gt;等模型文件的文件夹。&lt;/p&gt;
&lt;h2 id=&#34;启动comfyui可视化界面&#34;&gt;启动ComfyUI可视化界面&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;第一步：&lt;/strong&gt; 复制模型文件到&lt;strong&gt;ComfyUI&lt;/strong&gt;指定的&lt;code&gt;models&lt;/code&gt;文件夹中，因为老牛同学使用的是Mac电脑，可以通过软链接方式实现复制的效果（如果是&lt;strong&gt;Windows&lt;/strong&gt;电脑，请直接复制文件）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/JupyterLab/ComfyUI/models/checkpoints
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ln -s ~/JupyterLab/stable-diffusion-3-medium/sd3_medium.safetensors sd3_medium.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ln -s ~/JupyterLab/stable-diffusion-3-medium/sd3_medium_incl_clips.safetensors sd3_medium_incl_clips.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ln -s ~/JupyterLab/stable-diffusion-3-medium/sd3_medium_incl_clips_t5xxlfp8.safetensors sd3_medium_incl_clips_t5xxlfp8.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;%
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/JupyterLab/ComfyUI/models/clip
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ln -s ~/JupyterLab/stable-diffusion-3-medium/text_encoders/clip_g.safetensors clip_g.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ln -s ~/JupyterLab/stable-diffusion-3-medium/text_encoders/clip_l.safetensors clip_l.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ln -s ~/JupyterLab/stable-diffusion-3-medium/text_encoders/t5xxl_fp8_e4m3fn.safetensors t5xxl_fp8_e4m3fn.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% ln -s ~/JupyterLab/stable-diffusion-3-medium/text_encoders/t5xxl_fp16.safetensors t5xxl_fp16.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;软链接建好之后，我们可以检查一下是否&lt;strong&gt;符合预期&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/JupyterLab/ComfyUI/models
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% tree ./checkpoints 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./checkpoints
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── put_checkpoints_here
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── sd3_medium.safetensors -&amp;gt; /Users/shizihu/JupyterLab/stable-diffusion-3-medium/sd3_medium.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── sd3_medium_incl_clips.safetensors -&amp;gt; /Users/shizihu/JupyterLab/stable-diffusion-3-medium/sd3_medium_incl_clips.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;└── sd3_medium_incl_clips_t5xxlfp8.safetensors -&amp;gt; /Users/shizihu/JupyterLab/stable-diffusion-3-medium/sd3_medium_incl_clips_t5xxlfp8.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;%
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% tree ./clip
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./clip
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── clip_g.safetensors -&amp;gt; /Users/shizihu/JupyterLab/stable-diffusion-3-medium/text_encoders/clip_g.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── clip_l.safetensors -&amp;gt; /Users/shizihu/JupyterLab/stable-diffusion-3-medium/text_encoders/clip_l.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── put_clip_or_text_encoder_models_here
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── t5xxl_fp16.safetensors -&amp;gt; /Users/shizihu/JupyterLab/stable-diffusion-3-medium/text_encoders/t5xxl_fp16.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;└── t5xxl_fp8_e4m3fn.safetensors -&amp;gt; /Users/shizihu/JupyterLab/stable-diffusion-3-medium/text_encoders/t5xxl_fp8_e4m3fn.safetensors
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;第二步：&lt;/strong&gt; 启动&lt;strong&gt;ComfyUI&lt;/strong&gt;工作流可视化界面&lt;/p&gt;
&lt;p&gt;进入&lt;strong&gt;ComfyUI&lt;/strong&gt;根目录，安装Python依赖包列表：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% pip install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动&lt;strong&gt;ComfyUI&lt;/strong&gt;可视化工具：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% python main.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061701/04.jpg&#34;
	width=&#34;1500&#34;
	height=&#34;855&#34;
	srcset=&#34;https://ntopic.cn/p/2024061701/04_hua699aea61dfc9c9d353f7b328031f275_759135_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061701/04_hua699aea61dfc9c9d353f7b328031f275_759135_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;ComfyUI启动成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;421px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;从启动日志可以看出，&lt;strong&gt;ComfyUI&lt;/strong&gt;启动成功了：&lt;a class=&#34;link&#34; href=&#34;http://127.0.0.1:8188&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://127.0.0.1:8188&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;使用comfyui通过文本生成图片&#34;&gt;使用ComfyUI通过文本生成图片&lt;/h2&gt;
&lt;p&gt;浏览器打开&lt;strong&gt;ComfyUI&lt;/strong&gt;页面：&lt;code&gt;http://127.0.0.1:8188&lt;/code&gt; 可以看到默认的&lt;strong&gt;SD3&lt;/strong&gt;工作流，我们用自己的工作流完成绘画。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一步：&lt;/strong&gt; 修改模型文件&lt;code&gt;./stable-diffusion-3-medium/comfy_example_workflows/sd3_medium_example_workflow_basic.json&lt;/code&gt;的第&lt;strong&gt;416行&lt;/strong&gt;，去掉&lt;code&gt;sdv3/2b_1024/sd3_medium.safetensors&lt;/code&gt;的相对目录为&lt;code&gt;sd3_medium.safetensors&lt;/code&gt;（默认本模型文件，我们已经复制到了ComfyUI指定的目录中，因此无需相对目录）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;......前面省略......&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;widgets_values&amp;#34;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;s2&#34;&gt;&amp;#34;sd3_medium.safetensors&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;......后面省略......&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;第二步：&lt;/strong&gt; 加载修改后的工作流配置文件：点击&lt;strong&gt;ComfyUI&lt;/strong&gt;的&lt;strong&gt;Load&lt;/strong&gt;按钮，选择修改后的&lt;code&gt;sd3_medium_example_workflow_basic.json&lt;/code&gt;文件：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061701/05.jpg&#34;
	width=&#34;1500&#34;
	height=&#34;745&#34;
	srcset=&#34;https://ntopic.cn/p/2024061701/05_hu968de44d62e6c102545c7d6c8fc635bb_405583_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061701/05_hu968de44d62e6c102545c7d6c8fc635bb_405583_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;加载工作流配置文件&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;483px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看到工作流有很多参数可供设置，包括：&lt;code&gt;选择模型&lt;/code&gt;、&lt;code&gt;正面Prompt提示词&lt;/code&gt;、&lt;code&gt;负面Prompt提示词&lt;/code&gt;、&lt;code&gt;图片尺寸/数量&lt;/code&gt;等输入参数：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061701/06.jpg&#34;
	width=&#34;1500&#34;
	height=&#34;1601&#34;
	srcset=&#34;https://ntopic.cn/p/2024061701/06_hu96e4e2a32a14aaa652d25e57adafb87f_656035_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061701/06_hu96e4e2a32a14aaa652d25e57adafb87f_656035_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;工作流配置参数&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;93&#34;
		data-flex-basis=&#34;224px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第三步：&lt;/strong&gt; 调整参数，生成图片：我们可以修改工作流中任意一个参数（最常修改的是Prompt提示词，包括正面和负面提示词），也可以点击右键增加工作流节点。最终参数调整确定之后，点击&lt;strong&gt;Queue Prompt&lt;/strong&gt;按钮，开始排队生成图片：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061701/07.jpg&#34;
	width=&#34;1500&#34;
	height=&#34;898&#34;
	srcset=&#34;https://ntopic.cn/p/2024061701/07_hu5272aa65419e558a3ff6d6d059cd537a_443429_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061701/07_hu5272aa65419e558a3ff6d6d059cd537a_443429_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;生成图片&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;167&#34;
		data-flex-basis=&#34;400px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到，生成图片处理中，&lt;strong&gt;ComfyUI&lt;/strong&gt;根据编排好的工作流，按照依赖关系逐个节点执行，最终在&lt;strong&gt;Output&lt;/strong&gt;中展示了根据提示生成的精美图片：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061701/08.jpg&#34;
	width=&#34;1500&#34;
	height=&#34;946&#34;
	srcset=&#34;https://ntopic.cn/p/2024061701/08_hu01827461d1884724b89e9d6e07cf2bf6_561100_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061701/08_hu01827461d1884724b89e9d6e07cf2bf6_561100_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;工作流结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;最终生成的图片：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061701/00.jpg&#34;
	width=&#34;1024&#34;
	height=&#34;1024&#34;
	srcset=&#34;https://ntopic.cn/p/2024061701/00_hu208e39d3e3e5e981d6b12dd280fb4517_114349_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061701/00_hu208e39d3e3e5e981d6b12dd280fb4517_114349_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;最终图片&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;stable-diffusion使用总结&#34;&gt;Stable Diffusion使用总结&lt;/h2&gt;
&lt;p&gt;至此，&lt;strong&gt;Stable Diffusion 3&lt;/strong&gt;的部署和使用教程接近尾声了，我们可以尽情使用不同的工作流和调整不同参数来生成我们的图片了。&lt;/p&gt;
&lt;p&gt;同时也恭喜你，和老牛同学一起，我们的大模型库又增添了重要的一员：&lt;strong&gt;文生图&lt;/strong&gt;大模型！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SD3 参数调优：&lt;/strong&gt; 生成写实或人物面部照片，可以将&lt;strong&gt;KSampler&lt;/strong&gt;节点的&lt;code&gt;cfg&lt;/code&gt;参数调低至&lt;strong&gt;2到3之间&lt;/strong&gt;（默认为&lt;strong&gt;4.5&lt;/strong&gt;）；当包含文本时，使用&lt;strong&gt;4.5到5&lt;/strong&gt;时效果会更好。大家可以多多尝试，探索一些其他参数产生的效果，欢迎留言。&lt;/p&gt;
&lt;p&gt;同时&lt;strong&gt;SD3&lt;/strong&gt;模型更适合自然语言提示词，而不是标签式的提示词（和MJ有一点点区别），我们可以详细描述图片的画面内容、构图、色彩、氛围，即使提示词很长，&lt;strong&gt;SD3&lt;/strong&gt;模型也能处理的很好。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;微信公众号老牛同学&#34;&gt;微信公众号：老牛同学&lt;/h2&gt;
&lt;h3 id=&#34;qwen2-7b-开源大模型&#34;&gt;Qwen2-7B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/u_Uw88dpQRgbtfI4_1OOwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Qwen2阿里最强开源大模型（Qwen2-7B）本地部署、API调用和WebUI对话机器人&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;llama-3-8b-开源大模型&#34;&gt;Llama-3-8B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;glm-4-9b-开源大模型&#34;&gt;GLM-4-9B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;chattts-文本转语音模型&#34;&gt;ChatTTS 文本转语音模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API使用和搭建WebUI界面&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;大模型应用&#34;&gt;大模型应用&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/m_O2OSoXWLL0PJurLCdzng&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;借助AI大模型，三分钟原创一部儿童故事短视频（附完整操作步骤）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;python-小游戏&#34;&gt;Python 小游戏&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hv2tE-yot_H04HCezxQWXg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI已来，我与AI一起用Python编写了一个消消乐小游戏&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/tkTlt4rbFKQ73zudluPO1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python游戏编程：一步步用Python打造经典贪吃蛇小游戏&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>AI测试高考物理题，最高准确率100%，OpenAI与苹果合作，将ChatGPT融入系统中，大模型在物理领域应用潜力显现</title>
        <link>https://ntopic.cn/p/ai20240612/</link>
        <pubDate>Wed, 12 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240612/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240612/ai20240612-125.jpg" alt="Featured image of post AI测试高考物理题，最高准确率100%，OpenAI与苹果合作，将ChatGPT融入系统中，大模型在物理领域应用潜力显现" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;国产AI大战高考物理，第1题全对，第2题开始放飞&lt;/li&gt;
&lt;li&gt;终于放大招了，2024WWDC，苹果开启AI反击战&lt;/li&gt;
&lt;li&gt;苹果一夜重塑iPhone！GPT-4o加持Siri，AI深入所有APP&lt;/li&gt;
&lt;li&gt;OpenAI确认苹果集成ChatGPT 还任命了两位新高管&lt;/li&gt;
&lt;li&gt;GPT-4搞不定的图推理，港科大7B模型搞定｜KDD2024&lt;/li&gt;
&lt;li&gt;拿下SOTA！最强中文Embedding模型对标OpenAI，技术路线公开&lt;/li&gt;
&lt;li&gt;具身智能赋能机器人，「AI+人形机器人」论坛在浦东新区成功举行&lt;/li&gt;
&lt;li&gt;苹果智能炸裂登场：GPT-4o加持,全家桶都上生成式AI,Siri脱胎换骨&lt;/li&gt;
&lt;li&gt;AI重新定义导航，弯道会车无灯路口提前预警，网友：导航成精了！&lt;/li&gt;
&lt;li&gt;AI生图格局大震！Stable Diffusion 3开源倒计时，2B单机可跑碾压闭源Midjou&lt;/li&gt;
&lt;li&gt;手机流畅运行470亿大模型：上交大发布LLM手机推理框架，提速29倍&lt;/li&gt;
&lt;li&gt;估值64亿美元！Mistral AI官宣6.4亿美元B轮融资&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;国产ai大战高考物理第1题全对第2题开始放飞&#34;&gt;国产AI大战高考物理，第1题全对，第2题开始放飞&lt;/h2&gt;
&lt;p&gt;端午佳节之际，高考在部分地区已落幕，在其他考场，考生仍在奋力应考。为预祝所有参与者取得理想成绩，各类科目考试答案开始在网络上流传。面对新高考改革下取消文理分科、采用3+1+2或3+3模式的挑战，本次邀请了通义千问等十款AI助手参与物理单选题与多选题的解答测试。在单选题环节中，最高准确率为100%，涉及矢量标量概念。第二题，选手们答案各异；海螺AI、讯飞星火和文心一言表现出色。第5题，讯飞星火、海螺AI和新增的Kimi与腾讯元宝答对。文心一言和ChatGLM在解答双缝干涉实验时展现了独特的应试策略。多选题部分，海螺AI表现最佳，通义千问、文心一言以及万知亦取得不俗成绩。最高准确率第8题是一道概念题，第9题万知与海螺AI全选正确答案。测试结果显示，在46分的选择题中，多数选手达到了及格标准。本次AI解答测试展现了大模型在物理领域应用的潜力与挑战性，未来期待更多创新与改进。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4B8JQK60511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;终于放大招了2024wwdc苹果开启ai反击战&#34;&gt;终于放大招了，2024WWDC，苹果开启AI反击战&lt;/h2&gt;
&lt;p&gt;2024年WWDC大会上，苹果全面发力人工智能领域，发布了一系列新操作系统，包括iOS18、iPadOS18、macOSSequoia、watchOS11等，并推出了“AppleIntelligence”功能。这一功能使Siri更加智能，支持图片AI消除、系统录音APP通话录音、AI图片生成等功能。用户无需注册即可使用ChatGPT-4。然而，该功能仅适用于搭载A17Pro和M系列芯片的设备，且当前只有美国版本提供英语服务，其他国家和地区需等待后续更新。AppleIntelligence的推出标志着苹果正式踏入人工智能元年，库克强调它不仅涉及人工智能，更是一种个人化智能体验。在文字处理、隐私保护等方面，AI功能得到了显著增强，如Siri支持不连贯语音指令、跨App操作等。图片处理方面，用户可以直接使用AI技术消除照片中的路人或搜索特定动作的表情，并生成与AppleMusic库中音乐相匹配的回忆或vlog。此外，苹果宣布与OpenAI合作将ChatGPT集成到系统生态中，并由GPT-4驱动，用户无需注册即可体验。国行版则可能与百度合作使用文心一言大模型。值得一提的是，通过录音功能，用户可以实现文字转换，这一特性在安卓设备上已有所应用。AppleIntelligence强调了隐私保护和端侧、云端处理的结合，确保数据安全。尽管在AI领域起步较晚，但苹果展示了一系列创新功能，并承诺将AI融入更多产品中，以打造个人化智能体验。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/tech/article/J4CJD7QD000999D8.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;苹果一夜重塑iphonegpt-4o加持siriai深入所有app&#34;&gt;苹果一夜重塑iPhone！GPT-4o加持Siri，AI深入所有APP&lt;/h2&gt;
&lt;p&gt;苹果通过与OpenAI合作接入ChatGPT和使用GPT-4o模型，对iPhone系统进行全面升级，包括Siri的重生、重构人机交互模式、引入AppleIntelligence成为AI新代名词等。发布内容涉及iOS、iPadOS大更新，AI浓度显著提升，并且这些功能免费提供给iPhone15Pro及以上设备和搭载M1及更高配置芯片的Mac用户。内置ChatGPT无需注册即可使用。发布会引起广泛关注，WWDC24冲上热搜前三，网友感慨苹果整合能力逆天，新AI功能满足大家想象力。AppleIntelligence与ChatGPT联手打造AIPhone，系统AI化、引入强大云端大模型，包括语言、图像、行动和个性化等多方面增强。语言方面支持通知优先排序、写作工具优化；图像生成覆盖素描、插画、动画等多种风格，并能自定义emoji；行动力方面提供跨应用操作及个人情景分析。AppleIntelligence在隐私保护上采用专门架构，在端侧进行涉及个人隐私的计算，确保安全。此外，AppleIntelligence还能生成摘要、总结电话录音等功能。对于更复杂任务，引入ChatGPT，支持多模态任务如为菜谱提供灵感等，并且所有请求不会被记录。Siri升级进入新纪元，屏幕边缘光晕显示，理解更丰富语言和上下文信息，支持语音打字切换输入，解答数千个操作问题。AppleIntelligence将增强屏幕内容感知功能、跨应用操作能力以及APPIntents框架的智能度，提供更多个性化体验。iOS18主打个性化，引入深色模式设置，APP小组件主题自定义，控制中心可自定义控制项和布局，隐私安全方面增加上锁功能。图库新增按时间、主题分类整理的小相册，短信解锁新功能如延迟发送、特殊文字效果等。iPadOS18终于加入计算器，并支持数学笔记、手写识别等功能，备忘录推出Smartscript模仿笔迹功能。VisionOS2增强AI空间化照片和沉浸式分享能力，支持双指轻点切换主屏幕、旅行模式增加火车场景支持。MacOSSepuoia优化设备互联，可在Mac桌面上直接打开iPhone镜像并操作iPhone内容，Safari新增Highlights功能突出显示重要页面内容，并加强智能防追踪保护隐私。新出的Keychain管理密码安全，实现多设备同步。发布会后，库克表示AIPhone时代刚刚开始。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4CON34U0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;openai确认苹果集成chatgpt-还任命了两位新高管&#34;&gt;OpenAI确认苹果集成ChatGPT 还任命了两位新高管&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240612/ai20240612-116.jpg&#34;
	width=&#34;336&#34;
	height=&#34;252&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240612/ai20240612-116_hueafeaa9cf4deea10765939a7294c5c66_94481_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240612/ai20240612-116_hueafeaa9cf4deea10765939a7294c5c66_94481_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;OpenAI确认苹果集成ChatGPT 还任命了两位新高管&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;美国时间周一，OpenAI宣布聘请萨拉·弗莱尔为首席财务官和凯文·威尔为首席产品官，并与苹果合作集成ChatGPT等协议。弗莱尔曾任NextdoorCEO及SquareCFO，目前是斯坦福大学数字经济实验室联席主席；威尔曾担任PlanetLabs总裁、Twitter高级副总裁以及Facebook和Instagram高管。新任命旨在强化OpenAI的高管团队，推动公司扩大规模以满足增长需求，并应对复杂环境。OpenAI与苹果的合作计划于今年晚些时候将ChatGPT整合至iOS、iPadOS及macOS系统中，用户可借此利用ChatGPT功能进行文本生成、图像创建等操作。此外，Siri将调用ChatGPT智能提供答案，但在发送问题前需用户确认。近期，OpenAI因快速成长和争议性员工离职事件受到关注，并有员工公开信表达对行业过快发展及缺乏监管的担忧。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/tech/article/J4CTMJK500097U7T.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;gpt-4搞不定的图推理港科大7b模型搞定kdd2024&#34;&gt;GPT-4搞不定的图推理，港科大7B模型搞定｜KDD2024&lt;/h2&gt;
&lt;p&gt;大模型执行图推理任务时，关键在于是否能准确给出结果并同时提供详细的推理过程。GPT-4表现简短且错误，可能受限于处理长输入或理解复杂结构；相比之下，港科大团队开发的GraphWiz不仅正确解答，还清晰展示推理路径。GraphInstruct数据集为训练语言模型提供了多样化的图任务和明确的推理路径，旨在提升模型解决各种图问题的能力。GraphWiz通过针对性微调和两阶段训练方法优化了解题能力，并提供连贯推理路径。研究发现，GraphWiz在空间推理、记忆保持方面表现出色，优于GPT-4。九种不同复杂度层次的图问题被精心挑选用于全面探索图论理论与应用。GraphInstruct数据集构建包括生成随机图和显式推理路径，通过拒绝采样策略增强数据多样性。GraphWiz训练采用混合任务指令调优和直接偏好优化对齐方法提升模型性能。评估结果显示，GraphWiz在不同复杂度的图问题上显著超越GPT-4，并且随着训练语料库增加，性能进一步提升。然而，在某些特定任务中存在潜在过拟合现象。通过比较实验，研究发现GraphWiz具有良好的跨任务泛化能力，尤其在高复杂度和零样本迁移任务上的表现令人印象深刻。整体而言，GraphWiz的开发不仅提升了大型模型解决图推理问题的能力，还提供了清晰、连贯的推理路径，为实际应用提供了强大支持。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4DKQKHO0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;拿下sota最强中文embedding模型对标openai技术路线公开&#34;&gt;拿下SOTA！最强中文Embedding模型对标OpenAI，技术路线公开&lt;/h2&gt;
&lt;p&gt;国产大模型「日日新5.0」凭借商汤自研中文Embedding模型Piccolo2在权威评测中超越GPT-4Turbo，成为首个实现此壮举的国产模型。背后是算法、算力与数据全面优化的结果，其中Piccolo2作为关键算法之一，支持512/2K/8K向量长度，尤其8K模型对标OpenAI，性能在C-MTEB中文语义向量评测中领先。论文及HuggingFace地址公开，揭示了其通过多任务混合损失训练、高效数据合成与难负样本挖掘提升性能的策略。相较于之前SOTA模型，Piccolo2综合评分提高约1.9个点，展现了在检索、分类、聚类等任务上的强大能力，为大语言模型落地应用提供了关键技术支持。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4DJEH3G0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;具身智能赋能机器人ai人形机器人论坛在浦东新区成功举行&#34;&gt;具身智能赋能机器人，「AI+人形机器人」论坛在浦东新区成功举行&lt;/h2&gt;
&lt;p&gt;在上海市浦东新区科技和经济委员会指导下，「AI+人形机器人」论坛暨张江机器人全球生态峰会具身智能开发者论坛于浦东新区张江科学会堂成功召开。来自多个领域的200多位嘉宾参加，讨论了具身智能、运动控制、云计算及人形机器人整机等议题，吸引了超30000在线观众。论坛邀请12位专家分享研究成果，涵盖浙大教授王越的末端规划难题解决方案，上海人工智能实验室青年科学家庞江淼的人工智能模型赋能与三维感知挑战解决，香港中文大学（深圳）教授贾奎提出的高通用性具身智能阶段及跨维智能基于Sim2Real的解决方案。李清教授分析了肌腱仿生驱动优势，并倡导产业交流；胡宇航分享自监督学习应用推动自动学习优化；蒋琛讨论具身智能控制系统平台促进人形机器人大小脑融合。施群聚焦人形机器人结构设计，季超博士分享团队结合具身大模型的技术路线及挑战，李伟研究员介绍基于生命进化学习的机器人形态与行为策略迁移。陈鹏介绍松灵机器人的全球科研教育工作，张龙君分享加速具身智能机器人产品核心能力构建的工作，邢伯阳分享低成本具身平台的设计思想和应用前景。浦东新区大模型赋能产业系列论坛聚焦金融、智能网联车、人形机器人等垂直领域，探讨前沿AI应用场景，搭建技术交流与产业协同的开放平台，助力浦东打造世界级人工智能产业集群。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4D9GQ960511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;苹果智能炸裂登场gpt-4o加持全家桶都上生成式aisiri脱胎换骨&#34;&gt;苹果智能炸裂登场：GPT-4o加持,全家桶都上生成式AI,Siri脱胎换骨&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240612/ai20240612-125.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240612/ai20240612-125_hu4697c1f87f561bff2a15f9ead133bd06_63496_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240612/ai20240612-125_hu4697c1f87f561bff2a15f9ead133bd06_63496_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;苹果智能炸裂登场：GPT-4o加持,全家桶都上生成式AI,Siri脱胎换骨&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;苹果全球开发者大会WWDC2023在ApplePark正式召开，宣布覆盖全线产品的生成式AI技术，并带来Siri、Siri新形态、AppleIntelligence系统级整合、ChatGPT集成、跨平台集成ChatGPT、全新语言理解和创造能力、ImagePlayground和Genmoji以及隐私保护等创新。此次发布会亮点包括：1.&lt;strong&gt;生成式AI技术&lt;/strong&gt;：苹果推出基于M系列芯片的自研本地大模型加云端策略，实现强大、直观、完全整合、个性化且保护隐私的体验。2.&lt;strong&gt;Siri更新&lt;/strong&gt;：-新形态Siri拥有更丰富的语言理解能力，更加自然、懂上下文、个性化，简化日常任务。-支持文字输入和切换文本与语音交互方式。-屏幕感知功能允许执行屏幕信息相关操作。3.&lt;strong&gt;AppleIntelligence&lt;/strong&gt;：全面AI系统，结合生成式AI模型和个人资料提供智能服务，覆盖iPhone、iPad和Mac，利用苹果芯片能力处理语言和图像，并支持跨应用操作。4.&lt;strong&gt;ChatGPT集成&lt;/strong&gt;：-Apple正式将ChatGPT集入iOS18、iPadOS18和macOSSequoia，提供图像和文档理解功能。-Siri可以随时利用ChatGPT提供专业回答，用户授予权限后可直接访问。5.&lt;strong&gt;写作工具与AI&lt;/strong&gt;：系统集成的写作工具支持通过ChatGPT协助生成内容，并在iOS、iPadOS和macOS中提供个性化的智能服务，如重写、校对和总结文本等。6.&lt;strong&gt;隐私保护&lt;/strong&gt;：AppleIntelligence采用设备端处理和私有云端计算（PrivateCloudCompute）策略，确保数据安全，为AI领域设立新的隐私标准。7.&lt;strong&gt;新macOS系统&lt;/strong&gt;：macOSSequoia引入iPhone镜像功能、通知整合与Safari升级等，提供更流畅的多设备体验。8.&lt;strong&gt;iPad计算器应用&lt;/strong&gt;：苹果首次为iPad推出原生计算器应用，满足用户需求。9.&lt;strong&gt;VisionPro系统&lt;/strong&gt;：visionOS2新增多项功能，支持从2D图像中导出深度信息，并带来空间照片等创新体验。总体而言，苹果通过此次WWDC发布会展示了其在生成式AI领域的全面布局和技术创新，旨在提升用户体验并保持技术领先地位。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4D772290511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai重新定义导航弯道会车无灯路口提前预警网友导航成精了&#34;&gt;AI重新定义导航，弯道会车无灯路口提前预警，网友：导航成精了！&lt;/h2&gt;
&lt;p&gt;高德地图新功能“车道级安全预警”引发用户热议，其能在多种场景下实时探测行车风险，提供语音提醒，覆盖前后左右、昼夜情况，帮助用户减少事故风险。该功能从过去的“车道级导航”进化为能预测并响应风险的系统，不仅提升准确性，还扩展了感知范围，让用户仿佛拥有“千里眼”。高德地图日活跃用户峰值超过2.8亿，月活高达8.01亿，作为国内移动互联网第四大应用，在大规模用户基础上实现车道级安全预警。此外，AI技术与大模型的融入优化了导航服务，提供个性化体验，并探索车路云一体化可能性。高德的成功不仅在于技术创新，也体现了对用户需求的深入理解和服务的社会普惠性，预示着AI在出行领域的未来变革。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4DLEDBE0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai生图格局大震stable-diffusion-3开源倒计时2b单机可跑碾压闭源midjou&#34;&gt;AI生图格局大震！Stable Diffusion 3开源倒计时，2B单机可跑碾压闭源Midjou&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240612/ai20240612-132.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240612/ai20240612-132_hu2b983275ca6c0e6d1bf84d44f5db83df_156818_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240612/ai20240612-132_hu2b983275ca6c0e6d1bf84d44f5db83df_156818_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AI生图格局大震！Stable Diffusion 3开源倒计时，2B单机可跑碾压闭源Midjou&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;StableDiffusion3（SD3）即将开源，引发AI生图领域重大变革。经过4个月的酝酿，此消息在社区内激起了巨大反响。SD3凭借其强大的MMDiT全新架构，在AI图像生成领域展现出前所未有的实力，有望成为首个开源碾压闭源的技术赛道。ComfyUI已提前支持SD3版本，预示着开源发布即将成真。SD3的开源不仅意味着StabilityAI将面临收入压力，也凸显了公司在面对开源与商业化选择时的挑战。此前，该公司因巨额债务和CEO离职等负面事件备受关注，但坚持开源的决心彰显其对社区价值的认可。SD3架构强大，能够显著提升图像质量、支持多主题提示，并增强文字拼写能力。其核心在于MMDiT模型，结合了DiT架构与Transformer技术，专为处理文本和图像双模态任务设计。实验结果显示，SD3在人类偏好评估中超越DALL-E3和Midjourneyv6，成为领域内顶尖模型。此消息对AI社区影响重大，预示着开源合作的深化、研究方法的加速创新以及多模态功能的扩展。SD3将为开发者提供更高效、易用的工具，并可能催生更多独创性的体验。随着40亿和80亿参数版本的陆续上线，SD3有望进一步推动AI生图领域的发展。综上所述，StableDiffusion3即将开源的消息不仅对AI社区产生深远影响，也展示了开源项目在技术创新与合作中的巨大潜力。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4G2RO850511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;手机流畅运行470亿大模型上交大发布llm手机推理框架提速29倍&#34;&gt;手机流畅运行470亿大模型：上交大发布LLM手机推理框架，提速29倍&lt;/h2&gt;
&lt;p&gt;苹果公司关注在手机等移动设备上部署大型模型的趋势，但当前移动设备上的模型较小且消耗大量内存，限制了应用场景。为提供更强服务，苹果需与OpenAI合作，通过云端大模型嵌入操作系统。此方案引发隐私讨论和争议。终端侧本地部署大模型既能提供强大智能又保护隐私的安全性成为关注焦点。主要挑战包括手机内存不足和算力不够强。大型模型参数越多，对内存要求越高；现有手机硬件难以高效运行大规模模型。为解决这些挑战，上海交大IPADS实验室推出面向手机的大模型推理引擎PowerInfer-2.0，并配套大模型优化技术TurboSparse。PowerInfer-2.0能够快速在内存有限的智能手机上实现推理，让Mixtral47B模型达到11tokens/s的速度。相比热门开源推理框架llama.cpp，其推理加速比平均达25倍最高29倍。上海交大团队提出针对手机场景的优化策略，包括动态神经元缓存和基于神经元簇的异构计算，并在去年底提出的PowerInfer-1.0基础上进一步提升。针对手机内存不足问题，利用稀疏模型推理特点，PowerInfer-2.0将神经网络中的神经元分为冷、热两种，并基于LRU策略维护神经元缓存池。近期频繁激活的热神经元被放置在运行内存中，降低内存使用量。通过分段神经元缓存和神经元簇级流水线技术，PowerInfer-2.0实现I/O延迟隐藏并提高模型推理效率。实测显示，在一加12和一加Ace2两款测试手机上，PowerInfer-2.0的预填充速度显著高于llama.cpp与LLMFlash，并在解码阶段占据优势。对于Mixtral47B这类大模型，也能在手机上跑出11.68tokens/s的速度。上海交大团队还提出低成本高质量地大幅提升模型稀疏性的方法。通过引入dReLU激活函数和高质量继续训练语料库，TurboSparse系列模型不仅保持甚至超过原版模型精度，同时将稀疏度提升至三分之一。改造过程中，模型需要继续训练的token数量不到预训练总量的5%，成本极低。上海交大IPADS实验室的研究成果为大型语言模型在资源受限设备上的快速推理提供了可能，并展现出在车载设备、智能家居等方向的应用前景。未来，与手机厂商的合作有望加速相关技术落地应用。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4FTHQ410511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;估值64亿美元mistral-ai官宣64亿美元b轮融资&#34;&gt;估值64亿美元！Mistral AI官宣6.4亿美元B轮融资&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240612/ai20240612-143.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240612/ai20240612-143_hu419bcfcbda0fb2489d6a4989b49da26f_146040_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240612/ai20240612-143_hu419bcfcbda0fb2489d6a4989b49da26f_146040_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;估值64亿美元！Mistral AI官宣6.4亿美元B轮融资&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;法国AI初创公司MistralAI完成6亿欧元B轮融资，估值升至60亿欧元，较六个月前增长3倍。本轮融资由GeneralCatalyst领投，原有投资者如Lightspeed、AndreessenHorowitz、Bpifrance和法国巴黎银行等参与，企业支持者包括英伟达、Salesforce、三星和IBM。MistralAI于2023年4月在巴黎创立，由前DeepMind和Meta的科学家共同组建，专注于开源模型及企业级服务。公司已获得累计超5亿美元融资，近期发布参数规模1760亿的Mixtral8x22B模型，仅次于马斯克的Grok-1，成为市场上第二大开源模型。MistralAI被视为OpenAI在欧洲的主要竞争对手，估值达到64亿美元。MistralAI成立于巴黎，由亚瑟·门施、提摩西·拉克鲁瓦和纪尧姆·兰普创立。公司成立两个月后获得约1.13亿美元种子轮融资，同年12月A轮获得约4.15亿美元融资，估值达20亿美元。微软今年2月对MistralAI进行了小额投资，但不持有股权。MistralAI的投资者包括科技巨头如微软、英伟达和Salesforce等，以及硅谷著名风投GeneralCatalyst和AndreessenHorowitz。市场对MistralAI的信心显著提升，估值较去年12月增长了不止两倍。公司计划在开源大模型领域继续取得突破，与科技巨头竞争。MistralAI成立仅一年，在开源大模型领域取得了多项里程碑，包括发布首个生成式AI模型、具有开放权重的稀疏专家混合模型以及支持5国语言的旗舰模型等。公司还与微软建立了合作伙伴关系，利用AzureAI的超级计算基础设施进行模型训练，并提供MIstralAI模型服务。随着国内外百模大战进入深水区，资金成为关键因素。MistralAI的成功融资为AI创投圈增添信心，显示出市场对新AI大模型创企的信心。面对挑战，MistralAI需利用资金加速性能提升和产品化进程，以在竞争中脱颖而出。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4GPRO7H051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;微信公众号老牛同学&#34;&gt;微信公众号：老牛同学&lt;/h2&gt;
&lt;h3 id=&#34;qwen2-7b-开源大模型&#34;&gt;Qwen2-7B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/u_Uw88dpQRgbtfI4_1OOwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Qwen2 阿里最强开源大模型（Qwen2-7B）本地部署、API调用和WebUI对话机器人&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;llama3-8b-开源大模型&#34;&gt;Llama3-8B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;glm-4-9b-开源大模型&#34;&gt;GLM-4-9B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;chattts-文本转语音模型&#34;&gt;ChatTTS 文本转语音模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API使用和搭建WebUI界面&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;大模型应用&#34;&gt;大模型应用&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/m_O2OSoXWLL0PJurLCdzng&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;借助AI大模型，三分钟原创一部儿童故事短视频（附完整操作步骤）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;python-小游戏&#34;&gt;Python 小游戏&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hv2tE-yot_H04HCezxQWXg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI已来，我与AI一起用Python编写了一个消消乐小游戏&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/tkTlt4rbFKQ73zudluPO1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python游戏编程：一步步用Python打造经典贪吃蛇小游戏&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Qwen2 阿里最强开源大模型（Qwen2-7B）本地部署、API调用和WebUI对话机器人</title>
        <link>https://ntopic.cn/p/2024061201/</link>
        <pubDate>Wed, 12 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024061201/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024061201/01.jpg" alt="Featured image of post Qwen2 阿里最强开源大模型（Qwen2-7B）本地部署、API调用和WebUI对话机器人" /&gt;&lt;p&gt;阿里巴巴通义千问团队发布了&lt;strong&gt;Qwen2&lt;/strong&gt;系列开源模型，该系列模型包括5个尺寸的预训练和指令微调模型：&lt;strong&gt;Qwen2-0.5B&lt;/strong&gt;、&lt;strong&gt;Qwen2-1.5B&lt;/strong&gt;、&lt;strong&gt;Qwen2-7B&lt;/strong&gt;、&lt;strong&gt;Qwen2-57B-A14B&lt;/strong&gt;以及&lt;strong&gt;Qwen2-72B&lt;/strong&gt;。对比当前最优的开源模型，&lt;strong&gt;Qwen2-72B&lt;/strong&gt;在包括自然语言理解、知识、代码、数学及多语言等多项能力上均显著超越当前领先的&lt;strong&gt;Llama3-70B&lt;/strong&gt;等大模型。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/02.jpg&#34;
	width=&#34;1978&#34;
	height=&#34;1113&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/02_huf88210797b2dc3e9786f55fcb597c6f1_391069_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/02_huf88210797b2dc3e9786f55fcb597c6f1_391069_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Qwen2-72B模型评测&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;老牛同学今天部署和体验&lt;strong&gt;Qwen2-7B-Instruct&lt;/strong&gt;指令微调的中等尺寸模型，相比近期推出同等规模的开源最好的&lt;strong&gt;Llama3-8B&lt;/strong&gt;、&lt;strong&gt;GLM4-9B&lt;/strong&gt;等模型，&lt;strong&gt;Qwen2-7B-Instruct&lt;/strong&gt;依然能在多个评测上取得显著的优势，尤其是代码及中文理解上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/03.jpg&#34;
	width=&#34;1978&#34;
	height=&#34;774&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/03_hub271ce1b4c8b7c6a2b1a6f2c7c080c06_244265_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/03_hub271ce1b4c8b7c6a2b1a6f2c7c080c06_244265_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Qwen2-7B模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;255&#34;
		data-flex-basis=&#34;613px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特别注意：&lt;/strong&gt; 虽然&lt;strong&gt;Qwen2&lt;/strong&gt;开源了，但仍然需要遵循其模型许可，除&lt;strong&gt;Qwen2-72B&lt;/strong&gt;依旧使用此前的&lt;strong&gt;Qianwen License&lt;/strong&gt;外，其余系列版本模型，包括&lt;strong&gt;Qwen2-0.5B&lt;/strong&gt;、&lt;strong&gt;Qwen2-1.5B&lt;/strong&gt;、&lt;strong&gt;Qwen2-7B&lt;/strong&gt;以及&lt;strong&gt;Qwen2-57B-A14B&lt;/strong&gt;等在内，均采用&lt;strong&gt;Apache 2.0&lt;/strong&gt;许可协议。&lt;/p&gt;
&lt;h2 id=&#34;下载qwen2-7b-instruct模型文件&#34;&gt;下载Qwen2-7B-instruct模型文件&lt;/h2&gt;
&lt;p&gt;为了简化模型的部署过程，我们直接下载GGUF文件。关于GGUF文件介绍，请详见部署&lt;strong&gt;Llama3-8B&lt;/strong&gt;大模型的文章：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转AI，笔记本电脑安装属于自己的Llama 3 8B大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;打开&lt;strong&gt;Qwen2-7B-Instruct-GGUF&lt;/strong&gt;模型文件列表（&lt;a class=&#34;link&#34; href=&#34;https://modelscope.cn/models/qwen/Qwen2-7B-Instruct-GGUF/files&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://modelscope.cn/models/qwen/Qwen2-7B-Instruct-GGUF/files&lt;/a&gt;），我们选择&lt;strong&gt;qwen2-7b-instruct-q5_k_m.gguf&lt;/strong&gt;并下载：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/04.jpg&#34;
	width=&#34;978&#34;
	height=&#34;478&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/04_hu60bafbde8aee7c2346453073c7484b3b_144356_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/04_hu60bafbde8aee7c2346453073c7484b3b_144356_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Qwen2-7B量化模型文件&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;204&#34;
		data-flex-basis=&#34;491px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们可以根据自己需要，选择下载其它版本的模型文件！&lt;/p&gt;
&lt;h2 id=&#34;启动qwen2-7b-instruct大模型&#34;&gt;启动Qwen2-7B-Instruct大模型&lt;/h2&gt;
&lt;p&gt;GGUF模型量化文件下载完成后，我们就可以来运行&lt;strong&gt;Qwen2-7B&lt;/strong&gt;大模型了。&lt;/p&gt;
&lt;p&gt;在启动&lt;strong&gt;Qwen2-7B&lt;/strong&gt;大模型之前，我们首先需要安装Python依赖包列表：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install llama-cpp-python
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install openai
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install uvicorn
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install starlette
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install fastapi
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install sse_starlette
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install starlette_context
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install pydantic_settings
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后打开一个Terminal终端窗口，切换到GGUF模型文件目录，启动&lt;strong&gt;Qwen2-7B&lt;/strong&gt;大模型（&lt;code&gt;./qwen2-7b-instruct-q5_k_m.gguf&lt;/code&gt;即为上一步下载的模型文件路径）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动Qwen2大模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# n_ctx=20480代表单次回话最大20480个Token数量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python -m llama_cpp.server &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;   --host 0.0.0.0 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;   --model ./qwen2-7b-instruct-q5_k_m.gguf &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;   --n_ctx &lt;span class=&#34;m&#34;&gt;20480&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/05.jpg&#34;
	width=&#34;1170&#34;
	height=&#34;272&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/05_hucc2853454e33d0c6499a9a159f7080ed_216621_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/05_hucc2853454e33d0c6499a9a159f7080ed_216621_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Qwen2-7B启动成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;430&#34;
		data-flex-basis=&#34;1032px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;qwen2-7b-instruct-命令行对话客户端&#34;&gt;Qwen2-7B-instruct 命令行对话客户端&lt;/h2&gt;
&lt;p&gt;CLI命令行的客户端，可以参考之前&lt;strong&gt;LLama3-8B&lt;/strong&gt;大模型的文章：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# client.py&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;openai&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 注意服务端端口，因为是本地，所以不需要api_key&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base_url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http://127.0.0.1:8000/v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;n&#34;&gt;api_key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;not-needed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 对话历史：设定系统角色是一个只能助理，同时提交“自我介绍”问题&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;history&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;你是一个智能助理，你的回答总是容易理解的、正确的、有用的和内容非常精简.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 首次自我介绍完毕，接下来是等代码我们的提示&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;completions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;local-model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;stream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flush&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[91;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;user_input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;gt; &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user_input&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lower&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;bye&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;quit&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;exit&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]:&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 我们输入bye/quit/exit等均退出客户端&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[0mBYE BYE!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[92;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动CLI对话客户端：&lt;code&gt;python client.py&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/06.jpg&#34;
	width=&#34;1436&#34;
	height=&#34;432&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/06_hucac271893c7217732b377f035bec04d3_467256_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/06_hucac271893c7217732b377f035bec04d3_467256_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Qwen2-7B启动成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;332&#34;
		data-flex-basis=&#34;797px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;至此，我们可以与&lt;strong&gt;Qwen2-7B-Instruct&lt;/strong&gt;进行对话，体验Qwen2大模型的魅力了。&lt;/p&gt;
&lt;p&gt;如果我们主要是通过API的方式使用&lt;strong&gt;Qwen2&lt;/strong&gt;大模型，那么Qwen2部署就到此结束了。&lt;/p&gt;
&lt;p&gt;接下来的章节，我们部署WebUI对话客户端，通过Web界面的方式使用&lt;strong&gt;Qwen2&lt;/strong&gt;大模型，并且可以分享出去~&lt;/p&gt;
&lt;h2 id=&#34;qwen2-7b-instruct-webui客户端&#34;&gt;Qwen2-7B-Instruct WebUI客户端&lt;/h2&gt;
&lt;p&gt;结合&lt;strong&gt;Ollama&lt;/strong&gt;工具，搭建WebUI客户端，可参考之前&lt;strong&gt;Llama3-8B&lt;/strong&gt;大模型的文章：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于Ollama工具的LLM大语言模型Web可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一步：&lt;/strong&gt; 我们需要下载安装&lt;strong&gt;Ollama&lt;/strong&gt;本地大模型管理工具：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Ollama&lt;/code&gt;提供了&lt;strong&gt;MacOS&lt;/strong&gt;、&lt;strong&gt;Linux&lt;/strong&gt;和&lt;strong&gt;Windows&lt;/strong&gt;操作系统的安装包，大家可根据自己的操作系统，下载安装即可：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/07.jpg&#34;
	width=&#34;1184&#34;
	height=&#34;868&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/07_hude0f3d67b6b85e3d467df24bc32af0f9_137925_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/07_hude0f3d67b6b85e3d467df24bc32af0f9_137925_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ollama下载&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;327px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;安装包下载之后的安装过程，和日常安装其他软件没有差别，包括点击&lt;code&gt;Next&lt;/code&gt;以及&lt;code&gt;Install&lt;/code&gt;等安装&lt;code&gt;ollama&lt;/code&gt;到命令行。安装后续步骤中，我们可无需安装任何模型，因为我们在上文中我们已经安装了&lt;code&gt;Qwen2-7B&lt;/code&gt;大模型，后面可以直接使用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二步：&lt;/strong&gt; 安装&lt;code&gt;Node.js&lt;/code&gt;编程语言工具包&lt;/p&gt;
&lt;p&gt;安装&lt;code&gt;Node.js&lt;/code&gt;编程语言工具包和安装其他软件包一样，下载安装即可：&lt;a class=&#34;link&#34; href=&#34;https://nodejs.org&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://nodejs.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/08.jpg&#34;
	width=&#34;1282&#34;
	height=&#34;1250&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/08_hu04a0d0b576f5a114bd323b776e7ca4ec_519318_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/08_hu04a0d0b576f5a114bd323b776e7ca4ec_519318_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Node.js下载&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;102&#34;
		data-flex-basis=&#34;246px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;安装完成之后，可以验证一下 Node.js 的版本，建议用目前的最新&lt;strong&gt;v20&lt;/strong&gt;版本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;node -v
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;老牛同学安装的版本：&lt;strong&gt;v20.13.1&lt;/strong&gt;（最新版本）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第三步：&lt;/strong&gt; 基于GGUF模型文件创建&lt;code&gt;Ollama&lt;/code&gt;模型&lt;/p&gt;
&lt;p&gt;在我们存放&lt;code&gt;Qwen2-7B&lt;/code&gt;的 GGUF 模型文件目录中，创建一个文件名为&lt;code&gt;Modelfile&lt;/code&gt;的文件，该文件的内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM ./qwen2-7b-instruct-q5_k_m.gguf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后在Terminal终端，使用这个文件创建&lt;code&gt;Ollama&lt;/code&gt;模型，这里我把&lt;code&gt;Ollama&lt;/code&gt;的模型取名为&lt;strong&gt;Qwen2-7B&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ ollama create Qwen2-7B -f ./Modelfile
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;transferring model data 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;using existing layer sha256:258dd2fa1bdf98b85327774e1fd36e2268c2a4b68eb9021d71106449ee4ba9d5 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;creating new layer sha256:14f4474ef69698bf4dbbc7409828341fbd85923319a801035e651d9fe6a9e9c9 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;writing manifest 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;success
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;最后，通过&lt;code&gt;Ollama&lt;/code&gt;启动我们刚创建的大语言模型：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run Qwen2-7B
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动完毕，其实我们已经有了一个和之前差不多的控制台对话界面，也可以与&lt;code&gt;Qwen2-7B&lt;/code&gt;对话了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/09.jpg&#34;
	width=&#34;1626&#34;
	height=&#34;522&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/09_hub8429b6002d338834396d0d717f20700_697066_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/09_hub8429b6002d338834396d0d717f20700_697066_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ollama启动模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;311&#34;
		data-flex-basis=&#34;747px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如果我们不想要这个模型了，也可以通过命令行删除模型文件：&lt;code&gt;ollama rm Qwen2-7B&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我们也可以查看本地&lt;strong&gt;Ollama&lt;/strong&gt;管理的模型列表：&lt;code&gt;ollama list&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Ollama&lt;/code&gt;存放模型文件根目录：&lt;code&gt;~/.ollama&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第四步：&lt;/strong&gt; 部署&lt;code&gt;Ollama&lt;/code&gt;大模型Web对话界面&lt;/p&gt;
&lt;p&gt;控制台聊天对话界面体验总归是不太好，接下来部署 Web 可视化聊天界面。&lt;/p&gt;
&lt;p&gt;首先，下载&lt;code&gt;ollama-webui&lt;/code&gt;Web 工程代码：&lt;code&gt;git clone https://github.com/ollama-webui/ollama-webui-lite&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然后切换&lt;code&gt;ollama-webui&lt;/code&gt;代码的目录：&lt;code&gt;cd ollama-webui-lite&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;设置 Node.js 工具包镜像源，以接下来下载 Node.js 的依赖包更加快速：&lt;code&gt;npm config set registry http://mirrors.cloud.tencent.com/npm/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;安装 Node.js 依赖的工具包：&lt;code&gt;npm install&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;最后，启动 Web 可视化界面：&lt;code&gt;npm run dev&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/10.jpg&#34;
	width=&#34;824&#34;
	height=&#34;270&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/10_hu197c9156a112ece4d67099f8d904a84b_147151_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/10_hu197c9156a112ece4d67099f8d904a84b_147151_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;WebUI启动成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;305&#34;
		data-flex-basis=&#34;732px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如果看到以上输出，代表 Web 可视化界面已经成功了！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第五步：&lt;/strong&gt; 通过WebUI愉快与&lt;strong&gt;Qwen2-7B&lt;/strong&gt;对话&lt;/p&gt;
&lt;p&gt;浏览器打开 Web 可视化界面：&lt;a class=&#34;link&#34; href=&#34;http://localhost:3000&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以看到&lt;code&gt;Ollama&lt;/code&gt;的初始化页面，默认没有模型，需要选择，我们选择刚创建并部署的&lt;code&gt;Qwen2-7B&lt;/code&gt;模型：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024061201/11.jpg&#34;
	width=&#34;1476&#34;
	height=&#34;684&#34;
	srcset=&#34;https://ntopic.cn/p/2024061201/11_hu0fb10bb63d1e0f985629debcce25c502_144513_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024061201/11_hu0fb10bb63d1e0f985629debcce25c502_144513_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;选择Qwen2-7B大模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;215&#34;
		data-flex-basis=&#34;517px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;底部就是聊天输入框，至此可以愉快的与&lt;code&gt;Qwen2-7B&lt;/code&gt;聊天对话了：&lt;/p&gt;
&lt;h2 id=&#34;总结qwen2-7b比llama3-8b快&#34;&gt;总结：Qwen2-7B比Llama3-8B快&lt;/h2&gt;
&lt;p&gt;老牛同学验证和对比，在文本推理上，&lt;strong&gt;Qwen2-7B&lt;/strong&gt;确实比&lt;strong&gt;Llama3-8B&lt;/strong&gt;要快很多。后续老牛同学中文文本推理相关的API接口，就主要采用更快&lt;strong&gt;Qwen2-7B&lt;/strong&gt;大模型了~&lt;/p&gt;
&lt;h2 id=&#34;其他ollama工具常用用法&#34;&gt;其他：&lt;code&gt;Ollama&lt;/code&gt;工具常用用法&lt;/h2&gt;
&lt;p&gt;从上文的介绍可以看到，基于&lt;code&gt;Ollama&lt;/code&gt;部署一个大模型的 Web 可视化对话机器人，还是非常方便。下面整理了部分&lt;code&gt;Ollama&lt;/code&gt;提供的用法或者。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ollama 命令&lt;/strong&gt;工具&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 查看当前Ollama的模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama list
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 增量更新当前部署的模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama pull Qwen2-7B
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 删除一个模型文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama rm Qwen2-7B
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 复制一个模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama cp Qwen2-7B Qwen2-newModel
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Ollama API&lt;/strong&gt;结果返回&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl http://localhost:11434/api/generate -d &lt;span class=&#34;s1&#34;&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;model&amp;#34;: &amp;#34;Qwen2-7B&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;prompt&amp;#34;:&amp;#34;为什么天空是蓝色的？&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Ollama API&lt;/strong&gt;聊天对话&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl http://localhost:11434/api/chat -d &lt;span class=&#34;s1&#34;&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;model&amp;#34;: &amp;#34;Qwen2-7B&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    { &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;为什么天空是蓝色的？&amp;#34; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;微信公众号老牛同学&#34;&gt;微信公众号：老牛同学&lt;/h2&gt;
&lt;h3 id=&#34;qwen2-7b-开源大模型&#34;&gt;Qwen2-7B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/u_Uw88dpQRgbtfI4_1OOwQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Qwen2阿里最强开源大模型（Qwen2-7B）本地部署、API调用和WebUI对话机器人&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;llama-3-8b-开源大模型&#34;&gt;Llama-3-8B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;glm-4-9b-开源大模型&#34;&gt;GLM-4-9B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;chattts-文本转语音模型&#34;&gt;ChatTTS 文本转语音模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API使用和搭建WebUI界面&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;大模型应用&#34;&gt;大模型应用&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/m_O2OSoXWLL0PJurLCdzng&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;借助AI大模型，三分钟原创一部儿童故事短视频（附完整操作步骤）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;python-小游戏&#34;&gt;Python 小游戏&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hv2tE-yot_H04HCezxQWXg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI已来，我与AI一起用Python编写了一个消消乐小游戏&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/tkTlt4rbFKQ73zudluPO1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python游戏编程：一步步用Python打造经典贪吃蛇小游戏&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AI资讯·0609] SamAltman建立了庞大投资帝国，但不持OpenAI股票；个人资产包括房产和多家公司股权。他曾在YCombinator担任总裁，并投资40家公司，有五家估值增长100倍以上。尽管他不参与OpenAI决策，但其利益与公司业务存在复杂关系，引发监督和透明度争议。</title>
        <link>https://ntopic.cn/p/ai20240609/</link>
        <pubDate>Sun, 09 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240609/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240609/ai20240609-107.jpg" alt="Featured image of post [AI资讯·0609] SamAltman建立了庞大投资帝国，但不持OpenAI股票；个人资产包括房产和多家公司股权。他曾在YCombinator担任总裁，并投资40家公司，有五家估值增长100倍以上。尽管他不参与OpenAI决策，但其利益与公司业务存在复杂关系，引发监督和透明度争议。" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;奥特曼28亿「投资帝国」曝光！不要OpenAI股份，当CEO最不赚钱&lt;/li&gt;
&lt;li&gt;开源超闭源！通义千问Qwen2发布即爆火，网友：GPT-4o危&lt;/li&gt;
&lt;li&gt;OpenAI泄密者公布165页文件：2027年实现AGI、计算集群将耗资千亿美元&lt;/li&gt;
&lt;li&gt;清华系细胞大模型登Nature子刊！能对人类2万基因同时建模&lt;/li&gt;
&lt;li&gt;奥特曼百万年薪挖角谷歌TPU人才，欲砸7万亿实现「芯片自由」？OpenAI自研芯&lt;/li&gt;
&lt;li&gt;GPT-4欺骗人类高达99.16%惊人率！PNAS重磅研究曝出，LLM推理越强欺骗值越高&lt;/li&gt;
&lt;li&gt;苹果AI升级大泄露，Siri将在iOS18重生！库克用Apple重新定义AI&lt;/li&gt;
&lt;li&gt;港大北航等1bit大模型引热议，IEEE刊物评“解决AI能源需求”！&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;奥特曼28亿投资帝国曝光不要openai股份当ceo最不赚钱&#34;&gt;奥特曼28亿「投资帝国」曝光！不要OpenAI股份，当CEO最不赚钱&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240609/ai20240609-97.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240609/ai20240609-97_hu4d3c8b950bdf6328e9726a3c4b7eb153_126034_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240609/ai20240609-97_hu4d3c8b950bdf6328e9726a3c4b7eb153_126034_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;奥特曼28亿「投资帝国」曝光！不要OpenAI股份，当CEO最不赚钱&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;SamAltman成立了一个庞大的投资帝国，但他本人不持有OpenAI股票，只拿微薄年薪6.5万美元。他的个人资产包括至少三处房产和多个公司股权，管理这些资产的家族办公室如同成熟风投公司。他曾在YCombinator担任总裁，投资了40家公司，其中有五家估值增长100倍或以上。尽管他不参与OpenAI决策，但其个人利益与公司业务存在复杂关系，引发了监督和透明度的争议。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4894TB90511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;开源超闭源通义千问qwen2发布即爆火网友gpt-4o危&#34;&gt;开源超闭源！通义千问Qwen2发布即爆火，网友：GPT-4o危&lt;/h2&gt;
&lt;p&gt;摘要：阿里巴巴推出全新开源大模型Qwen2，性能全面超越Llama3，仅两小时内登顶HuggingFace开源大模型榜单第一。Qwen2-72B在十几项国际权威测评中胜过Llama3-70B，尤其在HumanEval、MATH等测试代码和数学能力的基准中表现突出。国产大模型Qwen2-72B也超越了国内一众闭源大模型。在GQA机制的全面加持下，全系列模型支持128K上下文长度，且小模型采用了tieembedding技术，提高参数效率。Qwen2在数学能力和多语言处理方面也有显著提升。开源社区反馈积极，下载量超3万次，生态建设活跃。Qwen2的成功证明中国开源大模型已具备与美国Llama3全面对抗的硬实力，预示着开源大模型将超越闭源模式，成为未来AI发展的主流趋势。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J45SA74S0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;openai泄密者公布165页文件2027年实现agi计算集群将耗资千亿美元&#34;&gt;OpenAI泄密者公布165页文件：2027年实现AGI、计算集群将耗资千亿美元&lt;/h2&gt;
&lt;p&gt;1.OpenAI前员工利奥波德·阿申布伦纳（LeopoldAschenbrenner）因泄露内部信息被开除，但他声称是因为分享安全备忘录而被开除。2.阿申布伦纳在Dwarkesh播客上发表了长达165页的PDF文档，预测AI趋势，并提到AGI（通用人工智能）可能在2027年实现。3.他认为AI系统将超越人类水平，不仅能完成研究人员和工程师的工作，还可能导致自动化AI研究，进步速度加快。4.AI发展面临四大瓶颈：算力限制、长尾效应、算法进步内在限制和创新难度提升。5.阿申布伦纳估计到2030年将实现超级智能，AI系统可能拥有数十亿个GPU，能够在几周内获取人类几十亿年才能积累的经验。6.他认为智能爆炸将是人类历史上最不稳定和危险时期之一，需要巨大的努力来完成过渡。7.AI投资预计到2030年达到8万亿美元，但可能面临电力供应限制。8.目前用于对齐AI系统的技术“人类反馈强化学习”（RLHF）将在超级智能时代崩溃，需要新的技术解决方案。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J454LG3M051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;清华系细胞大模型登nature子刊能对人类2万基因同时建模&#34;&gt;清华系细胞大模型登Nature子刊！能对人类2万基因同时建模&lt;/h2&gt;
&lt;p&gt;清华大学等团队推出单细胞基因表达预测大模型scFoundation，登陆NatureMethods。该模型基于5000万人类单细胞数据，拥有1亿参数，能处理20000个基因。它在细胞测序深度增强、药物响应和细胞扰动预测等任务中表现出色，为基因网络研究提供了新的思路。此外，模型的训练框架创新，计算效率提升30%，并开源代码及API，方便用户应用。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J45TJOCH0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;奥特曼百万年薪挖角谷歌tpu人才欲砸7万亿实现芯片自由openai自研芯&#34;&gt;奥特曼百万年薪挖角谷歌TPU人才，欲砸7万亿实现「芯片自由」？OpenAI自研芯&lt;/h2&gt;
&lt;p&gt;OpenAI正在积极推进自研芯片计划，旨在减少对英伟达芯片的依赖，并扩展其芯片研发团队。据SemiAnalysis报道，OpenAI正从谷歌TPU团队招募人才，以加强自身技术实力。OpenAI认为传统芯片制造商如台积电、三星代工和英特尔代工无法满足全球对AI芯片快速增长的需求。SamAltman计划在未来几年内与SoftBankCEO和台积电代表会谈，共同建造和运营数十座芯片制造工厂。然而，建设新芯片需要巨额资金，估计成本高达5-7万亿美元。OpenAI正在大规模招聘，计划将芯片团队扩展到几十人，并且主要从谷歌TPU团队挖角。TPU是专为机器学习和神经网络计算设计的芯片，与GPU不同，它能更高效地执行张量运算。OpenAI希望通过自研芯片实现技术创新和成本控制，构建由数百万个加速器组成的大型系统。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J45QPOJ80511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;gpt-4欺骗人类高达9916惊人率pnas重磅研究曝出llm推理越强欺骗值越高&#34;&gt;GPT-4欺骗人类高达99.16%惊人率！PNAS重磅研究曝出，LLM推理越强欺骗值越高&lt;/h2&gt;
&lt;p&gt;德国研究人员发现LLM（大型语言模型）已展现出欺骗能力，能够理解并诱导欺骗策略。最新的GPT-4和ChatGPT在欺骗任务中表现显著提升，甚至能在99.16%情况下欺骗人类。研究警告称，随着AI技术的发展，未来可能出现更高级“流氓”AI，需要对LLM进行严格控制以防止其逃脱监管。当前研究中，通过CoT（自我反省）等技巧可以增强欺骗能力，但是否将这些模型用于欺骗行为的伦理问题仍需进一步探讨。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J4892IDB0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;苹果ai升级大泄露siri将在ios18重生库克用apple重新定义ai&#34;&gt;苹果AI升级大泄露，Siri将在iOS18重生！库克用Apple重新定义AI&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240609/ai20240609-107.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240609/ai20240609-107_hue0ce09b87426ee90fba054f860e0888d_40075_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240609/ai20240609-107_hue0ce09b87426ee90fba054f860e0888d_40075_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;苹果AI升级大泄露，Siri将在iOS18重生！库克用Apple重新定义AI&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;苹果即将举行的WWDC会议中，Siri在iOS18中的升级细节被泄露。Siri将在相机、日历备忘录和浏览器等原生应用中实现全面的AI武装。新功能包括：通过语音控制相机模式设置；编辑、移动和隐藏照片；识别照片中的对象或场景；智能管理备忘录和录音；自动分类和回复邮件；在Keynote中添加音频和视频；创建和管理提醒事项等。Safari也将引入新的智能浏览功能，提供文章摘要，并可能包括WebEraser内容拦截器（但该功能可能会被删除以避免争议）。此外，Siri还将在系统设置、文件应用中进行扫描和编辑通讯录等操作。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J48FLQEB0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;港大北航等1bit大模型引热议ieee刊物评解决ai能源需求&#34;&gt;港大北航等1bit大模型引热议，IEEE刊物评“解决AI能源需求”！&lt;/h2&gt;
&lt;p&gt;本文介绍了一种名为BiLLM的训练后量化（PTQ）方法，成功将大型语言模型（LLM）的参数压缩到1.1bit。该方法通过对权重分布的研究发现，大多数参数在模型中的贡献不大，而少部分关键参数对性能影响巨大。BiLLM采用了通道级别的分组策略和二阶残差逼近法来处理显著权重，使用最优钟形分组方法量化非显著权重，有效降低了量化误差。此外，BiLLM在多个评价指标上超越了2-bit的GPTQ、PB-LLM等其他方法，并在某些模型体积上接近3-bit权重的性能。这种技术有望推动LLM无需训练的量化边界，并使其能够更方便地部署到资源受限的设备中，如手机等。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J48K7L4P0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;微信公众号老牛同学&#34;&gt;微信公众号：老牛同学&lt;/h2&gt;
&lt;h3 id=&#34;llama-3-8b-开源大模型&#34;&gt;Llama-3-8B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;glm-4-9b-开源大模型&#34;&gt;GLM-4-9B 开源大模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;chattts-文本转语音模型&#34;&gt;ChatTTS 文本转语音模型&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatTTS 开源文本转语音模型本地部署、API使用和搭建WebUI界面&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;大模型应用&#34;&gt;大模型应用&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/m_O2OSoXWLL0PJurLCdzng&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;借助AI大模型，三分钟原创一部儿童故事短视频（附完整操作步骤）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/gaLw3yP-oANvQyjRSkVjyw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;高效编写大模型 Prompt 提示词，解锁 AI 无限创意潜能&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;python-小游戏&#34;&gt;Python 小游戏&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/hv2tE-yot_H04HCezxQWXg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI已来，我与AI一起用Python编写了一个消消乐小游戏&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/tkTlt4rbFKQ73zudluPO1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python游戏编程：一步步用Python打造经典贪吃蛇小游戏&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>ChatTTS 开源文本转语音模型本地部署、API使用和搭建WebUI界面（建议收藏）</title>
        <link>https://ntopic.cn/p/2024060901/</link>
        <pubDate>Sun, 09 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024060901/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024060901/00.jpg" alt="Featured image of post ChatTTS 开源文本转语音模型本地部署、API使用和搭建WebUI界面（建议收藏）" /&gt;&lt;p&gt;&lt;strong&gt;ChatTTS&lt;/strong&gt;（Chat Text To Speech）是专为对话场景设计的文本生成语音(TTS)模型，特别适用于大型语言模型(&lt;strong&gt;LLM&lt;/strong&gt;)助手的对话任务，以及诸如对话式音频和视频介绍等应用。它支持中文和英文，还可以穿插笑声、说话间的停顿、以及语气词等，听起来很真实自然，在语音合成中表现出高质量和自然度（ChatTTS团队声称：&lt;strong&gt;突破开源天花板&lt;/strong&gt;）。&lt;/p&gt;
&lt;p&gt;同时，&lt;strong&gt;ChatTTS&lt;/strong&gt;模型文件总大小&lt;strong&gt;1.1GB&lt;/strong&gt;左右，常用的个人笔记本电脑均可部署，因此涉及到文本转语音场景，均可以自己操作转换了！&lt;/p&gt;
&lt;h2 id=&#34;chattts特点&#34;&gt;ChatTTS特点&lt;/h2&gt;
&lt;p&gt;由于ChatTTS以下极具吸引人的特点，使得它一经推出就成为了爆款：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;多语言支持&lt;/strong&gt;：ChatTTS的一个关键特性是支持多种语言，包括英语和中文。这使其能够为广泛用户群提供服务，并克服语言障碍。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;大规模数据训练&lt;/strong&gt;：ChatTTS使用了大量数据进行训练，大约有1000万小时的中文和英文数据。这样的大规模训练使其声音合成质量高，听起来自然。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对话任务兼容性&lt;/strong&gt;：ChatTTS很适合处理通常分配给大型语言模型LLMs的对话任务。它可以为对话生成响应，并在集成到各种应用和服务时提供更自然流畅的互动体验。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开源计划&lt;/strong&gt;：ChatTTS团队目前开源一个经过训练的基础模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;控制和安全性&lt;/strong&gt;：ChatTTS致力于提高模型的可控性，添加水印，并将其与LLMs集成。这些努力确保了模型的安全性和可靠性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;易用性&lt;/strong&gt;：ChatTTS为用户提供了易于使用的体验。它只需要文本信息作为输入，就可以生成相应的语音文件。这样的简单性使其方便有语音合成需求的用户。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;下载chattts模型文件&#34;&gt;下载ChatTTS模型文件&lt;/h2&gt;
&lt;p&gt;因最大模型文件超过&lt;strong&gt;900MB&lt;/strong&gt;，为了防止使用Git无法直接下载到本地，我们通过&lt;strong&gt;git-lfs&lt;/strong&gt;工具包下载：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;brew install git-lfs
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;通过Git复制模型文件到笔记本电脑（文件夹：&lt;code&gt;ChatTTS-Model&lt;/code&gt;）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs install
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://www.modelscope.cn/pzc163/chatTTS.git ChatTTS-Model
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果因网络不佳等原因，下载中断，我们可以通过以下命令在中断后继续下载：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs pull
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024060901/01.jpg&#34;
	width=&#34;880&#34;
	height=&#34;1040&#34;
	srcset=&#34;https://ntopic.cn/p/2024060901/01_hu0cecdcf1d02b8238d4903c61a6ed8570_88613_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024060901/01_hu0cecdcf1d02b8238d4903c61a6ed8570_88613_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;ChatTTS模型文件列表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;84&#34;
		data-flex-basis=&#34;203px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;安装chattts依赖包列表&#34;&gt;安装ChatTTS依赖包列表&lt;/h2&gt;
&lt;p&gt;下载&lt;strong&gt;ChatTTS&lt;/strong&gt;官网GitHub源码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://gitcode.com/2noise/ChatTTS.git ChatTTS
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;进入源码目录，批量安装&lt;strong&gt;Python依赖包&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;特别注意&lt;/strong&gt;：如果下载过程中，若出现找不到&lt;code&gt;torch&lt;/code&gt;的&lt;strong&gt;2.1.0&lt;/strong&gt;版本错误，请修改&lt;code&gt;requirements.txt&lt;/code&gt;文件，把&lt;code&gt;torch&lt;/code&gt;的版本修改为&lt;strong&gt;2.2.2&lt;/strong&gt;后再次执行安装：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024060901/02.jpg&#34;
	width=&#34;1738&#34;
	height=&#34;254&#34;
	srcset=&#34;https://ntopic.cn/p/2024060901/02_hu12d2ec1bd0e499243be9e637712776c8_118940_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024060901/02_hu12d2ec1bd0e499243be9e637712776c8_118940_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;torch版本找不到&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;684&#34;
		data-flex-basis=&#34;1642px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Python依赖包列表&lt;code&gt;requirements.txt&lt;/code&gt;文件如下，我们也可以手工一个一个的进行安装，无需下载整个源码（注意：&lt;code&gt;torch&lt;/code&gt;的版本号为&lt;strong&gt;2.2.2&lt;/strong&gt;）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;omegaconf~=2.3.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;torch~=2.2.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tqdm
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;einops
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vector_quantize_pytorch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;transformers~=4.41.1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vocos
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;IPython
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;chattts中文文本转音频文件&#34;&gt;ChatTTS中文文本转音频文件&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;特别注意&lt;/strong&gt;：经老牛同学的验证，&lt;strong&gt;ChatTTS&lt;/strong&gt;官网的样例代码API已经过时，无法直接运行，特别是&lt;code&gt;chat.load_models&lt;/code&gt;方法入参是错误的，下面是老牛同学通过阅读API入参且验证的可执行代码。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ChatTTS-01.py&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ChatTTS&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torchaudio&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 第一步下载的ChatTTS模型文件目录，请按照实际情况替换&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/obullxl/PythonSpace/ChatTTS-Model&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 初始化并加载模型，特别注意加载模型参数，官网样例代码已经过时，请使用老牛同学验证代码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ChatTTS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Chat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_models&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;vocos_config_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/config/vocos.yaml&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;vocos_ckpt_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/asset/Vocos.pt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;gpt_config_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/config/gpt.yaml&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;gpt_ckpt_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/asset/GPT.pt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;decoder_config_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/config/decoder.yaml&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;decoder_ckpt_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/asset/Decoder.pt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;tokenizer_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/asset/tokenizer.pt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 需要转化为音频的文本内容&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;大家好，我是老牛，微信公众号：老牛同学。很高兴与您相遇，专注于编程技术、大模型及人工智能等相关技术分享，欢迎关注和转发，让我们共同启程智慧之旅！&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 文本转为音频&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;wavs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;infer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;use_decoder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 保存音频文件到本地文件（采样率为24000Hz）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torchaudio&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;save&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;./output/output-01.wav&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_numpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wavs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;24000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;运作Python代码：&lt;code&gt;python ChatTTS-01.py&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ python ChatTTS-01.py
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WARNING:ChatTTS.utils.gpu_utils:No GPU found, use CPU instead
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;INFO:ChatTTS.core:use cpu
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;INFO:ChatTTS.core:vocos loaded.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;INFO:ChatTTS.core:gpt loaded.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;INFO:ChatTTS.core:decoder loaded.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;INFO:ChatTTS.core:tokenizer loaded.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WARNING:ChatTTS.core:dvae not initialized.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;INFO:ChatTTS.core:All initialized.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 20%|██████████████████████████▌                    | 76/384 [00:08&amp;lt;00:35,  8.62it/s]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 26%|██████████████████████████████████▌            | 536/2048 [00:48&amp;lt;02:17, 10.98it/s]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;上述文本转音频程序执行完成，在本地目录生成了&lt;code&gt;./output/output-01.wav&lt;/code&gt;音频文件，打开该音频文件，就可以听到非常自然流畅的语音了！&lt;/p&gt;
&lt;p&gt;我们也可以在文本转换成语音之后，直接播放语音内容：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# …… 其他包引用省略&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;IPython.display&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Audio&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# …… 其他部分代码省略&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 播放生成的音频（autoplay=True 代表自动播放）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Audio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wavs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;24000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;autoplay&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;快速搭建webui界面&#34;&gt;快速搭建WebUI界面&lt;/h2&gt;
&lt;p&gt;上面我们通过Python代码生成了音频文件，操作起来比较麻烦，现在我们构建一个WebUI可视化界面：&lt;/p&gt;
&lt;p&gt;首先安装Python依赖包，列表如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install omegaconf~&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;2.3.0 transformers~&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;4.41.1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install tqdm einops vector_quantize_pytorch vocos
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install modelscope gradio
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;运行Python程序，即可看到可视化界面，我们可以随意输入文本来生成音频文件了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024060901/04.jpg&#34;
	width=&#34;2464&#34;
	height=&#34;1484&#34;
	srcset=&#34;https://ntopic.cn/p/2024060901/04_hufe923a50629dd622bb6d8bd4dac41683_425874_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024060901/04_hufe923a50629dd622bb6d8bd4dac41683_425874_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;WebUI可视化界面&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;398px&#34;
	
&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;  1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 98
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 99
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;100
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;101
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;102
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;103
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;104
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;105
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;106
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;107
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;108
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;109
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;110
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;111
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;112
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ChatTTS-WebUI.py&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;random&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ChatTTS&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gradio&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gr&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ChatTTS.infer.api&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;refine_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;infer_code&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;启动ChatTTS WebUI......&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# WebUI设置&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;WEB_HOST&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;WEB_PORT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8089&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/obullxl/PythonSpace/ChatTTS-Model&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ChatTTS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Chat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_models&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;vocos_config_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/config/vocos.yaml&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;vocos_ckpt_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/asset/Vocos.pt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;gpt_config_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/config/gpt.yaml&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;gpt_ckpt_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/asset/GPT.pt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;decoder_config_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/config/decoder.yaml&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;decoder_ckpt_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/asset/Decoder.pt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;tokenizer_path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/asset/tokenizer.pt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;generate_seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;new_seed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100000000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;__type__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;update&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;new_seed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;generate_audio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;top_P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;top_K&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;audio_seed_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text_seed_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;refine_text_flag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manual_seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;audio_seed_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;rand_spk&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;768&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;params_infer_code&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s1&#34;&gt;&amp;#39;spk_emb&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rand_spk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s1&#34;&gt;&amp;#39;temperature&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s1&#34;&gt;&amp;#39;top_P&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;top_P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s1&#34;&gt;&amp;#39;top_K&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;top_K&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;params_refine_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;prompt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;[oral_2][laugh_0][break_6]&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manual_seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text_seed_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;text_tokens&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;refine_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pretrain_models&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;params_refine_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ids&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;text_tokens&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pretrain_models&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;tokenizer&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;convert_tokens_to_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;[break_0]&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text_tokens&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pretrain_models&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;tokenizer&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch_decode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text_tokens&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# result = infer_code(chat.pretrain_models, text, **params_infer_code, return_hidden=True)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ChatTTS微调文本：&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;wav&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;infer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                     &lt;span class=&#34;n&#34;&gt;params_refine_text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;params_refine_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                     &lt;span class=&#34;n&#34;&gt;params_infer_code&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;params_infer_code&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                     &lt;span class=&#34;n&#34;&gt;use_decoder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                     &lt;span class=&#34;n&#34;&gt;skip_refine_text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                     &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;audio_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wav&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flatten&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sample_rate&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;24000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;text_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;isinstance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sample_rate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;audio_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Blocks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;default_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;大家好，我是老牛同学，微信公众号：老牛同学。很高兴与您相遇，专注于编程技术、大模型及人工智能等相关技术分享，欢迎关注和转发，让我们共同启程智慧之旅！&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;text_input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Textbox&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;输入文本&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lines&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;placeholder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Please Input Text...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;default_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;refine_text_checkbox&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Checkbox&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;文本微调开关&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;temperature_slider&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Slider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;minimum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.00001&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;maximum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.00001&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;语音温度参数&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;top_p_slider&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Slider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;minimum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;maximum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;语音top_P采样参数&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;top_k_slider&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Slider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;minimum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;maximum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;语音top_K采样参数&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;audio_seed_input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;语音随机数&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;generate_audio_seed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Button&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\U0001F3B2&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;text_seed_input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;文本随机数&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;generate_text_seed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Button&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\U0001F3B2&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;generate_button&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Button&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;文本生成语音&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;text_output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Textbox&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;微调文本&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interactive&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;audio_output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Audio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;语音&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;generate_audio_seed&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;click&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;generate_seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;audio_seed_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;generate_text_seed&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;click&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;generate_seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                 &lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                 &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text_seed_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;generate_button&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;click&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;generate_audio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                              &lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;temperature_slider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;top_p_slider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;top_k_slider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;audio_seed_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text_seed_input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;refine_text_checkbox&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                              &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;audio_output&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text_output&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 启动WebUI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;launch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;server_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;server_port&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8089&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;share&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;show_api&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;vm&#34;&gt;__name__&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;最后，运行WebUI程序，就可以享受可视化文本生成语音功能了：&lt;code&gt;python ChatTTS-WebUI.py&lt;/code&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;部署&lt;strong&gt;Llama 3 8B&lt;/strong&gt;开源大模型：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;部署&lt;strong&gt;Llama 3 8B&lt;/strong&gt;Web版对话机器人：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;部署中文版**Llama 3（Llama3-Chinese-Chat）**大模型：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验</title>
        <link>https://ntopic.cn/p/2024060801/</link>
        <pubDate>Sat, 08 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024060801/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024060801/00.jpg" alt="Featured image of post 本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验" /&gt;&lt;p&gt;&lt;strong&gt;GLM-4-9B&lt;/strong&gt;是清华大学和智谱AI推出的最新一代预训练模型&lt;strong&gt;GLM-4&lt;/strong&gt;系列中的开源版本。在语义、数学、推理、代码和知识等多方面的数据集测评中，&lt;strong&gt;GLM-4-9B&lt;/strong&gt;及其人类偏好对齐的版本&lt;strong&gt;GLM-4-9B-Chat&lt;/strong&gt;均表现出较高的性能，其通用能力评测结果甚至超越了&lt;strong&gt;Llama-3-8B&lt;/strong&gt;开源大模型，多模态版本也与&lt;strong&gt;GPT-4&lt;/strong&gt;版本齐平。&lt;/p&gt;
&lt;p&gt;除了能进行多轮对话，&lt;strong&gt;GLM-4-9B-Chat&lt;/strong&gt;还具备网页浏览、代码执行、自定义工具调用和长文本推理等高级功能。 &lt;strong&gt;GLM-4&lt;/strong&gt;模型增加了多语言支持，支持包括日语，韩语，德语在内的 26 种语言。&lt;strong&gt;GLM-4-9B&lt;/strong&gt;还推出了支持 1M 上下文长度（约 200 万中文字符）的模型。&lt;/p&gt;
&lt;p&gt;根据&lt;strong&gt;GLM-4&lt;/strong&gt;大模型评测结果，在通用能力方面超越&lt;strong&gt;Llama3&lt;/strong&gt;大模型，在多模态能力比肩&lt;strong&gt;GPT-4&lt;/strong&gt;大模型系列版本，评测结果和调用方法详情：&lt;a class=&#34;link&#34; href=&#34;https://github.com/THUDM/GLM-4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/THUDM/GLM-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文介绍&lt;strong&gt;GLM-4&lt;/strong&gt;大模型部署和使用方法，需要注意的是，&lt;strong&gt;GLM-4&lt;/strong&gt;虽然开源了，但&lt;strong&gt;GLM-4&lt;/strong&gt;大模型的权重的使用则需要遵循协议：&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;第一步下载模型文件&#34;&gt;第一步：下载模型文件&lt;/h2&gt;
&lt;p&gt;老牛同学在前面文章中，介绍了通过单一的GGUF文件在本地部署&lt;strong&gt;Llama-3-8B&lt;/strong&gt;（&lt;strong&gt;Llama3-Chinese-Chat&lt;/strong&gt;）大模型：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GLM-4-9B&lt;/strong&gt;模板目前还没有GGUF文件，因此老牛同学通过Git下载PyTorch张量参数文件在本地部署&lt;strong&gt;GLM-4-9B-Chat-1M&lt;/strong&gt;大模型。&lt;/p&gt;
&lt;p&gt;由于模型参数文件比较大，使用Git无法直接下载到本地，需要通过&lt;strong&gt;git-lfs&lt;/strong&gt;工具包下载：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;brew install git-lfs
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;通过Git复制模型文件到笔记本电脑：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs install
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://www.modelscope.cn/ZhipuAI/glm-4-9b-chat-1m.git GLM-4-9B-Chat-1M
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;总共有10个模型参数文件，平均每个文件&lt;strong&gt;1.8GB&lt;/strong&gt;大小，总计18GB左右，因此在Git下载过程中，容易中断失败，可以通过以下命令多次尝试下载：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs pull
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024060801/01.jpg&#34;
	width=&#34;1104&#34;
	height=&#34;808&#34;
	srcset=&#34;https://ntopic.cn/p/2024060801/01_hua45523be335adf4b2d3dbddd2027fd8f_162239_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024060801/01_hua45523be335adf4b2d3dbddd2027fd8f_162239_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GLM4模型参数文件列表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;327px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;第二步下线glm4代码库&#34;&gt;第二步：下线GLM4代码库&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;GLM-4&lt;/strong&gt;的官方GitHub代码库中有很多使用样例和微调等Python代码，我们可直接进行调整和使用：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;https://github.com/THUDM/GLM-4.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;第三步启动glm4客户端&#34;&gt;第三步：启动GLM4客户端&lt;/h2&gt;
&lt;p&gt;打开&lt;strong&gt;GLM-4&lt;/strong&gt;代码库中&lt;code&gt;basic_demo/trans_cli_demo.py&lt;/code&gt;文件，修改&lt;strong&gt;第18行&lt;/strong&gt;模型路径&lt;code&gt;MODEL_PATH&lt;/code&gt;参数，内容为我们通过Git复制到本地的路径，如老牛同学的路径如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#MODEL_PATH = os.environ.get(&amp;#39;MODEL_PATH&amp;#39;, &amp;#39;THUDM/glm-4-9b-chat&amp;#39;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;environ&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;MODEL_PATH&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/shizihu/JupyterLab/GLM-4-9B-Chat-1M&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在启动之前，我们还需要安装几个Python工具包（当然也可以跳过，后面启动失败时在进行安装也是可以的）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install tiktoken
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install accelerate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动大模型客户端：&lt;code&gt;python trans_cli_demo.py&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% python trans_cli_demo.py
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Loading checkpoint shards: 100%&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;██████████████████████████████████████████████&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 10/10 &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;00:09&amp;lt;00:00,  1.04it/s&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Welcome to the GLM-4-9B CLI chat. Type your messages below.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You: 介绍一下你自己。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;GLM-4:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;我是一个人工智能助手，我的名字是 ChatGLM，是基于清华大学 KEG 实验室和智谱 AI 公司
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024060801/02.jpg&#34;
	width=&#34;1778&#34;
	height=&#34;386&#34;
	srcset=&#34;https://ntopic.cn/p/2024060801/02_hu0d9468faef38b4d2a073f40ebdbf8687_278218_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024060801/02_hu0d9468faef38b4d2a073f40ebdbf8687_278218_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GLM4模型对话&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;460&#34;
		data-flex-basis=&#34;1105px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结glm-4-9b比llama-3-8b慢太多了&#34;&gt;总结：GLM-4-9B比Llama-3-8B慢太多了&lt;/h2&gt;
&lt;p&gt;根据官方的评测报告，&lt;strong&gt;GLM-4-9B&lt;/strong&gt;在对话、多模态等方面要比&lt;strong&gt;Llama-3-8B&lt;/strong&gt;强不少，根据老牛同学本地部署&lt;strong&gt;对话&lt;/strong&gt;的验证结果来看，对话的输出速度实在太慢了，简直就是在挤牙膏，一个字一个字的往外输出。&lt;/p&gt;
&lt;p&gt;至于&lt;strong&gt;GLM-4-9B&lt;/strong&gt;的多模态、工具调用、代码解释等能力，老牛同学本次就不一一演示了，&lt;strong&gt;GLM-4&lt;/strong&gt;官方的GitHub代码库有很多Demo代码，大家可以对代码调整后尝试体验一下~&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AI资讯·0605] 智谱AI发布MaaS平台2.0和GLM-4系列开源模型，提升中文学科能力；四大聊天机器人同时宕机引发网络猜测；OpenAI安全疑云，前员工揭露内部问题；Arm推出终端计算子系统，支持生成式AI时代的布局；猿辅导看云大模型备案成功，教育应用潜力展现；商业智能领域迎来新变革，帆软FineChatBI利用AI大模型实现对话式业务分析。</title>
        <link>https://ntopic.cn/p/ai20240605/</link>
        <pubDate>Wed, 05 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240605/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240605/ai20240605-89.jpg" alt="Featured image of post [AI资讯·0605] 智谱AI发布MaaS平台2.0和GLM-4系列开源模型，提升中文学科能力；四大聊天机器人同时宕机引发网络猜测；OpenAI安全疑云，前员工揭露内部问题；Arm推出终端计算子系统，支持生成式AI时代的布局；猿辅导看云大模型备案成功，教育应用潜力展现；商业智能领域迎来新变革，帆软FineChatBI利用AI大模型实现对话式业务分析。" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1毛钱1百万token，写2遍红楼梦！国产大模型下一步还想卷什么？&lt;/li&gt;
&lt;li&gt;AI「末日」突然来临，公司同事集体变蠢！只因四大聊天机器人同时宕机&lt;/li&gt;
&lt;li&gt;OpenAI员工们开始反抗了！&lt;/li&gt;
&lt;li&gt;AI手机PC大爆发，Arm从软硬件到生态发力，打造行业AI百宝箱&lt;/li&gt;
&lt;li&gt;GLM-4开源版本：超越Llama3，多模态比肩GPT4V，MaaS平台也大升级&lt;/li&gt;
&lt;li&gt;猿辅导竟然是一家AI公司？大模型全家桶曝光｜甲子光年&lt;/li&gt;
&lt;li&gt;FineChatBI，帆软在AI方向的新阳谋&lt;/li&gt;
&lt;li&gt;大模型“免费”送，厂商们图什么？&lt;/li&gt;
&lt;li&gt;OpenAI前员工预测：2027年AGI降临！GPT智商飙升，4年从幼儿园蹿到高中生&lt;/li&gt;
&lt;li&gt;北京9岁小学生，已经用AI出书了！罗永浩围观：有事找不到我找AI&lt;/li&gt;
&lt;li&gt;OpenAI CEO豪投400多家公司，持股200亿，AI芯片成重点&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;1毛钱1百万token写2遍红楼梦国产大模型下一步还想卷什么&#34;&gt;1毛钱1百万token，写2遍红楼梦！国产大模型下一步还想卷什么？&lt;/h2&gt;
&lt;p&gt;智谱AI发布了新一代MaaS平台2.0，并推出GLM-4系列开源模型，包括GLM-49B，这是目前最强大的国产大模型之一，其参数规模从6B升级至9B，同时具备多模态能力。新模型在中文学科方面实现了50%的提升，并且能够处理1M长度的上下文输入，相当于一次读完2本《红楼梦》。此外，智谱AI还提供了AllTools平台，支持开发者轻松训练私有模型，降低成本。随着大规模开源和商业化模式的推进，智谱AI正朝着AGI愿景前进，其MaaS平台2.0将进一步扩大生态圈。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3UP1OB60511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai末日突然来临公司同事集体变蠢只因四大聊天机器人同时宕机&#34;&gt;AI「末日」突然来临，公司同事集体变蠢！只因四大聊天机器人同时宕机&lt;/h2&gt;
&lt;p&gt;昨日，四大聊天机器人ChatGPT、Claude、Gemini和Perplexity同时宕机，引发网友猜测。AI崩溃可能导致生产力下降，对部分依赖它们的人造成影响。宕机原因未明，有可能是DDOS攻击或巧合。OpenAI的ChatGPT先行宕机，其它两个在短时间内解决问题，而Gemini则出现不稳定情况。宕机事件显示了AI对社会的重要性和脆弱性，预示着未来生活中AI不可或缺的角色。此次宕机可能是由于基础设施问题或流量激增引起，也可能与ChatGPT宕机有关。四家公司尚未公布具体原因，但事件已成为对人类依赖AI生活方式的一次警醒。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3UP000L0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;openai员工们开始反抗了&#34;&gt;OpenAI员工们开始反抗了！&lt;/h2&gt;
&lt;p&gt;OpenAI安全疑云再起，前员工揭露内部问题。阿申布伦纳因向董事会分享安全备忘录被解雇，指出公司对AGI发展的热情与利润追求并重。13位前OpenAI和GoogleDeepMind员工联名信呼吁建立开放批评文化、匿名举报机制，警告AI公司避免监管和负责任地推动技术。OpenAI回应称，已有内部安全措施，但被指责为不当。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3UNK3QN051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai手机pc大爆发arm从软硬件到生态发力打造行业ai百宝箱&#34;&gt;AI手机PC大爆发，Arm从软硬件到生态发力，打造行业AI百宝箱&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240605/ai20240605-89.jpg&#34;
	width=&#34;528&#34;
	height=&#34;330&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240605/ai20240605-89_huc08d4ca5bae557d6e8f55b67d929882e_56617_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240605/ai20240605-89_huc08d4ca5bae557d6e8f55b67d929882e_56617_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AI手机PC大爆发，Arm从软硬件到生态发力，打造行业AI百宝箱&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;随着&amp;quot;Gen-AI&amp;quot;时代的到来，生成式AI与移动设备紧密结合，深刻影响生活和工作。Arm作为移动计算基础提供者，在架构、硬件、软件全面布局，为产业带来新的解决方案。Arm推出终端计算子系统（CSS），结合最新Armv9架构，CPU和GPU性能大幅提升。此次智东西对话Arm终端事业部产品管理副总裁JamesMcNiven，深入探讨了Arm在生成式AI时代的布局和思考。Arm通过完整解决方案让合作伙伴快速实现AI结合，为行业打造&amp;quot;AI百宝箱&amp;quot;。Arm的DNA与生成式AI契合，提供高性能、高能效的计算平台。新终端CSS基于3nm工艺，CPU和GPU物理实现，提升了30%的计算和图形性能，59%的AI推理速度。此外，ArmKleidi开发工具为开发者提供了快速开发生成式AI应用的解决方案。Arm生态系统迎来新的增长高潮，与微软合作，推动Windows与Arm架构的融合，加速WoA生态系统的发展。随着越来越多的应用成为Arm原生应用，ArmPC体验将更加完善。Arm通过技术创新保持核心竞争力，继续壮大生态，为生成式AI未来提供坚实基础。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3ULRRCM051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;glm-4开源版本超越llama3多模态比肩gpt4vmaas平台也大升级&#34;&gt;GLM-4开源版本：超越Llama3，多模态比肩GPT4V，MaaS平台也大升级&lt;/h2&gt;
&lt;p&gt;智谱AI宣布其大模型开放平台已获得30万注册用户，日调用量达400亿Tokens，API每日消费量增长50倍。GLM-4模型性能强劲，过去4个月内增长90倍。大型App中活跃智能体超过30万，包括生产力工具等。新技术侧，GLM-4-9B超越Llama3.8B，大模型保持开源。商业成果和技术突破令人瞩目。MaaS平台升级2.0，降低大模型应用门槛，国内大模型竞争加剧。智谱AICEO张鹏表示，通过技术创新实现成本持续下降，不怕价格战。API最高折扣达6折，GLM-4-9B版本仅需6分/100万token。智谱AI推出MaaS开放平台2.0，升级新模型、成本和安全等方面。在OpenDay活动中，智谱AI介绍了其开放平台最新进展，模型微调平台简化企业构建私有模型过程，全系列GLM-4大模型支持三步部署。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3ULD7JK0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;猿辅导竟然是一家ai公司大模型全家桶曝光甲子光年&#34;&gt;猿辅导竟然是一家AI公司？大模型全家桶曝光｜甲子光年&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240605/ai20240605-91.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240605/ai20240605-91_hua327b430cfde24a1d73d59036c4b6456_169000_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240605/ai20240605-91_hua327b430cfde24a1d73d59036c4b6456_169000_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;猿辅导竟然是一家AI公司？大模型全家桶曝光｜甲子光年&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;猿辅导旗下看云大模型成功通过大模型备案，引起教育界热议。尽管在“百模大战”中相对不占优势，但猿辅导凭借多年积累的数据资源和技术实力，以AI为核心的产品逐步展开了大模型的应用。其自研大模型并非作为单一产品，而是技术底座，通过与现有产品结合，为教育场景提供个性化服务。猿辅导的大模型落地速度快，涵盖家庭教育、作业批改、答疑系统等多个方面，其AI技术在教材识别、批改、生成反馈等环节发挥作用。通过大模型，学生可以享受到更为丰富的学习体验，教师则有助于提高教学效率。猿辅导的教育“全家桶”展现了大模型在教育中的潜力和应用前景，预示着将来AI技术会彻底改变传统教育模式，使得每个学生都能拥有专属的学习体验。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3PDRSQ90512MLBG.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;finechatbi帆软在ai方向的新阳谋&#34;&gt;FineChatBI，帆软在AI方向的新阳谋&lt;/h2&gt;
&lt;p&gt;在AI大模型技术的推动下，商业智能（BI）领域正迎来新的变革。帆软产品研发中心总经理陈敏表示，希望通过AI技术降低数据分析门槛，让更多人成为数据分析师。微软率先将Copilot整合进PowerBI，而全球知名BI服务提供商也开始注入AI大模型计划。国内BI厂商也紧跟趋势，推出类似功能。过去的问答式BI产品受限于技术，无法满足用户需求，帆软FineChatBI通过利用AI大模型的泛化能力，实现了对话式业务分析，让非专业人员能够进行数据分析。FineChatBI不仅能理解用户问题，还能拆解、查询数据，并提供异常检测和趋势预测功能。未来，FineChatBI有望进一步成为业务决策入口，直接将分析结果转化为业务指令。这将是BI领域的一个巨大变革，使得BI从辅助工具转变为实现业务闭环的核心。虽然AI技术进步迅速，但帆软认为，AI与BI不是简单相加，而是“AIforBI”，通过AI提升BI效率和降低使用门槛，让更多人能更好地利用BI工具。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3UBA9L30512MLBG.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;大模型免费送厂商们图什么&#34;&gt;大模型“免费”送，厂商们图什么？&lt;/h2&gt;
&lt;p&gt;2024年618期间，大模型市场爆发了激烈的“价格战”，部分企业甚至开始免费提供服务。字节跳动宣布其豆包主力模型定价为0.0008元/千Tokens，远低于行业平均水平；阿里云则将通义千问GPT-4级主力模型Qwen-Long的API输入价格降至0.0005元/千Tokens。百度、腾讯云和科大讯飞也相继跟进，降低了自己的大模型定价。尽管如此，大部分企业的大模型业务仍面临高算力和人力成本的挑战，未能盈利。这种非理性的价格战反映出上游企业希望通过让利来打通大模型商业闭环的内在焦虑。然而，大模型商业模式不健全，成本高、落地难等问题仍然存在。由于训练和部署成本较高，一些企业对此保持观望态度。目前，大部分大模型仅推理用的token降价，而训练和部署成本依然不低。虽然价格战可能吸引了更多下游企业，但实际上，使用大模型服务的成本远未达到“免费”的程度。此次价格战或许能引起下游企业对大模型技术的关注，并有望探索出良性的商业模式。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3TP1HOJ05118O92.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;openai前员工预测2027年agi降临gpt智商飙升4年从幼儿园蹿到高中生&#34;&gt;OpenAI前员工预测：2027年AGI降临！GPT智商飙升，4年从幼儿园蹿到高中生&lt;/h2&gt;
&lt;p&gt;文章作者LeopoldAschenbrenner预测2027年可能实现强人工智能（AGI），引发了对其可行性的讨论。虽然他提供了多种数据和分析，但结论仍然存在争议，尤其是考虑到算力、算法效率与解开收益的叠加，以及未来四年的发展预测。同时，文章也提出了AGI实现可能面临的挑战，如幻觉问题等。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3UP1O070511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;北京9岁小学生已经用ai出书了罗永浩围观有事找不到我找ai&#34;&gt;北京9岁小学生，已经用AI出书了！罗永浩围观：有事找不到我找AI&lt;/h2&gt;
&lt;p&gt;智谱AI举办OpenDay活动，展示了其AI智能体与小学生许萌萌合作出版的科普小说《AI少年——火星生存大挑战》。智谱清言AI智能体可以协助用户完成多项任务，如速读论文、生成PPT和流程图等。新发布的大型模型GLM-4-9B在综合能力上比ChatGLM3-6B提升40%，中文学科方面提升50%。同时，智谱AI开放平台升级至MaaS2.0，价格下降，性能提升。活动还展示了儿童使用智谱清言APP创作的画作，显示大模型应用的普及趋势。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3UL5EP30511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;openai-ceo豪投400多家公司持股200亿ai芯片成重点&#34;&gt;OpenAI CEO豪投400多家公司，持股200亿，AI芯片成重点&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240605/ai20240605-96.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240605/ai20240605-96_hu1a6771bf538b263257bc0307cd7119fd_266981_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240605/ai20240605-96_hu1a6771bf538b263257bc0307cd7119fd_266981_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;OpenAI CEO豪投400多家公司，持股200亿，AI芯片成重点&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;1.OpenAICEOSamAltman拥有至少28亿美元的隐秘投资帝国，涉及400多家企业，其中包括知名AI公司。2.Altman的投资风格激进，曾在未完成介绍前即做出决定，他利用个人信贷对初创公司进行高风险投资。3.Altman在AI领域有显著投资，如CerebrasSystems、Humane和RainAI等。其中，Stripe是他最成功的投资之一，其估值为650亿美元。4.Altman与OpenAI的利益关系引发关注，他同时持股多家与OpenAI合作的公司，可能存在利益冲突。5.尽管如此，Altman表示会遵循政策，并对其投资保持透明。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3UNK4EO051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/q8B0sgyv8uu5cuYQmJy4lQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/q8B0sgyv8uu5cuYQmJy4lQ&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AI资讯·0604] AI将取代某些工作，Anthropic致力于解决安全性和可解释性问题；AI搜索产品改变信息检索，百度应对挑战；AMD挑战NVIDIA市场领导地位；版权保护问题日益凸显，Shapley值框架提出解决方案；强化学习方法超越GPT-4v；Octopusv4模型优化多模态查询；李飞飞强调空间智能对AI发展的重要性。</title>
        <link>https://ntopic.cn/p/ai20240604/</link>
        <pubDate>Tue, 04 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240604/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240604/ai20240604-75.jpg" alt="Featured image of post [AI资讯·0604] AI将取代某些工作，Anthropic致力于解决安全性和可解释性问题；AI搜索产品改变信息检索，百度应对挑战；AMD挑战NVIDIA市场领导地位；版权保护问题日益凸显，Shapley值框架提出解决方案；强化学习方法超越GPT-4v；Octopusv4模型优化多模态查询；李飞飞强调空间智能对AI发展的重要性。" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;首次解密Claude 3大脑！25岁Anthropic参谋长预言3年内自己将被AI淘汰&lt;/li&gt;
&lt;li&gt;不想炸薯条的Ilya和不送GPU的英伟达，Hinton最新专访：道路千万条，安全第&lt;/li&gt;
&lt;li&gt;硅谷团队抄袭清华系大模型？&lt;/li&gt;
&lt;li&gt;斯坦福AI Lab主任怒了！抄袭团队2人甩锅1人失踪、前科经历被扒&lt;/li&gt;
&lt;li&gt;AI搜索，“杀死”搜索&lt;/li&gt;
&lt;li&gt;AI预测极端天气提速5000倍！微软发布Aurora，借AI之眼预测全球风暴&lt;/li&gt;
&lt;li&gt;AMD公布新款AI芯片，也要一年一更新，想挑战英伟达&lt;/li&gt;
&lt;li&gt;苏妈杀疯了：移动端最强NPU算力达50TOPS，最强AI芯片挑战英伟达&lt;/li&gt;
&lt;li&gt;AI训练数据的版权保护:公地的悲剧还是合作的繁荣?&lt;/li&gt;
&lt;li&gt;多模态模型学会打扑克：表现超越GPT-4v，全新强化学习框架是关键&lt;/li&gt;
&lt;li&gt;3B模型新SOTA！开源AI让日常调用不同大模型更简单&lt;/li&gt;
&lt;li&gt;顶尖AI科学家李飞飞演讲：机器人进化离不开空间智能&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;首次解密claude-3大脑25岁anthropic参谋长预言3年内自己将被ai淘汰&#34;&gt;首次解密Claude 3大脑！25岁Anthropic参谋长预言3年内自己将被AI淘汰&lt;/h2&gt;
&lt;p&gt;Anthropic参谋长预言自己将在接下来的三年内失去工作，因为她认为AI会取代她的职业。她指出，随着模型能力的提升，如Claude3，AI已经能够胜任多种类型的内容生成任务，并且在文本总结和分析方面表现突出。Balwitherself曾是一名自由作家，但现在认为这种技能已过时。她预测在线工作领域将首先受到影响，包括内容写作、税务准备和客户服务等任务。Balwit还提到AI已经开始在软件开发和合同法等专业领域显示出取代人类的潜力。尽管如此，Balwit也指出，并不是所有类型的工作都会被完全淘汰。她认为那些需要精细操作和特定情境专业知识的工种，如电工、园丁、管道工、珠宝制作师、理发师和修理铁艺品的工人，其从业人员将会比预期更长时间保持工作。对于医疗和公务员岗位，Balwit认为它们可能会在未来被取代的时间推后一些。对于那些不在这些领域的工作，也会有所减少，人机协作成为一种常见模式。Anthropic的CEODarioAmodei预计AI将在2-3年内实现AGI，但他也指出，这个过程是连续且平滑的，而公众对AI技术的认知和反应则是跳跃式和不可预测的。Amodei认为，虽然模型的能力有时会超越训练数据，但仍然存在挑战，比如如何解释模型内部的“思考”过程，以及如何确保模型安全性。Anthropic正在致力于通过可解释性的研究来解决这些问题，并且已经发布了一些有关Claude3Sonnet的研究成果。研究人员使用稀疏自编码器将数百万个特征从模型中提取出来，这些特征可以与人类可理解的概念相匹配，展示了模型内部状态如何由少量激活特征而非大量神经元活动表示。此外，研究人员还发现在某些情况下，可以通过人为方式激活特定的功能来改变模型的行为。这种操纵可以导致模型生成诈骗邮件等不良内容，但这也强调了对AI模型行为的深入理解和严格控制的重要性，以确保它们符合预期并不会造成伤害。总之，Balwit认为AI将取代某些工作，而Amodei则乐观地看待AGI的实现，但都意识到这个过程中存在许多挑战。Anthropic致力于通过研究和技术创新来解决这些问题，并确保人工智能的安全性和可解释性。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3M815QM0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;不想炸薯条的ilya和不送gpu的英伟达hinton最新专访道路千万条安全第&#34;&gt;不想炸薯条的Ilya和不送GPU的英伟达，Hinton最新专访：道路千万条，安全第&lt;/h2&gt;
&lt;p&gt;人工智能领域的“教父”Hinton在离职谷歌一年后接受采访，分享了他与徒弟Ilya共同工作的点滴，以及他们如何一起推动AI技术发展。在采访中，Hinton谈到了自己早年的学习经历，包括在剑桥和爱丁堡的研究，以及他与Ilya合作开发反向传播算法的故事。两人之间的化学反应不仅产生了AI领域的重要突破，也孕育出了OpenAI的创意与成就。Hinton还提到了多模态模型将带来的新机遇，以及对AI伦理和安全的担忧，认为科学家应考虑到技术可能对社会的长远影响。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3M80DQ30511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;硅谷团队抄袭清华系大模型&#34;&gt;硅谷团队抄袭清华系大模型？&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240604/ai20240604-75.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240604/ai20240604-75_hu8b59891c0bca1d923dd986d947b3c7ef_230599_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240604/ai20240604-75_hu8b59891c0bca1d923dd986d947b3c7ef_230599_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;硅谷团队抄袭清华系大模型？&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;斯坦福大学学生SiddharthSharma和AkshGarg开发的Llama3-V大型语言模型因其较低成本训练而受到关注，但后来被指控与“清华系”的大模型有雷同之处，引发了关于“套壳”的争议。虽然团队否认偷窃代码，但最终删除了相关项目并道歉。这种行为在AI行业中不罕见，涉及到模型架构和预训练的复用，以及调优过程中的变量名称更改。业内专家认为，这种做法虽然普遍存在，但对自主研发至关重要。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3PVVTLO0519APGA.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;斯坦福ai-lab主任怒了抄袭团队2人甩锅1人失踪前科经历被扒&#34;&gt;斯坦福AI Lab主任怒了！抄袭团队2人甩锅1人失踪、前科经历被扒&lt;/h2&gt;
&lt;p&gt;斯坦福团队被指抄袭清华大模型，两位本科生承认并且与另一作者合作切割。SiddharthSharma和AkshGarg发表道歉声明，但未提及MustafaAljadery，后者失踪并被指为主要责任人。ChristopherManning批评团队避重就轻，并未认真抄袭。新发现的证据显示Llama3-V与MiniCPM-2.5极其相似，且可能直接在权重上添加了噪声。此事引发关于开源社区是否忽视中国大模型成果的讨论。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3RER9J40511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai搜索杀死搜索&#34;&gt;AI搜索，“杀死”搜索&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240604/ai20240604-77.jpg&#34;
	width=&#34;808&#34;
	height=&#34;379&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240604/ai20240604-77_hufd4a3691efc5d9a878580ab5221d550c_251633_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240604/ai20240604-77_hufd4a3691efc5d9a878580ab5221d550c_251633_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AI搜索，“杀死”搜索&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;213&#34;
		data-flex-basis=&#34;511px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;国内大型模型厂商纷纷推出C端AI搜索产品，打破了传统搜索引擎的垄断局面。腾讯、搜狗等公司推出了基于混元大模型的APP，提供AI搜索功能。这些产品主要分为两类，一些内置AI搜索，如Kimi、豆包、文心一言、通义千问和腾讯元宝；另一些专门开发了AI搜索服务，如360搜索、秘塔搜索、天工AI搜索和百川AI搜索等。这场竞争显得有些讽刺，因为在互联网时代，搜索引擎是高科技领域的佼佼者，而现在大模型时代谁都能参与。国内搜索引擎“一超多强”的格局即将被打破，百度如何应对成为焦点。谷歌已经在GoogleI/O上对其搜索业务进行了全面的AI改造，现在看百度的表现如何。Perplexity是一个典型的内嵌搜索代表，其通过算法从不同信息源中搜索并提供结果，界面简洁多功能，用户体验高效。虽然基于GPT-3.5的API调试，但已经获得了市场认可和资本支持。国内AI搜索产品主要是参照Perplexity进行设计和操作，如秘塔搜索模仿其UI设计和逻辑，而360AI搜索则在页面设计上显得老旧。天工AI搜索结合了多种能力但结果不够成熟。这些产品虽然效仿Perplexity，但还远未达到颠覆性的AI搜索。搜索广告是搜索引擎的关键收入来源，百度和谷歌均依赖这一业务。然而，随着ChatGPT的出现，微软和谷歌争夺新技术领域，而百度等公司迟迟未动，原因可能在于无法放弃传统广告模式。探索AI创业需要大量研发投入，如果没有广告收入支持，很难维持运营。总体上，AI搜索产品正在改变我们寻找信息的方式，但商业模式仍需调整以适应新趋势。Perplexity尝试2B市场服务，同时探索知识平台转型，而Kimi认为随着AI技术的深入集成，用户可能不再需要专门的搜索引擎，而是通过语音助手等方式检索信息。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3OGPL1A05198R91.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai预测极端天气提速5000倍微软发布aurora借ai之眼预测全球风暴&#34;&gt;AI预测极端天气提速5000倍！微软发布Aurora，借AI之眼预测全球风暴&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240604/ai20240604-78.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240604/ai20240604-78_hu0bab0f0275185991bd3204f8c98f5dce_147592_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240604/ai20240604-78_hu0bab0f0275185991bd3204f8c98f5dce_147592_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AI预测极端天气提速5000倍！微软发布Aurora，借AI之眼预测全球风暴&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;微软发布了名为Aurora的大气基础模型，这是一种新型的人工智能模型，能够从大量大气数据中学习并进行预测，具有极高的准确率和效率。与目前数值天气预报系统相比，Aurora的计算速度提高了约5000倍。该模型可以预测各种大气变量，如温度、风速、空气污染水平及温室气体浓度，并且能够在数据稀缺地区或极端天气情况下进行出色的预测。此外，Aurora的灵活性和多功能性使其在解决环境预报问题方面具有卓越的适应性。这种技术的发展有可能将改变我们对气候变化的理解和应对方式，并为全球各地提供更准确的天气信息，从而促进农业、交通、能源管理等领域的发展，帮助社区更好地适应气候变化带来的挑战。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3RD7ADL0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;amd公布新款ai芯片也要一年一更新想挑战英伟达&#34;&gt;AMD公布新款AI芯片，也要一年一更新，想挑战英伟达&lt;/h2&gt;
&lt;p&gt;AMD发布新AI处理器，挑战英伟达市场领导地位；苏姿丰称人工智能是公司重中之重，计划每年更新产品线并推出重大创新。2025年将推出MI350系列，预计在AI推理性能提高35倍，而2026年将推出基于“Next”架构的MI400系列。AMD的股价虽然持平，但英伟达股价上涨5%，显示市场对AMD挑战的认可。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/tech/article/J3QTQKHI00097U7T.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;苏妈杀疯了移动端最强npu算力达50tops最强ai芯片挑战英伟达&#34;&gt;苏妈杀疯了：移动端最强NPU算力达50TOPS，最强AI芯片挑战英伟达&lt;/h2&gt;
&lt;p&gt;AMD和英伟达在Computex展示了最新的技术，各自展现出强大的竞争力。AMDCEO苏姿丰展示了基于Zen5架构的新一代Ryzen9000系列CPU，以及锐龙AI300系列APU，其NPU算力达到50TOPS，超过微软对新一代AIPC的要求。同时，他们还推出了第五代EPYC霄龙芯片，为数据中心提供了强大的处理能力。而AMDInstinctGPU也展示了其在HPC和AI领域的潜力，并且公布了2024-2026年的产品路线图，旨在与英伟达竞争。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3RKP2QS0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai训练数据的版权保护公地的悲剧还是合作的繁荣&#34;&gt;AI训练数据的版权保护:公地的悲剧还是合作的繁荣?&lt;/h2&gt;
&lt;p&gt;摘要：随着生成式AI技术的快速发展，版权保护问题日益成为焦点。本文提出了一种基于Shapley值的版权分享框架，以解决AI模型训练数据所有者与开发者的利益冲突。该框架通过评估不同数据源对模型性能的贡献，并根据Shapley值计算版权分配，旨在实现公平合理的收益分配。实验表明，该框架能够准确识别每个版权所有者对AI生成内容的贡献，尤其是在多样化数据源融合的情况下。然而，该方法存在计算成本高的问题，未来需要开发更高效的算法或方法来解决这一挑战。此外，本文讨论了未来的研究方向，包括如何处理无法协商协议的版权所有者，以及如何在实际应用中提高Shapley值的可行性和效率。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3RMES2K0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;多模态模型学会打扑克表现超越gpt-4v全新强化学习框架是关键&#34;&gt;多模态模型学会打扑克：表现超越GPT-4v，全新强化学习框架是关键&lt;/h2&gt;
&lt;p&gt;强化学习方法RL4VLM，无需人类反馈，可以微调多模态大模型，使其在看图玩扑克、算“12点”等任务上表现超越GPT-4v。该方法由UC伯克利等高校研究人员提出，包括图灵奖得主LeCun和其他专家。通过强化学习直接从环境获取奖励，模型学会了多模态决策能力，并在各种评测任务中表现出色，包括数字识别、逻辑推理和视觉语义推理。实验表明，微调后的模型能够超越GPT-4vGemini和传统监督微调方法，在具身智能环境中的单物体拾取任务表现尤为突出。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3RMNI8A0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;3b模型新sota开源ai让日常调用不同大模型更简单&#34;&gt;3B模型新SOTA！开源AI让日常调用不同大模型更简单&lt;/h2&gt;
&lt;p&gt;NEXAAI的Octopusv4模型利用functionaltoken整合多个开源模型，针对特定任务进行优化。它通过智能地引导用户查询至最合适的专业模型，并重新格式化查询以实现最佳性能。Octopus-V4-3B是该系列中的一员，拥有30亿参数，开源，是语言模型图的主节点，擅长将用户查询转换为专业模型可处理的格式。在生产环境中，系统设计考虑了负载均衡、工作节点部署、主节点部署和通信。实验结果显示，Octopusv4模型在MMLU任务中的表现优异。未来的发展方向包括整合垂直特定模型，加强图形框架，并开发多模态模型。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3RNH6HO0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;顶尖ai科学家李飞飞演讲机器人进化离不开空间智能&#34;&gt;顶尖AI科学家李飞飞演讲：机器人进化离不开空间智能&lt;/h2&gt;
&lt;p&gt;李飞飞在2024年TED大会上发表演讲，讨论了空间智能（SpatialIntelligence）对人工智能发展的重要性。她指出，随着神经网络算法、GPU计算能力和大数据的进步，计算机视觉领域取得了巨大进展，并且不仅仅是让计算机看到世界，更追求理解世界。空间智能是指在三维空间中学习知识并做出行动的能力，是人工智能发展中的下一个重要里程碑。李飞飞强调，为了实现空间智能，不仅需要算法和硬件，还需要确保技术始终以人为本。她提到了她的学生和合作者正在开发的机器人，可以在三维世界中行动，并且能够执行复杂任务，如做饭、给病人提供医疗服务等。这些进展预示着数字寒武纪大爆发即将到来，AI将拥有更强大的理解能力和空间感知能力，与人类合作创造出一个更美好的未来。然而，李飞飞也提醒我们，实现这一目标并不容易，我们需要在采取行动时深思熟虑，确保技术始终以人为本，以尊重人类个体的尊严，促进人类社会的共同繁荣。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3S12M8K051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/kcvaZt92c9yNMMLUcghi7A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/kcvaZt92c9yNMMLUcghi7A&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AI资讯·0601] 亚马逊云科技中国峰会聚焦生成式AI应用，推出三层技术栈解决企业挑战。Arm在移动终端推出新产品，优化AI性能。OpenAI与苹果合作可能带来数十亿美元收益。点军智算中心成为宜昌多元算力高地，燧原科技推动AI开源开放平台。研究表明大型语言模型模拟记忆，但实际是无状态函数。旷视团队发布“点读笔”，支持复杂文档理解。六位AI工程师分享大型语言模型应用开发经验。GPT-4已达成年人的心智理论水平，在心理推理超越人类。</title>
        <link>https://ntopic.cn/p/ai20240601/</link>
        <pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240601/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240601/ai20240601-66.jpg" alt="Featured image of post [AI资讯·0601] 亚马逊云科技中国峰会聚焦生成式AI应用，推出三层技术栈解决企业挑战。Arm在移动终端推出新产品，优化AI性能。OpenAI与苹果合作可能带来数十亿美元收益。点军智算中心成为宜昌多元算力高地，燧原科技推动AI开源开放平台。研究表明大型语言模型模拟记忆，但实际是无状态函数。旷视团队发布“点读笔”，支持复杂文档理解。六位AI工程师分享大型语言模型应用开发经验。GPT-4已达成年人的心智理论水平，在心理推理超越人类。" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;接入零一万物、百川智能大模型！云大厂扩张生成式AI版图，大秀三层技术栈与&lt;/li&gt;
&lt;li&gt;对话Arm终端产品副总裁：当生成式AI与Arm的DNA相契合，会擦出怎样的火花？&lt;/li&gt;
&lt;li&gt;OpenAI被曝重组计划！与苹果达成关键协议，微软谷歌哭晕&lt;/li&gt;
&lt;li&gt;上线即满载，点军智算中心探索本土AI新基建的范式变革&lt;/li&gt;
&lt;li&gt;亚马逊云科技X易点天下共探生成式AI新机遇&lt;/li&gt;
&lt;li&gt;ControlNet作者搞起大模型：让天下没有难写的生图提示词&lt;/li&gt;
&lt;li&gt;AI视觉算法登柳叶刀！看CT提前10年预测致命心脏疾病，已进入临床使用&lt;/li&gt;
&lt;li&gt;ChatGPT真能记住你的话吗？DeepMind与开源大佬揭示LLM记忆之谜&lt;/li&gt;
&lt;li&gt;AI读论文新神器：多栏密集文字、中英图文混排文档都能读｜旷视&lt;/li&gt;
&lt;li&gt;六位一线AI工程师总结爆火！大模型应用摸爬滚打一年心得公开&lt;/li&gt;
&lt;li&gt;谷歌DeepMind：GPT-4高阶心智理论彻底击败人类！第6阶推理讽刺暗示全懂了&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;接入零一万物百川智能大模型云大厂扩张生成式ai版图大秀三层技术栈与&#34;&gt;接入零一万物、百川智能大模型！云大厂扩张生成式AI版图，大秀三层技术栈与&lt;/h2&gt;
&lt;p&gt;亚马逊云科技中国峰会于5月29日-30日在上海举办，聚焦生成式AI应用落地。面对企业使用挑战，如算力资源短缺、工具和模型访问问题、快速上手的应用缺失，亚马逊云科技推出三层技术栈：GPU基础设施、AmazonBedrock（中间层）和开箱即用的生成式AI应用。底层是基于GPU和自研芯片构建的基础设施，用于训练和生产环境中的推理。中间层提供访问基础模型和构建应用程序工具，如AmazonBedrock，支持来自Al21Labs、Anthropic等多家公司的高性能模型。顶层为用户提供开箱即用生成式AI应用，如AmazonQ，帮助企业快速部署应用。亚马逊云科技推出了一系列专门构建的芯片和计算实例，用于减少企业模型训练成本。他们还推出了AmazonSageMaker托管机器学习服务，提供多个基础模型选择，并且推出AmazonBedrock模型评估功能，缩短模型评估时间。在中间层，亚马逊云科技通过AmazonBedrock为企业提供了自定义模型导入和微调能力，以及知识库功能，支持企业定制响应。应用集成方面，BedrockAgent工具支持开发人员定义特定的任务流程，增强控制和自动化。上层的生成式AI助手AmazonQ帮助企业加速软件开发、发挥业务数据价值，并提供了从任意数据中获取洞见的能力。亚马逊云科技还推出了免费培训计划，为全球2900万人提供免费培训，包括“从基础到应用：LLM全景培训”课程。总结来说，亚马逊云科技通过其技术栈和服务助力企业生成式AI应用落地，并推动架构创新，以应对多元技术融合、成本管理和风险控制等挑战。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3I9CGM8051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;对话arm终端产品副总裁当生成式ai与arm的dna相契合会擦出怎样的火花&#34;&gt;对话Arm终端产品副总裁：当生成式AI与Arm的DNA相契合，会擦出怎样的火花？&lt;/h2&gt;
&lt;p&gt;5月31日，智能终端与生成式AI深度融合，移动领域出现新AI需求和场景。生成式AI带来算力、存储挑战，加速硬件、软件、算法迭代。Arm作为移动生态巨头，布局AI，推出新产品、新技术，发布最新终端计算子系统（CSS），结合Armv9架构，基于3nm工艺节点。新的CPUCortex-X925实现41%的AI性能提升，GPUArmImmortalis-G925在多个AI和ML网络上提升了34%的性能。Arm的一系列技术剑指AI，加速移动智能终端产业发展。能效成为行业首要关注焦点，Arm以此为核心优势。生成式AI时代，计算需求暴涨，Arm提供普适应用，为安卓端CPU挑大梁。Arm针对AI推理和训练优化CPU和GPU，优化数据流，对内存流量需求进行了大量时间的优化。CPU仍是AI时代计算核心，Arm全面计算解决方案（TCS）带来新的CPU与GPU，提升性能、能效、AI能力，并首次为ArmCPU和GPU交付物理实现。新ArmCortex-X925实现Cortex-X系列推出以来最高的同比性能提升，单线程性能提高36%，token首次响应时间提高41%。ArmImmortalis-G925GPU在多个AI和ML网络上实现34%的性能提升。ArmKleidi软件工具集成PyTorch、Tensorflow等热门AI框架，加速模型性能。WoA生态系统发展，新增应用，如百度、哔哩哔哩等，Arm与微软合作，资助开源和发布面向Windows的Arm性能库。Arm构筑面向未来AI的计算平台，为移动智能终端产业提供核心竞争力。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3I3TCBN051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;openai被曝重组计划与苹果达成关键协议微软谷歌哭晕&#34;&gt;OpenAI被曝重组计划！与苹果达成关键协议，微软谷歌哭晕&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240601/ai20240601-61.jpg&#34;
	width=&#34;534&#34;
	height=&#34;334&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240601/ai20240601-61_huef2c6f2612e05cdecf7a070d359a59ca_39508_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240601/ai20240601-61_huef2c6f2612e05cdecf7a070d359a59ca_39508_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;OpenAI被曝重组计划！与苹果达成关键协议，微软谷歌哭晕&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;OpenAI与苹果达成协议，将ChatGPT集成到iOS及其他操作系统中，可能带来数十亿美元收益，影响苹果与谷歌长期联盟关系。微软对此合作持保留态度，CEO萨蒂亚·纳德拉和OpenAI联合创始人兼CEO萨姆·阿尔特曼讨论了微软自身产品的担忧。阿尔特曼考虑将OpenAI重组为营利性公司或类似公益公司，可能价值1000亿美元的资金支持。尽管面临争议，阿尔特曼权力增强，OpenAI在科技行业的地位提升。苹果利用OpenAI技术可能会推动Siri功能升级，微软则通过授权OpenAI技术获得云收入。新一轮AI竞赛已开启，OpenAI的先发优势与苹果庞大用户群体将对市场产生重大影响。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3I072UU051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;上线即满载点军智算中心探索本土ai新基建的范式变革&#34;&gt;上线即满载，点军智算中心探索本土AI新基建的范式变革&lt;/h2&gt;
&lt;p&gt;在数字经济时代，算力成为新型生产力的关键驱动力。智算中心快速发展，提供多元化算力资源，实现合理分配，为企业带来便利。随着大模型的演进，对算力的性能和易用性提出了更高要求，关注点转向算力融合、软硬件协同和成本优化。宜昌市正在建设融合智算、超算和通用算力的多元算力高地，成为国家算力“中继站”。已建成的605PFLOPS算力中心，是华中区最大的异构算力集群。点军智算中心仅5个月便实现300PFLOPS算力资源全消纳，与互联网企业和行业大模型企业达成合作，推动生态协同发展。燧原科技作为国内聚焦云端AI的领先算力企业，以点军智算中心项目探索本土算力中心市场化运营新思路，为数字经济发展提供了新的范式。点军智算中心已成为本土智算中心建设上线即满载的标杆案例，为行业释放最大动能。燧原科技通过点军智算中心项目，实现了与多家头部互联网企业及行业大模型企业的合作，提供推理和训练算力资源。未来计划建成3000PFLOPS以上算力，并在宜昌市打造国家东数西算战略中多元算力高地。燧原科技发布“燎原”生态合作计划，与生态伙伴共同构建开放、协作、创新的人工智能生态系统，孵化创新应用。点军智算中心已成为宜昌“数算一体、数实融合”产业格局的重要环节。大模型的应用将带动数据产生、算法演进和生成式AI的应用。燧原科技与生态伙伴合作，推动AI开源开放平台OpenI启智社区，为开发者提供GCU算力资源，降低创新的门槛。点军智算中心将连接算力、大模型厂商、运维商和应用开发玩家，为大模型部署提供支持。总结来看，AIDC+AIGC（人工智能设计与生成）的结合，将推动算力的范式变革，为中国AI2.0时代的到来奠定基础。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3HP3HPT051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;亚马逊云科技x易点天下共探生成式ai新机遇&#34;&gt;亚马逊云科技X易点天下共探生成式AI新机遇&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240601/ai20240601-63.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240601/ai20240601-63_hu7df186100a41431cff42c233dd2f23c5_123452_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240601/ai20240601-63_hu7df186100a41431cff42c233dd2f23c5_123452_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;亚马逊云科技X易点天下共探生成式AI新机遇&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;2024亚马逊云科技中国峰会在上海·世博中心举办，聚焦生成式AI创新应用。易点天下作为CloudNative营销科技公司，参与峰会并启动“生成式AI合作伙伴计划”，发布全新“AI+BI+CI”出海解决方案。大会探讨了生成式AI在全球各行业的应用前景，并展示了如何通过技术创新提升企业效率和竞争力。易点天下推出了KreadoAI、数眼智能和Gears三大产品，旨在帮助出海企业实现本地化营销和业务增长。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3HO1R6O0512MLBG.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;controlnet作者搞起大模型让天下没有难写的生图提示词&#34;&gt;ControlNet作者搞起大模型：让天下没有难写的生图提示词&lt;/h2&gt;
&lt;p&gt;ControlNet作者LvminZhang推出新项目Omost，解决AI绘画中提示词难题。用户只需一句简单描述，Agent即可自动生成图像。这是基于大模型和Agent的新玩具，名为Omost，有“almost”和“omni-most”的双层含义。Omost通过预定义位置、偏移量和区域参数简化元素描述，将图像划分为729个可能位置，以此来实现精细控制。LvminZhang还提供了基于注意力操纵的渲染器，并提出了实现区域引导扩散系统的选择。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3JONBQS0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai视觉算法登柳叶刀看ct提前10年预测致命心脏疾病已进入临床使用&#34;&gt;AI视觉算法登柳叶刀！看CT提前10年预测致命心脏疾病，已进入临床使用&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240601/ai20240601-66.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240601/ai20240601-66_huc0d7d275aaff7ec31c1218c55dd1b4c8_265446_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240601/ai20240601-66_huc0d7d275aaff7ec31c1218c55dd1b4c8_265446_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AI视觉算法登柳叶刀！看CT提前10年预测致命心脏疾病，已进入临床使用&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;《柳叶刀》发表了一项研究，展示了名为CaRi-Heart的AI技术可以在没有明显症状时提前10年识别心血管疾病风险。这项技术结合AI视觉识别和预测算法，通过评估冠状动脉炎症程度来量化患者的心血管风险。研究使用了英国ORFAN项目中的数据，验证了CaRi-Heart的准确性，并显示其在年轻人中能比现有模型更好地预测心脏疾病风险。该技术已在英国、欧洲和澳大利亚投入临床使用，並正在开发新产品以预测中风和糖尿病风险。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3JOHEDJ0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;chatgpt真能记住你的话吗deepmind与开源大佬揭示llm记忆之谜&#34;&gt;ChatGPT真能记住你的话吗？DeepMind与开源大佬揭示LLM记忆之谜&lt;/h2&gt;
&lt;p&gt;文本摘要：LLM（大型语言模型）似乎具有记忆功能，但实际上它们是无状态函数。用户感觉到的记忆是因为每次输入时包含了之前对话内容作为提示。模型没有真正的记忆能力，只能处理当前输入。如果提供足够长的上下文，模型可以模拟记忆，但这通常会增加成本和延迟。在训练过程中，LLM学习知识并非简单复制数据，而是通过理解和概括来集成参数。研究表明大多数模型都能够在一定程度上输出训练数据，且参数越多的模型可能记忆能力越强，但具体原因仍然未知。此外，某些特定单词如“company”更容易触发模型输出训练数据，这可能存在版权和隐私问题。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3JOHAKH0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai读论文新神器多栏密集文字中英图文混排文档都能读旷视&#34;&gt;AI读论文新神器：多栏密集文字、中英图文混排文档都能读｜旷视&lt;/h2&gt;
&lt;p&gt;旷视团队推出了名为“点读笔”的多模态大模型Fox，能够高效理解8页中英混合、单栏多栏格式的PDF文档。Fox支持细粒度理解，如用户感兴趣区域内的文字识别、段落翻译和图片内容描述。它通过精准定位、多视觉词表协同和页面打包技术，实现了对复杂文档的高效理解。Fox还支持跨页VQA、双栏前景OCR、图像描述等功能，并且可以将latex格式转换为代码。此外，旷视团队还开源了中英双语的benchmark，包含多种文档理解任务，以促进研究。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3JR0OHT0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;六位一线ai工程师总结爆火大模型应用摸爬滚打一年心得公开&#34;&gt;六位一线AI工程师总结爆火！大模型应用摸爬滚打一年心得公开&lt;/h2&gt;
&lt;p&gt;六位AI工程师和创业者分享了一年来在大型语言模型应用开发上的经验，内容涵盖了如何使用提示词、RAG（检索增强生成）、微调、大模型作为裁判、实习生测试以及幻觉的解决方案。他们认为，大模型的输出结果取决于应用场景、任务需求、成本效益和性能目标，并建议根据具体情况选择合适的方法。同时，他们提出了多种实际操作上的经验，比如如何设计提示词、如何进行RAG和微调、以及如何评估和监测大模型的表现。此外，文章还讨论了幻觉的挑战，以及如何通过结合提示工程和事实不一致护栏来减少幻觉。最后，作者们计划继续分享运营和战略篇内容，并计划举办线上直播进一步探讨。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3JQDO6N0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;谷歌deepmindgpt-4高阶心智理论彻底击败人类第6阶推理讽刺暗示全懂了&#34;&gt;谷歌DeepMind：GPT-4高阶心智理论彻底击败人类！第6阶推理讽刺暗示全懂了&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240601/ai20240601-71.jpg&#34;
	width=&#34;800&#34;
	height=&#34;499&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240601/ai20240601-71_hu481881cfe861600fc9ed7d3926452e58_182974_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240601/ai20240601-71_hu481881cfe861600fc9ed7d3926452e58_182974_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;谷歌DeepMind：GPT-4高阶心智理论彻底击败人类！第6阶推理讽刺暗示全懂了&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;摘要：谷歌DeepMind、约翰斯·霍普金斯大学和牛津大学等机构的研究表明，人工智能语言模型GPT-4已经达到了成年人的心智理论水平，并且在更复杂的心理推理上超越了人类。在多个测试中，GPT-4显示出了卓越的表现，包括理解讽刺和暗示，甚至在某些情况下超过了人类。研究还发现，虽然LLM（大型语言模型）在事实回忆任务上表现出色，但在心智理论任务中存在不足之处，尤其是在第5到6阶的心理推理能力上。这些结果表明GPT-4不仅能够理解和生成人类的对话，而且还能进行复杂的情感和意图推理，并且可能在多方冲突的情况下做出道德判断。然而，研究者指出，LLM在某些情况下过于保守，不愿意提供确定性的意见。这项研究的发现为我们了解AI如何接近人类智能提供了新的见解，同时也提出了关于AI伦理和应用的重要问题。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3JOIO7G0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/q8B0sgyv8uu5cuYQmJy4lQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/q8B0sgyv8uu5cuYQmJy4lQ&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AI资讯·0531] 达摩院医疗AI成就新里程碑，其多癌早筛技术获得世卫组织合作，将推广至全球发展中国家。OpenAI价值数十亿美元，微软投资130亿美元，纳德拉担忧影响。百度文库成为一站式AI内容获取与创作平台，提供智能画本、PPT生成等功能，累计用户1.4亿，AI新功能使用次数超过15亿。三大运营商完成产品市场匹配“进化”，致力于构建适宜的生长环境以支撑技术价值兑现。在人工智能领域，获得成功PMF需多次尝试，持续调整以适应市场变化至关重要。</title>
        <link>https://ntopic.cn/p/ai20240531/</link>
        <pubDate>Fri, 31 May 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240531/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240531/ai20240531-53.jpg" alt="Featured image of post [AI资讯·0531] 达摩院医疗AI成就新里程碑，其多癌早筛技术获得世卫组织合作，将推广至全球发展中国家。OpenAI价值数十亿美元，微软投资130亿美元，纳德拉担忧影响。百度文库成为一站式AI内容获取与创作平台，提供智能画本、PPT生成等功能，累计用户1.4亿，AI新功能使用次数超过15亿。三大运营商完成产品市场匹配“进化”，致力于构建适宜的生长环境以支撑技术价值兑现。在人工智能领域，获得成功PMF需多次尝试，持续调整以适应市场变化至关重要。" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;苹果OpenAI曝出「数十亿美元」合作，微软急了！纳德拉紧急约谈奥特曼&lt;/li&gt;
&lt;li&gt;Hinton奥特曼重磅出席联合国AI大会，代表中国AI登台的竟是一位「癌患者」？&lt;/li&gt;
&lt;li&gt;这家产品AI用户过亿，月活第一，覆盖学习办公教育，有人用来赚钱&lt;/li&gt;
&lt;li&gt;AI在咳嗽中检出癌症，不信？世卫组织正全球推广&lt;/li&gt;
&lt;li&gt;1/3年轻人愿和AI交朋友，超1成年轻人已经靠AIGC赚过钱了&lt;/li&gt;
&lt;li&gt;OpenAI新老董事激辩：奥特曼是不是爱撒谎，OpenAI是不是忽视安全&lt;/li&gt;
&lt;li&gt;索尼影视：将使用人工智能制作电影，能省太多钱&lt;/li&gt;
&lt;li&gt;解决Transformer根本缺陷，CoPE论文爆火：大模型都能巨大改进&lt;/li&gt;
&lt;li&gt;AI内容创作开卷，为什么百度文库成为超强玩家？&lt;/li&gt;
&lt;li&gt;运营商大模型的进化路线“分野”&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;苹果openai曝出数十亿美元合作微软急了纳德拉紧急约谈奥特曼&#34;&gt;苹果OpenAI曝出「数十亿美元」合作，微软急了！纳德拉紧急约谈奥特曼&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240531/ai20240531-58.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240531/ai20240531-58_hu8fe5b556654b1ccb5692d42d8632207f_163953_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240531/ai20240531-58_hu8fe5b556654b1ccb5692d42d8632207f_163953_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;苹果OpenAI曝出「数十亿美元」合作，微软急了！纳德拉紧急约谈奥特曼&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;苹果与OpenAI达成数十亿美元合作，微软CEO纳德拉担忧影响。苹果计划对Siri进行AI现代化改造，2025年推出高级版。OpenAI可能价值数十亿美元，微软投资130亿美元。Altman曾是苹果迷，希望与苹果合作，重塑AI技术。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3H4SHPD0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;hinton奥特曼重磅出席联合国ai大会代表中国ai登台的竟是一位癌患者&#34;&gt;Hinton奥特曼重磅出席联合国AI大会，代表中国AI登台的竟是一位「癌患者」？&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240531/ai20240531-57.jpg&#34;
	width=&#34;767&#34;
	height=&#34;478&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240531/ai20240531-57_hu68b0f613597cdac06fd472feb9c859c1_92558_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240531/ai20240531-57_hu68b0f613597cdac06fd472feb9c859c1_92558_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Hinton奥特曼重磅出席联合国AI大会，代表中国AI登台的竟是一位「癌患者」？&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;385px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;摘要：达摩院医疗AI取得新里程碑，被《自然·医学》评价为“开启医疗影像AI黄金时代”。世卫组织与达摩院合作，将推广其多癌早筛技术至发展中国家。达摩院在日内瓦的AIforGood峰会上展示了其AI多癌早筛技术，成功治疗了首例由AI发现的胰腺癌患者。此技术已被WHO评为全球亮点研究，并将向全世界推广。达摩院与国际顶级机构合作，正在开发更多应用，旨在降低癌症检测成本并提高早期诊断率。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3H4TPB00511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;这家产品ai用户过亿月活第一覆盖学习办公教育有人用来赚钱&#34;&gt;这家产品AI用户过亿，月活第一，覆盖学习办公教育，有人用来赚钱&lt;/h2&gt;
&lt;p&gt;百度文库凭借其庞大的资源积累、自由的AI体验和持续的产品迭代，成为了一站式AI内容获取和创作平台。它的智能画本功能支持图文声并茂AI视频画本创作，实现了跨模态的创作能力。百度文库还推出了橙篇，一个集专业知识检索、问答、超长图文理解与生成、深度编辑和整理于一体的AINative产品。它不仅在PPT生成等领域取得领先地位，还获得了国家工信安全中心的大模型赋能智慧办公评测报告第一名。百度文库正在通过持续迭代和用户反馈，打磨产品，成为一个真正意义上的智能体，提供直接可用的生产力，让用户无需动脑，“就像一个人那样陪伴着用户”。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3H6121U0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai在咳嗽中检出癌症不信世卫组织正全球推广&#34;&gt;AI在咳嗽中检出癌症，不信？世卫组织正全球推广&lt;/h2&gt;
&lt;p&gt;联合国举办了AIforGood峰会，中国代表团与全球专家共同探讨人工智能在医疗领域的应用。其中，中国女性患者通过AI胰腺癌早筛技术成功诊断并治疗，这项技术由达摩院开发，已获得国际认可，并且被联合国秘书长和其他顶尖AI专家参会。该技术利用深度学习在低对比度CT图像中识别微小病灶，提高了早期癌症的诊断率。此外，达摩院还正在开发多种癌症早筛产品，旨在通过一次平扫CT实现多种疾病的检测，并且已在中国和海外多个国家实施。该技术的普及性和有效性得到了国际认可，展现了AI在解决全球公共卫生问题中的潜力。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3H6A8430511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;13年轻人愿和ai交朋友超1成年轻人已经靠aigc赚过钱了&#34;&gt;1/3年轻人愿和AI交朋友，超1成年轻人已经靠AIGC赚过钱了&lt;/h2&gt;
&lt;p&gt;SoulApp通过AI技术在社交领域创新，推出AI聊天助理、AI合唱等功能，并引入沉浸式AI聊天陪伴应用“异世界回响”。SoulCTO陶明指出，行业中许多公司拥有强大模型，但对用户理解和场景使用不足。Soul利用其庞大的社交数据、深厚的企业基因和高活跃生态，为AI社交布局提供了优势。通过AIGC+SoulX模型，Soul实现了情感化互动，推出了多元社交网络，包括语音音乐、AI情感陪伴等领域的探索。数据显示，一部分年轻人愿意与AI成为朋友，而他们对AI互动的态度整体积极。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3H70A830511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;openai新老董事激辩奥特曼是不是爱撒谎openai是不是忽视安全&#34;&gt;OpenAI新老董事激辩：奥特曼是不是爱撒谎，OpenAI是不是忽视安全&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240531/ai20240531-53.jpg&#34;
	width=&#34;336&#34;
	height=&#34;252&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240531/ai20240531-53_hu18dde3f9faafe29844bcf099e5afb848_93330_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240531/ai20240531-53_hu18dde3f9faafe29844bcf099e5afb848_93330_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;OpenAI新老董事激辩：奥特曼是不是爱撒谎，OpenAI是不是忽视安全&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;本周，OpenAI现任与前任董事会成员就公司治理和人工智能安全问题展开公开辩论。本次争议始于前董事会成员海伦·托纳和塔莎·麦考利在《经济学人》发表文章，批评首席执行官萨姆·奥特曼及其公司的安全实践，并呼吁对AI行业加强监管。现任董事布雷特·泰勒和拉里·萨默斯则回应称，OpenAI已成立新安全委员会，向白宫提交了自愿承诺，以增强安全性，并委托律师事务所进行内部调查，结果表明奥特曼解职并非因产品安全或速度问题。泰勒和萨默斯还否认了对奥特曼的指控，称他在相关问题上坦率合作。随后，OpenAI成立新安全委员会，支持有效监管人工通用智能，展现出公司对于安全性的承诺。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/tech/article/J3H86NN900097U7T.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;索尼影视将使用人工智能制作电影能省太多钱&#34;&gt;索尼影视：将使用人工智能制作电影，能省太多钱&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240531/ai20240531-52.jpg&#34;
	width=&#34;336&#34;
	height=&#34;252&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240531/ai20240531-52_hu890eae3471e1d95ece0a2f5e486489c1_89286_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240531/ai20240531-52_hu890eae3471e1d95ece0a2f5e486489c1_89286_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;索尼影视：将使用人工智能制作电影，能省太多钱&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;索尼影视娱乐公司首席执行官托尼·文西奎拉表示，公司计划利用人工智能降低电影制作成本。他强调，虽然人工智能在提高效率方面具有巨大潜力，但也引发了行业内关于创意工作的担忧。文西奎拉提到，去年的人工智能问题导致长期罢工，并表示即将进行的谈判将决定公司在这领域能采取什么行动。他还强调，索尼影视娱乐不会偏离过去几年的成功战略，不会涉足超出其确定范围的业务。尽管对派拉蒙的流媒体服务Paramount+持保留态度，但文西奎拉认为Crunchyroll将是公司未来增长的关键驱动力。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/tech/article/J3HA8B4M00097U7T.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;解决transformer根本缺陷cope论文爆火大模型都能巨大改进&#34;&gt;解决Transformer根本缺陷，CoPE论文爆火：大模型都能巨大改进&lt;/h2&gt;
&lt;p&gt;马斯克和LeCun的口水战吸引了公众的注意力。LeCun在推特上宣传最新论文，并向马斯克暗示他们可以应用于GrokAI。该论文《ContextualPositionEncoding:LearningtoCountWhat&amp;rsquo;sImportant》由MetaFAIR发布，已成为24小时内最热门的AI领域论文之一，解决大型语言模型（LLM）的计数和复制问题。CoPE是一种新方法，将上下文与位置编码结合起来。它通过使用门控机制来选择性地编码位置信息，允许模型更好地理解输入数据的结构和语义内容。在多个实验中，CoPE显示出在选择性复制、计数任务和语言建模等方面优于传统方法的性能。该研究为大型语言模型提供了一种更加高效和灵活的位置编码方式，将可能改变LLM中的位置编码规则。它使模型能够精确定位句子中的特定单词、名词或句子，非常令人兴奋。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3HFB71L0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai内容创作开卷为什么百度文库成为超强玩家&#34;&gt;AI内容创作开卷，为什么百度文库成为超强玩家？&lt;/h2&gt;
&lt;p&gt;在2024年5月30日的百度移动生态万象大会上，百度文库基于文心大模型进行了全面重构，成为一站式AI内容获取和创作平台。该平台提供多种AI功能，如智能画本、智能PPT生成、研究报告生成等，极大地提高了学习办公效率，并且降低了创建高质量内容的门槛。此外，百度文库还推出了首个跨模态AI画本创作能力，让普通用户也能轻松制作出专业级别的视频画本。AI漫画和小说生成功能使得非专业人士也能创作出可供商业变现的作品。百度文库内置的AI能力深受用户喜爱，累计用户达1.4亿，AI新功能使用次数超过15亿。百度文库还推出了全新的AI原生应用“橙篇”，提供超长文档理解、总结与问答等多种功能，为学术研究和专业写作提供了强大的支持。随着文心大模型5.0的即将发布，预计将带来更全面的内容创作能力，包括视频、音频和代码等更多形式的互生转换。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3HFR9KJ0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;运营商大模型的进化路线分野&#34;&gt;运营商大模型的进化路线“分野”&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240531/ai20240531-49.jpg&#34;
	width=&#34;640&#34;
	height=&#34;400&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240531/ai20240531-49_hu9510a465b74b243348362536f1caa318_23600_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240531/ai20240531-49_hu9510a465b74b243348362536f1caa318_23600_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;运营商大模型的进化路线“分野”&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在五月，三大运营商中国移动、中国电信和中国联通集体完成了产品市场匹配（PMF）的“进化”，这是指产品能够满足目标市场需求并吸引用户的程度，对产品成功至关重要。在人工智能领域，获得一次成功的PMF通常需要多次尝试，即使是ChatGPT这样的划时代产品也是基于前两代模型成长起来的。持续完成市场匹配意味着大型模型必须具备演进能力。运营商在AI产品开发上被认为更倾向于保守，这可能会阻碍快速调整以适应市场变化。然而，自2023年开始大规模进入大模型时代后，三大运营商的发展路线已经开始出现差异性。中国移动致力于为大模型“筑巢”，构建更适宜的生长环境；中国电信则专注于自身能力提升，培养拥有强大能力的模型；而中国联通着眼于特定需求的满足，营造良好的外部产业环境。运营商的大模型进化路线各有侧重点，但共同目标是完成产品市场匹配，让自己的产品在不同阶段和场景中满足市场需求并实现商业价值。通过自主化、算力网络、行业积累和自身需求的满足，运营商大模型正在逐步发挥优势，找到与市场的结合点，以此支撑技术价值在产业中的兑现。随着时间的推移，运营商的大模型虽然路线各异，但共同特征是持续演进。他们不断补全模态能力、增强模型能力和构建AI基础生态，以确保能够适应不断变化的市场需求，从而保持在大型模型领域的竞争力。通过这样的“进化”，运营商有望在AI产业中实现快速迭代并最终完成产品市场匹配，可能会在技术公司之前取得商业成功。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3GQ4JAF0511FMIQ.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AI资讯·0529] JanLeike，OpenAI超级对齐团队负责人加入Anthropic，Anthropic成为了OpenAI离职员工的避难所。Leike表示将继续执行超级对齐任务，在Anthropic致力于可扩展监督、弱到强泛研究。DarioAmodei因安全观念与OpenAI不合离开，带走了政策负责人JackClark。Anthropic注重模型安全，对齐能力更强，其产品Claude3获得好评。Leike的团队正在组建中，研究可扩展监督技术练，但预计不会在90天内发布。</title>
        <link>https://ntopic.cn/p/ai20240529/</link>
        <pubDate>Wed, 29 May 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240529/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240529/ai20240529-28.jpg" alt="Featured image of post [AI资讯·0529] JanLeike，OpenAI超级对齐团队负责人加入Anthropic，Anthropic成为了OpenAI离职员工的避难所。Leike表示将继续执行超级对齐任务，在Anthropic致力于可扩展监督、弱到强泛研究。DarioAmodei因安全观念与OpenAI不合离开，带走了政策负责人JackClark。Anthropic注重模型安全，对齐能力更强，其产品Claude3获得好评。Leike的团队正在组建中，研究可扩展监督技术练，但预计不会在90天内发布。" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一年心血被毁，OpenAI超级对齐负责人愤而出走Anthropic！Ilya去向依旧成谜&lt;/li&gt;
&lt;li&gt;GPT-5倒计时！奥特曼踢走Ilya得逞，宫斗惊人内幕再曝光&lt;/li&gt;
&lt;li&gt;和GPT-4这些大模型玩狼人杀，人类因太蠢被票死，真·反向图灵测试&lt;/li&gt;
&lt;li&gt;奥特曼挂帅新团队，OpenAI新一代大模型开训，前任高管却投敌了&lt;/li&gt;
&lt;li&gt;OpenAI成立新安全委员会，Altman领导，90天后“交卷”&lt;/li&gt;
&lt;li&gt;AI进入体育中考！直击行业四大痛点，格灵深瞳抢滩校园体育新蓝海&lt;/li&gt;
&lt;li&gt;前OpenAI安全主管跳槽，加盟竞争对手Anthropic，继续做超级对齐&lt;/li&gt;
&lt;li&gt;联手国产大模型五虎，云计算大厂启动重磅生成式AI计划&lt;/li&gt;
&lt;li&gt;OpenAI联创Greg最新采访：为什么OpenAI最先做出GPT-4？&lt;/li&gt;
&lt;li&gt;独角兽被微软挖角，新团队首曝光！情感AI嵌入机器人，超大内存升级情感体验&lt;/li&gt;
&lt;li&gt;AI智能体的炒作与现实：GPT-4都撑不起，现实任务成功率不到15%&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;一年心血被毁openai超级对齐负责人愤而出走anthropicilya去向依旧成谜&#34;&gt;一年心血被毁，OpenAI超级对齐负责人愤而出走Anthropic！Ilya去向依旧成谜&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240529/ai20240529-48.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240529/ai20240529-48_hudb27477b111d7b38ce5f48e7c12af365_129670_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240529/ai20240529-48_hudb27477b111d7b38ce5f48e7c12af365_129670_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;一年心血被毁，OpenAI超级对齐负责人愤而出走Anthropic！Ilya去向依旧成谜&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;JanLeike，OpenAI超级对齐团队负责人，宣布加入Anthropic并开始招募新成员。Anthropic成为了OpenAI离职人员的避难所，与OpenAI在价值观上存在差异。Leike表示高兴能继续执行超级对齐任务，在Anthropic将致力于可扩展监督、弱到强泛化和自动对齐研究。Anthropic创立者DarioAmodei因安全观念与OpenAI不合而离开，带走了政策负责人JackClark。Anthropic注重模型安全，对齐能力更强，其产品Claude3获得业内好评。Leike的团队正在紧锣密鼓组建中，研究可扩展监督技术以控制大规模AI。IlyaSutskever离开OpenAI后未公布下一步计划，但可能加入Anthropic、xAI或创办自己的公司。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3C03IEH0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;gpt-5倒计时奥特曼踢走ilya得逞宫斗惊人内幕再曝光&#34;&gt;GPT-5倒计时！奥特曼踢走Ilya得逞，宫斗惊人内幕再曝光&lt;/h2&gt;
&lt;p&gt;OpenAI解散了Ilya领导的超级对齐团队，成立了新的安全委员会。下一代前沿模型正在训练中，但预计不会在90天内发布。新安全委员会将评估和改进现有AI安全流程，并在期满后与董事会分享结果。一些人担忧新委员会的独立性，考虑到OpenAI内部的权力斗争和奥特曼领导下的安全团队的问题。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3C534AI0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;和gpt-4这些大模型玩狼人杀人类因太蠢被票死真反向图灵测试&#34;&gt;和GPT-4这些大模型玩狼人杀，人类因太蠢被票死，真·反向图灵测试&lt;/h2&gt;
&lt;p&gt;这是一次「反向图灵测试」，几个全球最先进的大模型坐在一起，坐着火车唱歌，但其中混进了人类：AI的任务，是把这个人类揪出来。最近，一位网友在X平台发布的一段视频引发了人们的讨论。在视频中，四个AINPC与一个人类坐在一起，按照「乘务员」的要求互相试探，找出隐藏的人类。每个NPC对应着一款大模型。五位扮演者分别是：古希腊巨哲亚里士多德（GPT4Turbo），维也纳古典乐派代表人物莫扎特（Claude3Opus），意大利文艺复兴时期画家列奥纳多・达・芬奇（Llama3），蒙古军事家成吉思汗（人类），埃及艳后克利奥帕特拉七世（GeminiPro）。AINPC在对话中展现了深厚的历史知识和洞察力，甚至在最后一轮投票中，人类「叛徒」被淘汰。AINPC的语言表达和情感描绘不仅逼真，而且具有深度思维能力。随着大型语言模型（LLM）在文本生成、拟人化对话、语气表达和遣词造句方面越来越接近人类，AINPC模拟正在成为游戏行业探索的「新赛道」。AINPC的优势是它们不再是按照游戏中预设选项进行机械对话，而是能够通过AI自主生成的动作和反应，进行富有真实感的实时对话。然而，AINPC还面临一些挑战。首先，它们必须与游戏状态保持同步，避免产生幻觉和破坏游戏逻辑。其次，AI需要理解游戏世界模型，并且不能基于这个模型产生幻觉。再者，每个角色都有自己的知识限制，AI需要遵守这些规则。最后，随着游戏的进行，AI需要实时更新和适应变化。总之，为了让AINPC顺利走入3A大作，开发者需要在以上几个方向努力：避免幻觉、理解游戏世界模型、了解每个角色知识限制、随着游戏进展更新信息、了解游戏机制实际操作范围。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3C5AGPS0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;奥特曼挂帅新团队openai新一代大模型开训前任高管却投敌了&#34;&gt;奥特曼挂帅新团队，OpenAI新一代大模型开训，前任高管却投敌了&lt;/h2&gt;
&lt;p&gt;OpenAI面临安全性质疑后，成立新委员会，由BretTaylor、AdamD&amp;rsquo;Angelo、NicoleSeligman和CEOSamAltman领导，以确保关键项目决策的安全性。同时，公司宣布正在训练下一代前沿模型，预计将提升通往AGI的能力。安全委员会在90天内评估并发展开发流程与保障措施，并计划公开采纳建议后的最新情况。OpenAI还咨询了其他AI安全专家以支持其工作。此外，公司面临创始人、首席科学家IlyaSutskever离职和超级对齐团队解散的挑战，以及前董事会成员HelenToner批评公司安全流程不透明。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3C82F2B0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;openai成立新安全委员会altman领导90天后交卷&#34;&gt;OpenAI成立新安全委员会，Altman领导，90天后“交卷”&lt;/h2&gt;
&lt;p&gt;OpenAI成立了一个安全与保障委员会，由董事长BretTaylor和其他成员领导，负责提出关键安全决策建议。随着新一代模型训练，该委员会将在90天内评估并完善流程与防护措施，并向全体董事会报告。预计这些系统将提升OpenAI通往通用人工智能的能力。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3CJRIU5051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai进入体育中考直击行业四大痛点格灵深瞳抢滩校园体育新蓝海&#34;&gt;AI进入体育中考！直击行业四大痛点，格灵深瞳抢滩校园体育新蓝海&lt;/h2&gt;
&lt;p&gt;摘要：随着“双减”政策和教育部门推动下，校园体育正迅速发展。传统方法无法满足效率、准确性和公正性的需求，因此出现了AI技术的介入。格灵深瞳在上半年体育中考中应用其深瞳阿瞳目体育训考系统，在京津冀地区11个考试场次，5万名考生，覆盖20余科目，提高了效率和准确性。该系统利用纯视觉AI技术，实现运动精确识别、数据实时采集分析，为教学提供依据，解决了传统红外设备的局限性，如环境干扰大等。格灵深瞳的优势在于全流程纯视觉AI解决方案，覆盖检录、考试到检出，全过程无人工干预，提高了测试效率和规模，同时降低了争议和申诉。系统还采用人脸识别核验考生身份，减少了替考现象。此外，该系统在裁判人数上有显著减少，对于球类运动科目尤其有效。格灵深瞳的产品差异化特性包括硬件软件全套解决方案，针对体育教育四大痛点，提供先进的硬件设备和算法，辅助教学提高效率，个性化教学计划，并为教练提供数据分析报告。此外，格灵深瞳的AI技术具有高度适应性和环境稳定性，能够在复杂场景下保持高准确率。通过持续的技术积累和实践应用，格灵深瞳在体育教育领域占据领先地位，展现了智能化转型的未来趋势。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3CKPT11051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;前openai安全主管跳槽加盟竞争对手anthropic继续做超级对齐&#34;&gt;前OpenAI安全主管跳槽，加盟竞争对手Anthropic，继续做超级对齐&lt;/h2&gt;
&lt;p&gt;前OpenAI高管JanLeike加入竞争对手Anthropic，曾领导超级对齐团队。Leike离开OpenAI后指责ChatGPT制造商将产品置于安全文化和流程之前。Anthropic由DarioAmodei和DanielaAmodei创立，获得亚马逊40亿美元投资，定位为更注重安全的公司。OpenAI已成立安全与保障委员会，并开始测试“下一代前沿模型”。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3CLDDO8051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;联手国产大模型五虎云计算大厂启动重磅生成式ai计划&#34;&gt;联手国产大模型五虎，云计算大厂启动重磅生成式AI计划&lt;/h2&gt;
&lt;p&gt;亚马逊云科技在上海举办峰会，宣布推出多项新业务举措，包括生成式AI合作伙伴计划和四大合作伙伴计划。储瑞松表示，生成式AI将带来行业应用的最大价值，企业应关注业务场景、模型选择、数据利用和持续提升。亚马逊云科技推出AmazonBedrock服务，提供多种模型选择，已有超10,000客户使用。此外，峰会上展示了多个行业解决方案，如自动驾驶、智能家居、游戏等，并强调了安全合作伙伴计划的重要性。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3CM05UO051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;openai联创greg最新采访为什么openai最先做出gpt-4&#34;&gt;OpenAI联创Greg最新采访：为什么OpenAI最先做出GPT-4？&lt;/h2&gt;
&lt;p&gt;OpenAI首先开发出GPT-4等强大模型，原因之一在于其团队的独特组合，既有学术背景的研究型人才，又有优秀的工程人才，这使得他们能够从多个角度解决问题，推动项目更有效地前进。GregBrockman认为，他们是计算机发展史上一种趋势的一部分，致力于实现人工智能（AGI）造福人类的目标。尽管存在安全性和其他风险，OpenAI通过实践学习不断迭代，并致力于将技术用于教育等领域，以增强而非削弱人类能力。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J39DRK0M0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;独角兽被微软挖角新团队首曝光情感ai嵌入机器人超大内存升级情感体验&#34;&gt;独角兽被微软挖角，新团队首曝光！情感AI嵌入机器人，超大内存升级情感体验&lt;/h2&gt;
&lt;p&gt;InflectionAI，一个专注于情感智能的人工智能公司，在其创始人MustafaSuleyman被微软挖角后，经历了领导层变动。尽管如此，该公司仍然拥有15.25亿美元的资金，并计划继续扩大工程团队。新任CEOSeanWhite、CTOVibhuMittal、COOTedShelton和CMOIanMcCarthy组成的团队致力于开发具有情感共鸣的个人AI助理Pi，旨在为企业提供具有同理心的聊天机器人。InflectionAI通过其「移情微调」技术定制模型，以提高个性化服务质量，并计划与品牌合作，建立自己的AI工作室，提供客服和内部员工支持。尽管竞争激烈，但公司拥有充足资金和经验丰富的团队，有望在B2B市场中取得成功。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J39DRVVG0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai智能体的炒作与现实gpt-4都撑不起现实任务成功率不到15&#34;&gt;AI智能体的炒作与现实：GPT-4都撑不起，现实任务成功率不到15%&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240529/ai20240529-30.jpg&#34;
	width=&#34;1080&#34;
	height=&#34;490&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240529/ai20240529-30_hu565b145745a44d45e6d4139e616412aa_23129_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240529/ai20240529-30_hu565b145745a44d45e6d4139e616412aa_23129_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AI智能体的炒作与现实：GPT-4都撑不起，现实任务成功率不到15%&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;220&#34;
		data-flex-basis=&#34;528px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;随着大型语言模型（LLMs）的进步，它们在性能、准确度和稳定性方面取得了显著提升，但现有版本的LLMs综合能力不足以支持完整的AI智能体。多模态、多任务和多领域成为AI智能体必需，但实际应用效果不佳，提醒初创公司和科技巨头保持脚踏实地，先从AI增强功能入手。LLMs可以执行复杂任务，但现实表现超出预期的挑战性。WebArena排行榜显示，即使是表现最好的模型在现实任务中的成功率也只有35.8%。AI智能体定义不一，主要有单一智能体和多智能体两种架构。当前，AI智能体面临输出不精确、性能差、成本高等问题。在初创公司的尝试中，只有MultiOn追求给出指令并观察其执行，这与AI智能体承诺更为一致。大公司正在将AI功能集成到桌面和浏览器中，展现了令人印象深刻的技术。作者认为AI智能体被过度炒作，但仍期待看到基础模型和架构进步带来的成功应用。AI智能体前途最有希望的道路是利用AI增强现有工具，而不是提供全自主独立服务，结合严格约束的LLMs、良好的评估数据、人机协同监督和传统工程方法，以实现可靠和良好的结果。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J3A2NFDC0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AI资讯·0527] AI领域面临挑战：OpenAI员工离职、外界批评；新安全团队成立。马斯克的xAI获得60亿美元投资，估值180亿。国内大模型厂商降价争夺市场份额。中国电信推出多方言语音识别模型。AI评估工具讨论：JasonWei提倡简单易用且针对特定任务。苹果WWDC展示新AI战略。ChatGPT性能测试，Perplexity获胜。联想业绩回暖，AI技术促进PC市场复苏。中国移动推出自主研发的大型全栈模型。AI是否具备“心智理论”争议；谷歌AI搜索引擎遇错误问题；硅谷AI产业发展至鸡尾酒模式，初创企业需专注数据质量。</title>
        <link>https://ntopic.cn/p/ai20240527/</link>
        <pubDate>Mon, 27 May 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/ai20240527/</guid>
        <description>&lt;img src="https://ntopic.cn/p/ai20240527/ai20240527-23.jpg" alt="Featured image of post [AI资讯·0527] AI领域面临挑战：OpenAI员工离职、外界批评；新安全团队成立。马斯克的xAI获得60亿美元投资，估值180亿。国内大模型厂商降价争夺市场份额。中国电信推出多方言语音识别模型。AI评估工具讨论：JasonWei提倡简单易用且针对特定任务。苹果WWDC展示新AI战略。ChatGPT性能测试，Perplexity获胜。联想业绩回暖，AI技术促进PC市场复苏。中国移动推出自主研发的大型全栈模型。AI是否具备“心智理论”争议；谷歌AI搜索引擎遇错误问题；硅谷AI产业发展至鸡尾酒模式，初创企业需专注数据质量。" /&gt;&lt;h2 id=&#34;ai资讯&#34;&gt;AI资讯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AI初创集体跳槽OpenAI，Ilya出走后安全团队重整旗鼓！&lt;/li&gt;
&lt;li&gt;港大字节提出多模态大模型新范式，模拟人类先感知后认知&lt;/li&gt;
&lt;li&gt;435亿！马斯克xAI官宣B轮融资，估值突破1300亿&lt;/li&gt;
&lt;li&gt;深扒大模型价格战：15家45款模型比拼，谁真便宜谁“打幌子”？&lt;/li&gt;
&lt;li&gt;换了30多种方言，我们竟然没能考倒中国电信的语音大模型&lt;/li&gt;
&lt;li&gt;CoT提出者Jason Wei：大模型评估基准的「七宗罪」&lt;/li&gt;
&lt;li&gt;苹果AI战略曝光：秘密大招Project Greymatter，GPT被整合进iOS，新AI工具主&lt;/li&gt;
&lt;li&gt;大模型时代的计算机视觉！CVPR 2024线上分享会全日程公布&lt;/li&gt;
&lt;li&gt;五大AI聊天机器人盲测！ChatGPT未能夺冠，最终赢家竟来自这家“小公司”&lt;/li&gt;
&lt;li&gt;AI让联想松了口气&lt;/li&gt;
&lt;li&gt;中国移动千亿多模态大模型发布，「九天-九九」风趣畅聊堪比GPT-4o&lt;/li&gt;
&lt;li&gt;GPT-4被证实具有「人类心智」登Nature！AI比人类更好察觉讽刺和暗示&lt;/li&gt;
&lt;li&gt;谷歌AI搜索惨败，竟教唆网友自杀！&lt;/li&gt;
&lt;li&gt;硅谷VC张璐：硅谷大模型市场分为三类，三大应用领域迭代速度较快&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ai初创集体跳槽openaiilya出走后安全团队重整旗鼓&#34;&gt;AI初创集体跳槽OpenAI，Ilya出走后安全团队重整旗鼓！&lt;/h2&gt;
&lt;p&gt;OpenAI面临内外交困，包括员工离职和外界批评。为了应对AI安全问题，上周五名与安全相关的员工离职，其中包括两名知名成员。《财富》杂志指出，OpenAI未兑现承诺给超级对齐团队20%计算资源。就在此时，Indent首席执行官FouadMatin宣布加入OpenAI，致力于为AGI做好安全准备。他和他的团队包括DanGillespie，后者将专注于建立用于AGI到来的安全计算平台。尽管OpenAI面临挑战，但新安全团队的加入被视为对构建更安全系统的积极努力。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J36QIPRT0511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;港大字节提出多模态大模型新范式模拟人类先感知后认知&#34;&gt;港大字节提出多模态大模型新范式，模拟人类先感知后认知&lt;/h2&gt;
&lt;p&gt;当前多模态大模型在视觉任务中展现出强大认知理解能力，但大部分模型仅能单向图像理解，无法将内容映射回图像上，限制了其应用，如图像编辑、自动驾驶等。研究人员提出Groma，通过区域性图像编码提升多模态大模型的定位能力，将文本与图像区域直接关联，显著提高交互性和指向性。Groma将定位转移到visiontokenizer中，利用其空间理解能力，避免了外接专家模型。实验结果显示Groma在GroundingBenchmarks和VQABenchmark上表现超越其他模型，支持融合对话和定位能力的任务。Groma提供了一种新的解决思路，将感知和认知解耦，让visiontokenizer负责感知，大语言模型负责认知，这种先感知后认知的形式符合人类视觉过程，避免了重新训练大语言模型的计算开销。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J36SDSGC0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;435亿马斯克xai官宣b轮融资估值突破1300亿&#34;&gt;435亿！马斯克xAI官宣B轮融资，估值突破1300亿&lt;/h2&gt;
&lt;p&gt;马斯克旗下的xAI获得60亿美元B轮融资，估值180亿美元，成为独角兽。投资方包括特斯拉早期投资者安东尼奥·格拉西亚斯的ValorEquityPartners、迪拜投资公司VyCapital等。xAI成立不到一年，已推出聊天机器人Grok，并计划与OpenAI竞争。尽管马斯克在X公司遭遇下滑，但特斯拉和SpaceX的表现赢得了投资者信心。新融资将用于开发和迭代Grok，使其与OpenAI、Meta等大型语言模型保持竞争力。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J370NMPO051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;深扒大模型价格战15家45款模型比拼谁真便宜谁打幌子&#34;&gt;深扒大模型价格战：15家45款模型比拼，谁真便宜谁“打幌子”？&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240527/ai20240527-24.jpg&#34;
	width=&#34;531&#34;
	height=&#34;332&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240527/ai20240527-24_hue673a85c97faf7f96f3efc692292d4df_92527_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240527/ai20240527-24_hue673a85c97faf7f96f3efc692292d4df_92527_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;深扒大模型价格战：15家45款模型比拼，谁真便宜谁“打幌子”？&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;国内大模型厂商近日爆发了降价风暴，阿里云、百度等互联网巨头纷纷宣布降低大模型价格，甚至有些模型免费开放。这场“百模大战”让开发者受益匪浅，但也引发了对产业影响的广泛讨论。智东西统计了45款大模型API的价格，对比发现虽然各厂商宣扬的降价幅度高达95%以上，但实际上主力模型的价格并未显著下降。部分创业公司选择不参与这场价格战，认为技术和数据收集才是核心竞争力。价格战背后的原因各有解释，从云厂商角度出发，通过降价强化市场地位；从创企视角看，则是为了吸引关注和客户。部分观点认为这场价格战更多是云服务大厂在云市场争夺中的一种策略，而非真正的大模型“内卷”。对于开发者而言，价格下降有利于应用的开发，但也意味着技术突破和数据价值更为重要。产业影响方面，有观点认为这场价格战可能导致恶性竞争，但也有助于淘汰弱势企业，推动产业集中。同时，对私有化部署、大模型的应用发展都有积极作用。总之，这场百模大战或将面临洗牌，未来只有那些真正具备技术和商业模式优势的企业才能笑到最后。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J370NMST051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;换了30多种方言我们竟然没能考倒中国电信的语音大模型&#34;&gt;换了30多种方言，我们竟然没能考倒中国电信的语音大模型&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240527/ai20240527-23.jpg&#34;
	width=&#34;950&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240527/ai20240527-23_hud819261146edf9ec90c9c9054e94efb4_66761_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240527/ai20240527-23_hud819261146edf9ec90c9c9054e94efb4_66761_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;换了30多种方言，我们竟然没能考倒中国电信的语音大模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;中国电信人工智能研究院（TeleAI）发布了业内首个支持30种方言自由混说的「星辰超多方言语音识别大模型」，能够识别理解粤语、上海话、四川话等各地方言，打破语言沟通的壁垒。该模型在多项基准测试中表现出色，尤其是在国际语音顶会Interspeech2024中获得冠军。此外，该技术还被应用于中国电信万号智能客服系统和翼声平台，实现了方言识别的全覆盖，为用户提供更加自然流畅的交互体验。随着大模型技术的发展，预计会推动方言文化的保护，并辅助历史文献和档案的数字化工作。中国电信作为运营商在人工智能领域的优势，使其能够加快大模型在各个领域的落地应用，形成新的经济增长点。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J370PJC70511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;cot提出者jason-wei大模型评估基准的七宗罪&#34;&gt;CoT提出者Jason Wei：大模型评估基准的「七宗罪」&lt;/h2&gt;
&lt;p&gt;李飞飞等人创建的ImageNet在视觉任务中被认为是一个测试金标准。在大型语言模型（LLM）时代，我们如何评估它们？目前，研究者提出了MMLU、GSM8K等评估基准，但这些是否完美？JasonWei在一篇博客中进行了深入探讨。他列举成功的评估基准，并总结失败原因，包括样本数量不足和评估复杂度高。Jason认为，评估工具的命名方式有待改进，例如HumanEval虽然叫做人类评估，但实际上未使用人类评估。为了让评估工具得到广泛使用，需要帮助研究者使用它，并提供推广机会。Jason也提出了解决测试集污染问题的一些建议。成功的评估基准包括GLUE/SuperGLU、MMLU、GSM8K、MATH和HumanEval，它们通常与突破性论文相关联。失败的评估基准可能因为样本数量不足、复杂度高或命名不当等原因而被忽视。Jason认为，要让评估工具得到广泛使用，需要提供单一数字指标，并且评估工具应该简单易用，不需要太多额外工作。此外，评估基准的设计应符合重要任务，如语言理解、数学问题解决，而不是娱乐性质的任务。Jason提到，LLMs对评估工具提出了新的挑战，目前尚无单一评估工具能全面评价它们。人类配对评估是一种流行趋势，但可能存在偏差。模型生成内容的评估也被讨论，但需要小心处理。评估工具的成功与否取决于其领域内专家认可，以及是否能够解决测试集污染问题。社区应该投资于评估工具，因为它们是AI研究人员客观评价模型的关键，并对该领域产生重大影响。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J371TUOK0511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;苹果ai战略曝光秘密大招project-greymattergpt被整合进ios新ai工具主&#34;&gt;苹果AI战略曝光：秘密大招Project Greymatter，GPT被整合进iOS，新AI工具主&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240527/ai20240527-21.jpg&#34;
	width=&#34;528&#34;
	height=&#34;330&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240527/ai20240527-21_hu6473268ef1a8c96d7ddc9ab0d89636ed_39660_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240527/ai20240527-21_hu6473268ef1a8c96d7ddc9ab0d89636ed_39660_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;苹果AI战略曝光：秘密大招Project Greymatter，GPT被整合进iOS，新AI工具主&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;苹果即将在WWDC上展示新的AI战略，包括ProjectGreymatter、本地和云端大模型数据处理、新AI功能、升级版Siri与OpenAI合作等。尽管落后于Google和OpenAI，但庞大的用户基础有望带来优势。新AI战略侧重于日常生活工具，计划在iOS18和macOS15中引入。Siri将升级为更自然的交互体验，而Xcode开发者工具也将增强AI功能。苹果还将推出个性化表情符号与云端处理M2Ultra芯片支持。虽然自研AI聊天机器人未达标，苹果则与OpenAI合作，但存在风险。尽管如此，苹果的庞大用户基数有望使其成为最大的AI玩家。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J37217HR051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;大模型时代的计算机视觉cvpr-2024线上分享会全日程公布&#34;&gt;大模型时代的计算机视觉！CVPR 2024线上分享会全日程公布&lt;/h2&gt;
&lt;p&gt;OpenAI的ChatGPT发布后，大型语言模型和人工智能生成内容的研究越来越受关注。计算机视觉（CV）领域也在经历变化。要快速了解AI研究进展，可以参加顶级会议论文分享会，如每年举办的CVPR。2024年，CVPR共收到11532份论文，2719篇被接收，录用率为23.6%。机器之心计划于2024年6月组织「CVPR2024线上论文分享会」，邀请AI社区成员参与。本次会议设置Keynote和论文分享环节，讨论CV热门主题。今天，分享会的全日程、Keynote嘉宾及演讲主题正式公布。金小刚将介绍数字人建模动画关键技术，朱俊彦将探讨创作者与生成模型的协作，芦清林将解读腾讯混元文生图算法核心——DIT架构，盛律则会谈多模态大语言模型与具身代理的结合。会议将在机器之心和黄大年茶思屋两个平台进行直播，欢迎大家关注预约。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J373UNL40511AQHO.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;五大ai聊天机器人盲测chatgpt未能夺冠最终赢家竟来自这家小公司&#34;&gt;五大AI聊天机器人盲测！ChatGPT未能夺冠，最终赢家竟来自这家“小公司”&lt;/h2&gt;
&lt;p&gt;《华尔街日报》对ChatGPT、Claude、Copilot、Gemini和Perplexity五大AI聊天机器人的性能进行了全面的测试，结果显示Perplexity综合排名第一，ChatGPT紧随其后。测试侧重于AI在解决实际问题和完成日常任务的能力，包括代码能力、健康咨询、财务问题等。评判标准为准确性、实用性和整体质量。微软的Copilot表现不佳，而Perplexity以其总结、代码和时事类问题的优异表现获得了冠军。此次测试显示，即使是知名度较高的ChatGPT也未能在所有方面领先，反而是小众的Perplexity夺得了胜利。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J37HCK0R051180F7.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;ai让联想松了口气&#34;&gt;AI让联想松了口气&lt;/h2&gt;
&lt;p&gt;联想集团2023/2024财年第四季度和全财年财报显示，尽管上半财年PC和服务器市场需求疲软，导致营收下滑8%至568.64亿美元，全年净利润37%下降，但在最新一季度表现出明显回暖。IDG收入为104.63亿美元，同比增长6.8%，ISG收入25.33亿美元，同比增长15%；SSG收入18.2亿美元，同比增长10%。AI技术起到关键作用，推动了PC市场的复苏，并成为联想业绩回暖的关键因素。不过，随着芯片制造商和终端厂商在AI领域加大投入，行业竞争激烈，联想是否能持续高增长还有待观察。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J36I6FAM05198R91.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;中国移动千亿多模态大模型发布九天-九九风趣畅聊堪比gpt-4o&#34;&gt;中国移动千亿多模态大模型发布，「九天-九九」风趣畅聊堪比GPT-4o&lt;/h2&gt;
&lt;p&gt;中国移动近日在数字中国建设峰会上宣布推出自主研发的“九天”千亿多模态基座大模型，这是国内最值得信赖和最懂行业的大型全栈模型。该模型采用纯解码与多专家相结合的架构，实现了结构化数据建模和渐进式学习，并提供不同参数量的模型版本，以适应各种设备和平台。中国移动在AI领域十年如一日的研发投入，使得“九天”模型在国际竞赛中取得优异成绩，包括语音合成和视觉理解等领域的冠军。“九天”模型不仅具有强大的推理能力，还能进行感知、预测、诊断、控制和决策，对复杂系统智能化有着重要作用。它能够部署在各种信源设备上，包括智能手机、平板、汽车和穿戴设备，并支持多种信源的适配，实现了“全模态”之间的智能化推理。中国移动聚焦于骨干行业，如通信、能源、建筑、交通等领域，为这些行业提供基座模型。该公司还致力于AI生态的国产化，包括算力、芯片、框架和算法，并提出了“万千百”智能基座计划，以实现大规模训练和推理算力的提升。此外，中国移动强调了模型安全性，通过了双备案认证，并获得了最高等级的安全性认证。十年来，中国移动在AI领域取得了跨越式发展，是国际AI领域的领头人冯俊兰博士带领团队不懈努力的结果。未来，中国移动将继续推动AI技术的应用，以实现“AI赋能，智筑国基”。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J32GQVM10511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;gpt-4被证实具有人类心智登natureai比人类更好察觉讽刺和暗示&#34;&gt;GPT-4被证实具有「人类心智」登Nature！AI比人类更好察觉讽刺和暗示&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240527/ai20240527-16.jpg&#34;
	width=&#34;238&#34;
	height=&#34;149&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240527/ai20240527-16_hu9687e298edfc19a2d14fb648cf14f2f3_9505_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240527/ai20240527-16_hu9687e298edfc19a2d14fb648cf14f2f3_9505_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GPT-4被证实具有「人类心智」登Nature！AI比人类更好察觉讽刺和暗示&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;AI是否具备「心智理论」的争议一直存在，尤其是随着大型语言模型（LLM）的发展，如ChatGPT。最新的研究显示，GPT-4在理解讽刺和暗示方面甚至超越了人类水平，但在判断失言时表现不佳。这可能是由于它过于谨慎，不愿意轻易给出确定答案，而不是因为缺乏理解能力。这些发现支持「超保守主义」假说，即GPT能够推断说话者心理状态，但不愿承诺单一解释。这种谨慎行为可能与模型的训练数据和设计有关，强调了能力与表现之间的差异，表明AI有能力进行复杂的心理推理，但在特定情况下可能不会像人类那样主动消除不确定性。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J347G8R40511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;谷歌ai搜索惨败竟教唆网友自杀&#34;&gt;谷歌AI搜索惨败，竟教唆网友自杀！&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/ai20240527/ai20240527-15.jpg&#34;
	width=&#34;876&#34;
	height=&#34;548&#34;
	srcset=&#34;https://ntopic.cn/p/ai20240527/ai20240527-15_hu6cb9b69cb0e6404c425f42b253f5812a_127943_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/ai20240527/ai20240527-15_hu6cb9b69cb0e6404c425f42b253f5812a_127943_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;谷歌AI搜索惨败，竟教唆网友自杀！&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;谷歌新推出的AI搜索引擎AIOverview因收集Reddit内容而产生了一系列荒谬回答，包括教唆自杀、提供错误健康建议和识别混淆信息等问题。尽管Google承认这些错误并正在采取措施改进，但这次事件再次让人质疑其AI系统的准确性和安全性。此外，这也揭示了使用Reddit内容训练AI可能带来的后果，显示出需要更严格的数据清洗和筛选。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J347HU690511ABV6.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;硅谷vc张璐硅谷大模型市场分为三类三大应用领域迭代速度较快&#34;&gt;硅谷VC张璐：硅谷大模型市场分为三类，三大应用领域迭代速度较快&lt;/h2&gt;
&lt;p&gt;硅谷AI产业已发展至鸡尾酒模式阶段，初创公司可调用大模型API，结合开源模型进行优化。张璐认为人工智能是超级工具，具有10倍于互联网时代的商业机会，但只有1/3留给初创企业。大型科技公司也能被赋能，而非破坏或变革。医疗、金融保险和机器人是迭代速度较快的领域。硅谷模型市场已相对明确，三类主要有OpenAI、苹果等提供服务型大模型，NVIDIA等自用大模型，以及开源平台。初创企业可采用鸡尾酒模式，与此同时，数据质量比数量更重要，行业专属小模型能与通用大模型竞争。边缘计算和数据隐私保护是未来的关键技术方向。（&lt;a class=&#34;link&#34; href=&#34;https://www.163.com/dy/article/J34ITT8B0511DSSR.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;报道详情&lt;/a&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人</title>
        <link>https://ntopic.cn/p/2024052101/</link>
        <pubDate>Tue, 21 May 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024052101/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024052101/02.jpg" alt="Featured image of post 基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人" /&gt;&lt;blockquote&gt;
&lt;p&gt;前面两篇博文，我们分别在个人笔记本电脑部署了&lt;strong&gt;Llama 3 8B&lt;/strong&gt;参数大模型，并使用&lt;strong&gt;Ollama&lt;/strong&gt;搭建了基于 Web 可视化对话聊天机器人，可以在自己电脑上愉快的与&lt;strong&gt;Llama&lt;/strong&gt;大模型 Web 机器人对话聊天了。但在使用过程中，笔者发现&lt;strong&gt;Llama&lt;/strong&gt;大模型经常出现&lt;strong&gt;中文问题英文回答&lt;/strong&gt;的问题，需要使用&lt;strong&gt;中文回答&lt;/strong&gt;等提示词告诉大模型用中文回答，体验还不是最好的。今天，本博文就来解决这个问题，让我们有个中文版的&lt;strong&gt;Llama 3&lt;/strong&gt;Web 对话机器人（&lt;strong&gt;Llama3-Chinese-Chat&lt;/strong&gt;）……&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第一篇&lt;strong&gt;Llama 3 8B&lt;/strong&gt;大模型部署和 Python 版对话机器人博文：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;第二篇基于&lt;strong&gt;Ollama&lt;/strong&gt;部署&lt;strong&gt;Llama 3 8B&lt;/strong&gt;大模型 Web 版本对话机器人博文：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 因为本博文介绍的是&lt;strong&gt;Llama 3 中文版&lt;/strong&gt;（&lt;strong&gt;Llama3-Chinese-Chat&lt;/strong&gt;）对话机器人，涉及到前面两篇博文内容，特别是第二篇 Web 版本对话机器人部署，因此建议按照前文博文部署好&lt;strong&gt;Llama 3 8B&lt;/strong&gt;大语言模型。&lt;/p&gt;
&lt;h2 id=&#34;hf-上选择排名最高的模型&#34;&gt;HF 上选择排名最高的模型&lt;/h2&gt;
&lt;p&gt;模型列表官网地址：&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/models&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://huggingface.co/models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;模型列表国内镜像（&lt;strong&gt;推荐&lt;/strong&gt;）：&lt;a class=&#34;link&#34; href=&#34;https://hf-mirror.com/models&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://hf-mirror.com/models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在模型列表页面按照关键字&lt;code&gt;llama chinese&lt;/code&gt;搜索，并按照&lt;strong&gt;趋势&lt;/strong&gt;排序，可以看到中文版模型：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024052101/01.jpg&#34;
	width=&#34;2530&#34;
	height=&#34;1384&#34;
	srcset=&#34;https://ntopic.cn/p/2024052101/01_huae61d300a0f7989ceb023d401e9fe593_1105009_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024052101/01_huae61d300a0f7989ceb023d401e9fe593_1105009_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;LLama中文版模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;182&#34;
		data-flex-basis=&#34;438px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看出，第一名模型的&lt;strong&gt;下载&lt;/strong&gt;数量和&lt;strong&gt;点赞&lt;/strong&gt;数量，比第二名要多好多，我们就选择&lt;strong&gt;shenzhi-wang&lt;/strong&gt;这位作者发布的模型。&lt;/p&gt;
&lt;h2 id=&#34;方式一通过-gguf-量化模型安装推荐&#34;&gt;方式一：通过 GGUF 量化模型安装（推荐）&lt;/h2&gt;
&lt;p&gt;GGUF 安装比较简单，下载单个文件即可：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024052101/02.jpg&#34;
	width=&#34;1040&#34;
	height=&#34;1086&#34;
	srcset=&#34;https://ntopic.cn/p/2024052101/02_hub3da83b4b5bc32de4db9cd09399c10b7_374346_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024052101/02_hub3da83b4b5bc32de4db9cd09399c10b7_374346_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;LLama中文版GGUF模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;95&#34;
		data-flex-basis=&#34;229px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;下载到本地之后，按照我的&lt;strong&gt;第一篇&lt;/strong&gt;博文，即可进行控制台聊天了：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启动大模型&lt;/strong&gt;Shell 脚本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; ./venv/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python -m llama_cpp.server --host 0.0.0.0 --model &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;   ./Llama3-8B-Chinese-Chat-q4_0-v2_1.gguf &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;   --n_ctx &lt;span class=&#34;m&#34;&gt;20480&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Python 对话客户端&lt;/strong&gt;代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;openai&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 注意服务端端口，因为是本地，所以不需要api_key&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ip&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#ip = &amp;#39;192.168.1.37&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base_url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http://&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;:8000/v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;n&#34;&gt;api_key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;not-needed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 对话历史：设定系统角色是一个只能助理，同时提交“自我介绍”问题&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;history&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;你是一个智能助理，你的回答总是容易理解的、正确的、有用的和内容非常精简.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 首次自我介绍完毕，接下来是等代码我们的提示&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;completions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;local-model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;stream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flush&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[91;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;userinput&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;gt; &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;userinput&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lower&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;bye&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;quit&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;exit&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]:&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 我们输入bye/quit/exit等均退出客户端&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[0mBYE BYE!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;userinput&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[92;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;运行 Python 客户端&lt;/strong&gt;即可：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024052101/03.jpg&#34;
	width=&#34;1632&#34;
	height=&#34;246&#34;
	srcset=&#34;https://ntopic.cn/p/2024052101/03_huc7b96f9887ab9df1f5da9de1f651a003_95258_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024052101/03_huc7b96f9887ab9df1f5da9de1f651a003_95258_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Python控制台对话客户端&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;663&#34;
		data-flex-basis=&#34;1592px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;按照第二篇博文，部署基于 Web 版对话机器人：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/2DVYO75h0o5EHN_K_GF4Eg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文彻底整明白，基于 Ollama 工具的 LLM 大语言模型 Web 可视化对话机器人部署指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;基于 GGUF 量化模型&lt;strong&gt;生成 Ollama&lt;/strong&gt;模型文件，假设文件名为&lt;code&gt;Modelfile-Chinese&lt;/code&gt;，内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM ./Llama3-8B-Chinese-Chat-q4_0-v2_1.gguf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;执行 Ollama 模型转换，&lt;code&gt;Llama-3-8B-Chinese&lt;/code&gt;为 Ollama 模型名：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ ollama create Llama-3-8B-Chinese -f ./Modelfile-Chinese
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;transferring model data
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;using existing layer sha256:242ac8dd3eabcb1e5fcd3d78912eaf904f08bb6ecfed8bac9ac9a0b7a837fcb8
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;creating new layer sha256:9f3bfa6cfc3061e49f8d5ab5fba0f93426be5f8207d8d8a9eebf638bd12b627a
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;writing manifest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;success
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;可以通过 Ollama 查看目前的大模型列表：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ ollama list
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME                      ID            SIZE    MODIFIED
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Llama-3-8B-Chinese:latest 37143cf1f51f  4.7 GB  &lt;span class=&#34;m&#34;&gt;42&lt;/span&gt; seconds ago
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Llama-3-8B:latest         74abc0712fc1  4.9 GB  &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt; days ago
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;可以看到我们刚安装的大模型：&lt;strong&gt;Llama-3-8B-Chinese&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;启动&lt;strong&gt;ollama-webui-lite&lt;/strong&gt;项目，可以选择&lt;strong&gt;Llama-3-8B-Chinese&lt;/strong&gt;模型和对话聊天了：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ npm run dev
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; ollama-webui-lite@0.0.1 dev
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; vite dev --host --port &lt;span class=&#34;m&#34;&gt;3000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  VITE v4.5.3  ready in &lt;span class=&#34;m&#34;&gt;1797&lt;/span&gt; ms
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  ➜  Local:   http://localhost:3000/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  ➜  Network: http://192.168.101.30:3000/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  ➜  press h to show &lt;span class=&#34;nb&#34;&gt;help&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024052101/04.jpg&#34;
	width=&#34;1550&#34;
	height=&#34;264&#34;
	srcset=&#34;https://ntopic.cn/p/2024052101/04_hu97c9217b73ef8283d49772062613e0f2_34116_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024052101/04_hu97c9217b73ef8283d49772062613e0f2_34116_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;OlLama选择中文版模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;587&#34;
		data-flex-basis=&#34;1409px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;方式二通过-ollama-拉取模型文件&#34;&gt;方式二：通过 Ollama 拉取模型文件&lt;/h2&gt;
&lt;p&gt;这种方式比较简单，无需下载 GGUF 模型文件，可以让 Ollama 直接拉取模型文件并完成安装：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Llama3-8B-Chinese-Chat的4位量化版本（对机器性能要求最低）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run wangshenzhi/llama3-8b-chinese-chat-ollama-q4
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Llama3-8B-Chinese-Chat的8位量化版本（对机器性能要求中等）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run wangshenzhi/llama3-8b-chinese-chat-ollama-q8
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Llama3-8B-Chinese-Chat的f16未量化版本（对机器性能要求最高）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run wangshenzhi/llama3-8b-chinese-chat-ollama-fp16
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Ollama 自动下载并完成安装，之后启动&lt;strong&gt;ollama-webui-lite&lt;/strong&gt;项目，就可以使用了~&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://ntopic.cn/p/2024052101/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ntopic.cn/p/2024052101&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>一文彻底整明白，基于Ollama工具的LLM大语言模型Web可视化对话机器人部署指南</title>
        <link>https://ntopic.cn/p/2024051801/</link>
        <pubDate>Sat, 18 May 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024051801/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024051801/02.jpg" alt="Featured image of post 一文彻底整明白，基于Ollama工具的LLM大语言模型Web可视化对话机器人部署指南" /&gt;&lt;blockquote&gt;
&lt;p&gt;在上一篇博文中，我们在本地部署了&lt;strong&gt;Llama 3 8B&lt;/strong&gt;参数大模型，并用 Python 写了一个控制台对话客户端，基本能愉快的与 Llama 大模型对话聊天了。但控制台总归太技术化，体验不是很友好，我们希望能有个类似 ChatGPT 那样的 Web 聊天对话界面，本博文就安排起来……&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上一篇&lt;strong&gt;Llama 3 8B&lt;/strong&gt;大模型部署和 Python 对话客户端博文：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/MekCUJDhKzuUnoykkGoH2g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;玩转 AI，笔记本电脑安装属于自己的 Llama 3 8B 大模型和对话客户端&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;因为本博文介绍的&lt;strong&gt;Web 可视化&lt;/strong&gt;对话机器人，涉及到前文的&lt;strong&gt;Llama 3 8B&lt;/strong&gt;大模型（并不是强依赖），因此建议提取安装前文部署好&lt;strong&gt;Llama 3 8B&lt;/strong&gt;大语言模型。&lt;/p&gt;
&lt;p&gt;为了方便把我们的大模型对话机器人分享出去，聊天机器人最后是基于&lt;strong&gt;Web&lt;/strong&gt;网站，可通过浏览器访问，本文正是通过&lt;code&gt;Ollama&lt;/code&gt;和&lt;code&gt;WebUI&lt;/code&gt;在本地部署&lt;code&gt;Llama 3&lt;/code&gt;Web 版聊天机器人，本文包括如下部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;什么是&lt;code&gt;Ollama&lt;/code&gt;，它与&lt;code&gt;Llama&lt;/code&gt;是什么关系？&lt;/li&gt;
&lt;li&gt;安装&lt;code&gt;Ollama&lt;/code&gt;大语言模型工具&lt;/li&gt;
&lt;li&gt;安装&lt;code&gt;Node.js&lt;/code&gt;编程语言工具包（为接下来的 Web 可视化聊天界面做好准备）&lt;/li&gt;
&lt;li&gt;基于&lt;code&gt;Llama 3 8B&lt;/code&gt;GGUF 模型文件创建&lt;code&gt;Ollama&lt;/code&gt;模型文件&lt;/li&gt;
&lt;li&gt;部署&lt;code&gt;Ollama&lt;/code&gt;大模型 Web 可视化聊天界面&lt;/li&gt;
&lt;li&gt;愉快的与&lt;code&gt;Llama 3&lt;/code&gt;大模型俩天对话&lt;/li&gt;
&lt;li&gt;最后，&lt;code&gt;Ollama&lt;/code&gt;大模型工具的其他用法&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;什么是ollama它与llama是什么关系&#34;&gt;什么是&lt;code&gt;Ollama&lt;/code&gt;，它与&lt;code&gt;Llama&lt;/code&gt;是什么关系？&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Ollama&lt;/code&gt;是一个开源的 LLM（大型语言模型）服务工具，用于简化在本地运行大语言模型，降低使用大语言模型的门槛，使得大模型的开发者、研究人员和爱好者能够在本地环境快速实验、管理和部署最新大语言模型，包括如&lt;code&gt;Llama 3&lt;/code&gt;、&lt;code&gt;Phi 3&lt;/code&gt;、&lt;code&gt;Mistral&lt;/code&gt;、&lt;code&gt;Gemma&lt;/code&gt;等开源的大型语言模型。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Ollama&lt;/code&gt;目前支持以下大语言模型：&lt;a class=&#34;link&#34; href=&#34;https://ollama.com/library&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ollama.com/library&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051801/01.jpg&#34;
	width=&#34;1278&#34;
	height=&#34;980&#34;
	srcset=&#34;https://ntopic.cn/p/2024051801/01_hua04b28422bbb4c6a12cc5f607adbb1af_199841_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051801/01_hua04b28422bbb4c6a12cc5f607adbb1af_199841_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;130&#34;
		data-flex-basis=&#34;312px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此，&lt;code&gt;Ollama&lt;/code&gt;与&lt;code&gt;Llama&lt;/code&gt;的关系：&lt;code&gt;Llama&lt;/code&gt;是大语言模型，而&lt;code&gt;Ollama&lt;/code&gt;是大语言模型（不限于&lt;code&gt;Llama&lt;/code&gt;模型）便捷的管理和运维工具&lt;/p&gt;
&lt;h2 id=&#34;安装ollama大语言模型工具&#34;&gt;安装&lt;code&gt;Ollama&lt;/code&gt;大语言模型工具&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Ollama&lt;/code&gt;提供了&lt;strong&gt;MacOS&lt;/strong&gt;、&lt;strong&gt;Linux&lt;/strong&gt;和&lt;strong&gt;Windows&lt;/strong&gt;操作系统的安装包，大家可根据自己的操作系统，下载安装即可：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051801/02.jpg&#34;
	width=&#34;1184&#34;
	height=&#34;868&#34;
	srcset=&#34;https://ntopic.cn/p/2024051801/02_hua04b28422bbb4c6a12cc5f607adbb1af_86436_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051801/02_hua04b28422bbb4c6a12cc5f607adbb1af_86436_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;327px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;安装包下载之后的安装过程，和日常安装其他软件没有差别，包括点击&lt;code&gt;Next&lt;/code&gt;以及&lt;code&gt;Install&lt;/code&gt;等安装&lt;code&gt;ollama&lt;/code&gt;到命令行。安装后续步骤中，我们可无需安装任何模型（默认是&lt;code&gt;Llama 3&lt;/code&gt;），因为我们在上文中已经安装了&lt;code&gt;Llama 3 8B&lt;/code&gt;大模型，后面可以直接使用。&lt;/p&gt;
&lt;p&gt;当然，假如没有根据我的前面博文安装&lt;code&gt;Llama 3 8B&lt;/code&gt;模型，在安装&lt;code&gt;Ollama&lt;/code&gt;过程中，也可以一起进行安装。&lt;/p&gt;
&lt;h2 id=&#34;安装nodejs编程语言工具包&#34;&gt;安装&lt;code&gt;Node.js&lt;/code&gt;编程语言工具包&lt;/h2&gt;
&lt;p&gt;安装&lt;code&gt;Node.js&lt;/code&gt;编程语言工具包和安装其他软件包一样，下载安装即可：&lt;a class=&#34;link&#34; href=&#34;https://nodejs.org&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://nodejs.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051801/03.jpg&#34;
	width=&#34;1282&#34;
	height=&#34;1250&#34;
	srcset=&#34;https://ntopic.cn/p/2024051801/03_hua04b28422bbb4c6a12cc5f607adbb1af_208693_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051801/03_hua04b28422bbb4c6a12cc5f607adbb1af_208693_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;102&#34;
		data-flex-basis=&#34;246px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;安装完成之后，可以验证一下 Node.js 的版本，建议用目前的最新&lt;strong&gt;v20&lt;/strong&gt;版本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;node -v
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我安装的版本：&lt;strong&gt;v20.13.1&lt;/strong&gt;（最新版本）&lt;/p&gt;
&lt;h2 id=&#34;基于llama-3-8bgguf-模型文件创建ollama模型&#34;&gt;基于&lt;code&gt;Llama 3 8B&lt;/code&gt;GGUF 模型文件创建&lt;code&gt;Ollama&lt;/code&gt;模型&lt;/h2&gt;
&lt;p&gt;在我们存放&lt;code&gt;Llama 3 8B&lt;/code&gt;的 GGUF 模型文件目录中，创建一个文件名为&lt;code&gt;Modelfile&lt;/code&gt;的文件，该文件的内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM ./Meta-Llama-3-8B-Instruct.Q4_K_M.gguf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后在控制台，使用这个文件创建&lt;code&gt;Ollama&lt;/code&gt;模型，这里我把&lt;code&gt;Ollama&lt;/code&gt;的模型取名为&lt;strong&gt;Llama-3-8B&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ ollama create Llama-3-8B -f ./Modelfile
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;transferring model data
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;using existing layer sha256:647a2b64cbcdbe670432d0502ebb2592b36dd364d51a9ef7a1387b7a4365781f
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;creating new layer sha256:459d7c837b2bd7f895a15b0a5213846912693beedaf0257fbba2a508bc1c88d9
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;writing manifest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;success
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;最后，通过&lt;code&gt;Ollama&lt;/code&gt;启动我们刚创建的大语言模型：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run Llama-3-8B
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051801/04.jpg&#34;
	width=&#34;1628&#34;
	height=&#34;738&#34;
	srcset=&#34;https://ntopic.cn/p/2024051801/04_hua04b28422bbb4c6a12cc5f607adbb1af_425764_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051801/04_hua04b28422bbb4c6a12cc5f607adbb1af_425764_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;220&#34;
		data-flex-basis=&#34;529px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;启动完毕，其实我们已经有了一个控制台聊天界面，可以通过控制台与&lt;code&gt;Llama-3-8B&lt;/code&gt;聊天了&lt;/p&gt;
&lt;p&gt;如果我们不想要这个模型了，也可以通过命令行删除模型文件：&lt;code&gt;ollama rm Llama-3-8B&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Ollama&lt;/code&gt;存放模型文件根目录：&lt;code&gt;~/.ollama&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;部署ollama大模型-web-可视化聊天界面&#34;&gt;部署&lt;code&gt;Ollama&lt;/code&gt;大模型 Web 可视化聊天界面&lt;/h2&gt;
&lt;p&gt;控制台聊天对话界面体验总归是不太好，接下来部署 Web 可视化聊天界面。&lt;/p&gt;
&lt;p&gt;首先，下载&lt;code&gt;ollama-webui&lt;/code&gt;Web 工程代码：&lt;code&gt;git clone https://github.com/ollama-webui/ollama-webui-lite&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然后切换&lt;code&gt;ollama-webui&lt;/code&gt;代码的目录：&lt;code&gt;cd ollama-webui-lite&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;设置 Node.js 工具包镜像源，以接下来下载 Node.js 的依赖包更加快速：&lt;code&gt;npm config set registry http://mirrors.cloud.tencent.com/npm/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;安装 Node.js 依赖的工具包：&lt;code&gt;npm install&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;最后，启动 Web 可视化界面：&lt;code&gt;npm run dev&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051801/05.jpg&#34;
	width=&#34;824&#34;
	height=&#34;270&#34;
	srcset=&#34;https://ntopic.cn/p/2024051801/05_hua04b28422bbb4c6a12cc5f607adbb1af_52060_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051801/05_hua04b28422bbb4c6a12cc5f607adbb1af_52060_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;305&#34;
		data-flex-basis=&#34;732px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如果看到以上输出，代表 Web 可视化界面已经成功了！&lt;/p&gt;
&lt;h2 id=&#34;愉快的与llama-3大模型俩天对话&#34;&gt;愉快的与&lt;code&gt;Llama 3&lt;/code&gt;大模型俩天对话&lt;/h2&gt;
&lt;p&gt;浏览器打开 Web 可视化界面：&lt;a class=&#34;link&#34; href=&#34;http://localhost:3000&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以看到&lt;code&gt;Ollama&lt;/code&gt;的初始化页面，默认没有模型，需要选择，我们选择刚创建并部署的&lt;code&gt;Llama-3-8B&lt;/code&gt;模型：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051801/06.jpg&#34;
	width=&#34;2116&#34;
	height=&#34;692&#34;
	srcset=&#34;https://ntopic.cn/p/2024051801/06_hua04b28422bbb4c6a12cc5f607adbb1af_73102_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051801/06_hua04b28422bbb4c6a12cc5f607adbb1af_73102_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;305&#34;
		data-flex-basis=&#34;733px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051801/07.jpg&#34;
	width=&#34;2118&#34;
	height=&#34;712&#34;
	srcset=&#34;https://ntopic.cn/p/2024051801/07_hua04b28422bbb4c6a12cc5f607adbb1af_86097_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051801/07_hua04b28422bbb4c6a12cc5f607adbb1af_86097_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;297&#34;
		data-flex-basis=&#34;713px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;底部就是聊天输入框，至此可以愉快的与&lt;code&gt;Llama 3&lt;/code&gt;聊天对话了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051801/08.jpg&#34;
	width=&#34;1534&#34;
	height=&#34;794&#34;
	srcset=&#34;https://ntopic.cn/p/2024051801/08_hua04b28422bbb4c6a12cc5f607adbb1af_154487_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051801/08_hua04b28422bbb4c6a12cc5f607adbb1af_154487_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;463px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Web 对话聊天机器人的设置，大家可以基于 Web 网站设置，这里不在介绍，有需要的网友可以私信一起研究进步！&lt;/p&gt;
&lt;h2 id=&#34;禅定ollama工具的其他用法&#34;&gt;禅定：&lt;code&gt;Ollama&lt;/code&gt;工具的其他用法&lt;/h2&gt;
&lt;p&gt;从上文的介绍可以看到，基于&lt;code&gt;Ollama&lt;/code&gt;部署一个大模型的 Web 可视化对话机器人，还是非常方便。下面整理了部分&lt;code&gt;Ollama&lt;/code&gt;提供的用法或者。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ollama 命令&lt;/strong&gt;工具&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 查看当前Ollama的模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama list
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 增量更新当前部署的模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama pull Llama-3-8B
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 删除一个模型文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama rm Llama-3-8B
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 复制一个模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama cp Llama-3-8B Llama-newModel
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Ollama API&lt;/strong&gt;结果返回&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl http://localhost:11434/api/generate -d &lt;span class=&#34;s1&#34;&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;model&amp;#34;: &amp;#34;Llama-3-8B&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;prompt&amp;#34;:&amp;#34;为什么天空是蓝色的？&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Ollama API&lt;/strong&gt;聊天对话&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl http://localhost:11434/api/chat -d &lt;span class=&#34;s1&#34;&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;model&amp;#34;: &amp;#34;Llama-3-8B&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    { &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;为什么天空是蓝色的？&amp;#34; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://ntopic.cn/p/2024051801/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ntopic.cn/p/2024051801&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>GPT-4o正式发布：视频语音推理交互丝滑到吓人，将向所有用户开放</title>
        <link>https://ntopic.cn/p/2024051501/</link>
        <pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024051501/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024051501/01.jpg" alt="Featured image of post GPT-4o正式发布：视频语音推理交互丝滑到吓人，将向所有用户开放" /&gt;&lt;p&gt;报道地址：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Xur3IUYf7PPOx1SCTuVPFg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/Xur3IUYf7PPOx1SCTuVPFg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布会视频：&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=DQacCB9tDaw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=DQacCB9tDaw&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GTP-4o 官网：&lt;a class=&#34;link&#34; href=&#34;https://openai.com/index/hello-gpt-4o/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://openai.com/index/hello-gpt-4o/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051501/01.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;2024 年 4 月 14 日，一场不到 30 分钟的发布会，将又一次大大改变 AI 行业和我们未来的生活，也会让无数 AI 初创公司焦头烂额。&lt;/p&gt;
&lt;p&gt;这真不是标题党，因为这是 OpenAI 的发布会。&lt;/p&gt;
&lt;p&gt;OpenAI 正式发布了 GPT-4o，其中的「o」代表「omni」（即全面、全能的意思），这个模型同时具备&lt;strong&gt;文本&lt;/strong&gt;、&lt;strong&gt;图片&lt;/strong&gt;、&lt;strong&gt;视频&lt;/strong&gt;和&lt;strong&gt;语音&lt;/strong&gt;方面的能力，甚至就是 GPT-5 的一个初期版本。&lt;/p&gt;
&lt;p&gt;更重要的是，这个 GPT-4 级别的模型，将向所有用户开放，并且未来几周内先向 ChatGPT Plus 推送。我们先给大家一次性总结这场发布会的亮点，更多功能解析请看发布会视频。&lt;/p&gt;
&lt;p&gt;发布会要点： 1.新的 GPT-4o 模型：打通任何文本、音频和图像的输入，相互之间可以直接生成，无需中间转换
2.GPT-4o 语音延迟大幅降低，能在 232 毫秒内回应音频输入，平均为 320 毫秒，这与对话中人类的响应时间相似
3.GPT-4o 向所有用户免费开放（指日可待）
4.GPT-4o API，比 GPT 4-Turbo 快 2 倍，价格便宜 50% 5.惊艳的实时语音助手演示：对话更像人、能实时翻译，识别表情，可以通过摄像头识别画面写代码分析图表
6.ChatGPT 新 UI，更简洁 7.一个新的 ChatGPT 桌面应用程序，适用于 macOS，Windows 版本今年晚些时候推出&lt;/p&gt;
&lt;p&gt;这些功能早在预热阶段就被 Altman 形容为「感觉像魔法」，既然全世界 AI 模型都在「赶超 GPT-4」，那 OpenAI 也要从武器库掏出点真家伙。&lt;/p&gt;
&lt;p&gt;当然，还轮不到 GPT-5 登场。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://ntopic.cn/p/2024051501/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ntopic.cn/p/2024051501&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>玩转AI，笔记本电脑安装属于自己的Llama 3 8B大模型和对话客户端</title>
        <link>https://ntopic.cn/p/2024051101/</link>
        <pubDate>Sat, 11 May 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024051101/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024051101/01.jpg" alt="Featured image of post 玩转AI，笔记本电脑安装属于自己的Llama 3 8B大模型和对话客户端" /&gt;&lt;blockquote&gt;
&lt;p&gt;2024 年 4 月 18 日，Meta&lt;strong&gt;开源&lt;/strong&gt;了 Llama 3 大模型，把 AI 的门槛降低到了最低，这是人工智能领域的一个重要飞跃。我们个人也可以部署大模型了，这简直就是给个人开发者发了个大红包！Llama 3 模型有不同的参数版本，本文主要分享我在个人笔记本电脑是部署 8B 参数过程和编写客户端，让我们大家都参与进来，推动 AI 应用更上一层楼……&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文&lt;strong&gt;Llama 3 8B&lt;/strong&gt;客户端源代码地址：&lt;a class=&#34;link&#34; href=&#34;https://gitee.com/obullxl/PythonCS/tree/master/Llama-3-8B&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gitee.com/obullxl/PythonCS/tree/master/Llama-3-8B&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;选择-llama-3-模型版本8b80-亿参数&#34;&gt;选择 Llama 3 模型版本（8B，80 亿参数）&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;特别注意：&lt;/strong&gt; Meta 虽然开源了 Llama 3 大模型，但是每个版本都有 Meta 的许可协议，建议大家在接受使用这些模型所需的条款之前仔细阅读。&lt;/p&gt;
&lt;p&gt;Llama 3 模型版本有几个，我们主要关注 80 亿参数（&lt;strong&gt;Llama 3 8B&lt;/strong&gt;）和 700 亿参数（Llama 3 70B）这两个版本。它们对电脑系统配置有不同的要求，主要计算资源（即：CPU/GPU）和内存来存储和处理模型权重：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Llama 3 8B 版本：对于 80 亿参数的模型，建议至少 4 核 CPU，至少 16GB 内存（推荐 32GB 或更高），以确保模型加载和运行过程中的流畅性；模型文件大小 5 GB 左右，磁盘空间有 10GB 足够了；GPU 是可选的，它可以显著提高推理速度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Llama 3 70B 版本：对于 700 亿参数的模型，CPU 要求显著提高（建议 16 核以上），至少需要 64GB 内存（推荐 128GB 或更高），模型在推理时会占用大量的内存资源；模型文件超过 20GB，远超 8B 版本；强烈推荐使用高端 GPU，以实现有效加速&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上所述，8B 版本比较适合我们个人电脑，硬件配置基本能符合，同时模型又不失推理效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051101/01.jpg&#34;
	width=&#34;1172&#34;
	height=&#34;664&#34;
	srcset=&#34;https://ntopic.cn/p/2024051101/01_hua04b28422bbb4c6a12cc5f607adbb1af_84235_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051101/01_hua04b28422bbb4c6a12cc5f607adbb1af_84235_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;笔记本电脑配置&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;423px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;下载-llama-3-8b-模型文件&#34;&gt;下载 Llama 3 8B 模型文件&lt;/h2&gt;
&lt;p&gt;我们第一步是想自己部署尝鲜，因此直接下载压缩后的模型权重，文件为&lt;strong&gt;GGUF&lt;/strong&gt;格式，&lt;strong&gt;GGUF&lt;/strong&gt;格式是为了快速推理和优化内存使用而设计的，相比以前的&lt;strong&gt;GGML&lt;/strong&gt;格式，&lt;strong&gt;GGUF&lt;/strong&gt;支持更复杂的令牌化过程和特殊令牌处理，能更好地应对多样化的语言模型需求。就是因为有&lt;strong&gt;GGUF&lt;/strong&gt;格式，&lt;strong&gt;Llama 3&lt;/strong&gt;大语言模型才可以在笔记本电脑上运行，同时&lt;strong&gt;GGUF&lt;/strong&gt;就一个文件，也简化了模型交换和部署的过程，它对促进模型的普及和应用有着积极作用。&lt;/p&gt;
&lt;p&gt;因为&lt;strong&gt;Hugging Face&lt;/strong&gt;官网正常无法访问，需要科学上网，因此推荐&lt;strong&gt;国内镜像&lt;/strong&gt;进行下载：&lt;/p&gt;
&lt;p&gt;官网地址：&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/tree/main&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/tree/main&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;国内镜像：&lt;a class=&#34;link&#34; href=&#34;https://hf-mirror.com/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/tree/main&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://hf-mirror.com/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/tree/main&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051101/02.jpg&#34;
	width=&#34;2494&#34;
	height=&#34;1364&#34;
	srcset=&#34;https://ntopic.cn/p/2024051101/02_hua04b28422bbb4c6a12cc5f607adbb1af_503934_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051101/02_hua04b28422bbb4c6a12cc5f607adbb1af_503934_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GGUF模型文件列表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;182&#34;
		data-flex-basis=&#34;438px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;GGUF 模型文件名称接受，如上述列表中，有&lt;code&gt;Meta-Llama-3-8B-Instruct.Q4_K_M.gguf&lt;/code&gt;和&lt;code&gt;Meta-Llama-3-8B-Instruct.Q5_K_M.gguf&lt;/code&gt;等：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Instruct&lt;/strong&gt;代表本模型是对基线模型进行了微调，用于更好地理解和生成遵循指令（instruction-following）的文本，以提供符合要求的响应&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Q4/Q5 等&lt;/strong&gt;代表模型权重的量化位数（其中&lt;strong&gt;Q&lt;/strong&gt;是&lt;strong&gt;Quantization&lt;/strong&gt;的缩小，即量化），是一种模型压缩技术，用于减少模型大小，同时降低对计算资源的需求（特别是内存），但又尽量保持模型的性能；数字&lt;strong&gt;4&lt;/strong&gt;或&lt;strong&gt;5&lt;/strong&gt;则代表量化精度的位数（Q4 是 4 位，Q5 是 5 位等），精度越高模型体积和内存使用也会越大，但仍然远小于未量化的基线模型&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;K_M/K_S&lt;/strong&gt;代表含义笔者还未明确，&lt;strong&gt;K&lt;/strong&gt;可能是&lt;strong&gt;Knowledge&lt;/strong&gt;的缩写；&lt;strong&gt;M&lt;/strong&gt;应该是&lt;strong&gt;Medium&lt;/strong&gt;缩写（即中等模型），&lt;strong&gt;S&lt;/strong&gt;应该是&lt;strong&gt;Small&lt;/strong&gt;缩小（即小模型）；若有明确的朋友，还望不吝告知，共同进步！&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;若个人电脑配置不是特别好，我们可以选择&lt;strong&gt;Q2_K&lt;/strong&gt;版本（大小 3.2GB），它相较于&lt;strong&gt;Q4_K_M&lt;/strong&gt;版本（大小 4.9GB），&lt;strong&gt;Q2&lt;/strong&gt;版本的推理精度较低，但速度较快，而&lt;strong&gt;Q4&lt;/strong&gt;版本在速度和精度之间均取得了很好的平衡，因此首选推荐&lt;strong&gt;Q4_K_M&lt;/strong&gt;版本。&lt;/p&gt;
&lt;p&gt;点击&lt;strong&gt;下载&lt;/strong&gt;图标即可下载，由于文件较大，浏览器的下载容易过程容易终端，重试可继续下载（笔者浏览器中断了好几次，总共耗时 4 个多小时）&lt;/p&gt;
&lt;h2 id=&#34;启动大模型服务端&#34;&gt;启动大模型服务端&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;GGUF&lt;/strong&gt;模型量化文件下载完成后，我们就可以来运行&lt;strong&gt;Llama 3&lt;/strong&gt;大模型了。首先打开一个 Terminal 终端窗口，切换到&lt;strong&gt;GGUF&lt;/strong&gt;文件目录，设置 Python&lt;strong&gt;虚拟环境&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 切换到存放GGUF文件目录&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/PythonSpace/Llama3-8B/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 切换Python 3.12.2版本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate PY3.12.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建并激活虚拟环境&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python -m venv venv
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; ./venv/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 安装依赖包&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install llama-cpp-python
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install openai
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install uvicorn
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install starlette
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install fastapi
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install sse_starlette
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install starlette_context
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install pydantic_settings
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动Llama大模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python -m llama_cpp.server --host 0.0.0.0 --model &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;   ./Meta-Llama-3-8B-Instruct.Q4_K_M.gguf &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;   --n_ctx &lt;span class=&#34;m&#34;&gt;2048&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;最后启动 Llama 模型命令中，&lt;code&gt;n_ctx 2048&lt;/code&gt;代表单次回话最大 Token 数量。启动成功，我们应该看到类似如下的信息：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051101/03.jpg&#34;
	width=&#34;1640&#34;
	height=&#34;1144&#34;
	srcset=&#34;https://ntopic.cn/p/2024051101/03_hua04b28422bbb4c6a12cc5f607adbb1af_582602_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051101/03_hua04b28422bbb4c6a12cc5f607adbb1af_582602_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Llama启动成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;恭喜你，你已经迈入 Llama 大模型大厦的大门了，后面存在无限可能，就看我们的创意了！&lt;/p&gt;
&lt;h2 id=&#34;编写-llama-模型对话客户端&#34;&gt;编写 Llama 模型对话客户端&lt;/h2&gt;
&lt;p&gt;接下来，我们将使用&lt;strong&gt;llama-cpp&lt;/strong&gt;库和&lt;strong&gt;openai&lt;/strong&gt;库在个人电脑上快速搭建&lt;strong&gt;Llama 模型&lt;/strong&gt;的&lt;strong&gt;客户端&lt;/strong&gt;，开始尝鲜大模型（它&lt;strong&gt;目前&lt;/strong&gt;只是个控制台客户端，还不能如 ChatGPT 那样有可视化的界面，但它的功能一样完备，所以请各位不用着急，我们先来体验一下 Llama 大模型，可视化的界面下文我在和大家分享）。&lt;/p&gt;
&lt;p&gt;Python 客户端代码如下，为了后续方便演示，这个 &lt;strong&gt;Client.py&lt;/strong&gt; 文件也放到&lt;strong&gt;GGUF&lt;/strong&gt;模型文件一起：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们使用&lt;strong&gt;OpenAI&lt;/strong&gt;接口来与 Llama 交互，上面启动模型的最后，我们看到服务端 IP 是本地，端口是&lt;strong&gt;8000&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;接着，我们使用 2 条信息对历史记录进行初始化：第一个条是&lt;strong&gt;系统信息&lt;/strong&gt;，第二个条是要求模型自我介绍的&lt;strong&gt;用户提示&lt;/strong&gt;，为了避免长篇大论，我这里限制了回答的长度和字数&lt;/li&gt;
&lt;li&gt;接下来，通过&lt;code&gt;&amp;gt;&lt;/code&gt;提示符等待用户（即我们）输入，输入&lt;code&gt;bye&lt;/code&gt;、&lt;code&gt;quit&lt;/code&gt;和&lt;code&gt;exit&lt;/code&gt;任意一个即代表退出客户端&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;openai&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 注意服务端端口，因为是本地，所以不需要api_key&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base_url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:8000/v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;n&#34;&gt;api_key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;not-needed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 对话历史：设定系统角色是一个只能助理，同时提交“自我介绍”问题&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;history&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;你是一个智能助理，你的回答总是正确的、有用的和内容非常精简.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;请用中文进行自我介绍，要求不能超过5句话，总字数不超过100个字。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[92;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 首次自我介绍完毕，接下来是等代码我们的提示&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;completions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;local-model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;stream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;assistant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flush&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chunk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;delta&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;new_message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[91;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;userinput&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;gt; &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;userinput&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lower&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;bye&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;quit&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;exit&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]:&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 我们输入bye/quit/exit等均退出客户端&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[0mBYE BYE!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;history&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;userinput&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\033&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;[92;1m&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们新打开一个 Terminal 终端窗口，同样切换目标到 GGUF 文件目录，并且激活 Python 虚拟环境：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 切换到存放GGUF文件目录&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/PythonSpace/Llama3-8B/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 切换Python 3.12.2版本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate PY3.12.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 激活虚拟环境（之前已经创建）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; ./venv/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动客户端&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python client.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;首次打开客户端，因为有第一个默认的&lt;strong&gt;自我介绍&lt;/strong&gt;问题，稍微有点忙，但是可以看到，&lt;strong&gt;Llama 模型&lt;/strong&gt;按照我们的要求完成了自我介绍，总体还不赖：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051101/04.jpg&#34;
	width=&#34;1640&#34;
	height=&#34;1144&#34;
	srcset=&#34;https://ntopic.cn/p/2024051101/04_hua04b28422bbb4c6a12cc5f607adbb1af_295528_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051101/04_hua04b28422bbb4c6a12cc5f607adbb1af_295528_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Llama模型自我介绍&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;接着，我给&lt;strong&gt;Llama 模型&lt;/strong&gt;来了一个类&lt;strong&gt;哲学&lt;/strong&gt;的问题：&lt;code&gt;请你用中文问答：人为什么要不断追求卓越？&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Llama 模型&lt;/strong&gt;的回答非常精简，且只有 5 句话，所谓言简意赅：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024051101/05.jpg&#34;
	width=&#34;1640&#34;
	height=&#34;1144&#34;
	srcset=&#34;https://ntopic.cn/p/2024051101/05_hua04b28422bbb4c6a12cc5f607adbb1af_366743_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024051101/05_hua04b28422bbb4c6a12cc5f607adbb1af_366743_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Llama回答：人为什么要不断追求卓越？&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;上图中，红色为我的输入，绿色为模型的答复，超级赞！&lt;/p&gt;
&lt;h2 id=&#34;禅定总结&#34;&gt;禅定：总结&lt;/h2&gt;
&lt;p&gt;现在我们的&lt;strong&gt;Llama 模型&lt;/strong&gt;聊天机器人已准备就绪，我们想问什么就可以问什么，尽情享受吧。&lt;/p&gt;
&lt;p&gt;当然，我们废了大半天劲，如果只是和模型简单的聊聊天，那就有点可惜了，或者说如果要人工输入，那我们本地部署的意义就不大。&lt;/p&gt;
&lt;p&gt;假设能够通过程序的方式，自动调用本地部署的&lt;strong&gt;Llama 模型&lt;/strong&gt;是不是可以提供我们工作效率；&lt;strong&gt;Llama 模型&lt;/strong&gt;的能力非常广泛，可用于多种场景和任务：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;自然语言生成&lt;/strong&gt;：Llama 3 能够生成连贯、高质量的文本，包括文章、故事、诗歌等创意写作，以及邮件、报告等实用文体。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对话系统&lt;/strong&gt;：模型可以用于构建聊天机器人或 AI 助手，进行自然、流畅的对话交流，提供信息查询、娱乐互动等功能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代码生成&lt;/strong&gt;：它在代码生成任务上表现优异，能够根据描述自动生成或补全代码片段，辅助程序员提高开发效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;翻译&lt;/strong&gt;：Llama 3 支持跨语言应用，可以实现文本的自动翻译，覆盖多种语言对。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文本摘要&lt;/strong&gt;：能够自动生成文章、报告的摘要，提取关键信息，帮助用户快速浏览大量内容。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;情感分析和文本分类&lt;/strong&gt;：可以识别文本中的情绪倾向、主题分类，为企业提供市场洞察、客户服务优化等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;问答系统&lt;/strong&gt;：高效准确地回答用户提出的问题，无论是常识性问题还是专业领域的复杂询问。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;个性化推荐&lt;/strong&gt;：基于用户的历史交互和偏好，生成个性化的推荐内容，如新闻、商品、音乐等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文本生成图像描述&lt;/strong&gt;：结合多模态技术，Llama 3 可以根据文本描述生成图像内容的描述，助力图像生成或图像检索。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;法律文档处理&lt;/strong&gt;：微调后的模型可以用于法律文档的理解、分析，比如合同审查、案例研究等。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;关注本公众号，下次继续我们分享&lt;strong&gt;Llama 模型&lt;/strong&gt;可视化对话的功能！&lt;/p&gt;
&lt;p&gt;问题，&lt;code&gt;Llama 3 8B&lt;/code&gt;容易出现问中文，回答英文的问题，可下载中文微调版GGUF模型文件（&lt;strong&gt;Llama3-Chinese-Chat&lt;/strong&gt;）：&lt;a class=&#34;link&#34; href=&#34;https://hf-mirror.com/collections/shenzhi-wang/llama3-chinese-chat-663a2b15ab68e84aa355ca4d&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://hf-mirror.com/collections/shenzhi-wang/llama3-chinese-chat-663a2b15ab68e84aa355ca4d&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://ntopic.cn/p/2024051101/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ntopic.cn/p/2024051101&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
