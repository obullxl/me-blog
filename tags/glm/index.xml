<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>GLM on 奔跑的蜗牛</title>
        <link>https://ntopic.cn/tags/glm/</link>
        <description>Recent content in GLM on 奔跑的蜗牛</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 08 Jun 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://ntopic.cn/tags/glm/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验</title>
        <link>https://ntopic.cn/p/2024060801/</link>
        <pubDate>Sat, 08 Jun 2024 00:00:00 +0000</pubDate>
        
        <guid>https://ntopic.cn/p/2024060801/</guid>
        <description>&lt;img src="https://ntopic.cn/p/2024060801/00.jpg" alt="Featured image of post 本地部署GLM-4-9B清华智谱开源大模型方法和对话效果体验" /&gt;&lt;p&gt;&lt;strong&gt;GLM-4-9B&lt;/strong&gt;是清华大学和智谱AI推出的最新一代预训练模型&lt;strong&gt;GLM-4&lt;/strong&gt;系列中的开源版本。在语义、数学、推理、代码和知识等多方面的数据集测评中，&lt;strong&gt;GLM-4-9B&lt;/strong&gt;及其人类偏好对齐的版本&lt;strong&gt;GLM-4-9B-Chat&lt;/strong&gt;均表现出较高的性能，其通用能力评测结果甚至超越了&lt;strong&gt;Llama-3-8B&lt;/strong&gt;开源大模型，多模态版本也与&lt;strong&gt;GPT-4&lt;/strong&gt;版本齐平。&lt;/p&gt;
&lt;p&gt;除了能进行多轮对话，&lt;strong&gt;GLM-4-9B-Chat&lt;/strong&gt;还具备网页浏览、代码执行、自定义工具调用和长文本推理等高级功能。 &lt;strong&gt;GLM-4&lt;/strong&gt;模型增加了多语言支持，支持包括日语，韩语，德语在内的 26 种语言。&lt;strong&gt;GLM-4-9B&lt;/strong&gt;还推出了支持 1M 上下文长度（约 200 万中文字符）的模型。&lt;/p&gt;
&lt;p&gt;根据&lt;strong&gt;GLM-4&lt;/strong&gt;大模型评测结果，在通用能力方面超越&lt;strong&gt;Llama3&lt;/strong&gt;大模型，在多模态能力比肩&lt;strong&gt;GPT-4&lt;/strong&gt;大模型系列版本，评测结果和调用方法详情：&lt;a class=&#34;link&#34; href=&#34;https://github.com/THUDM/GLM-4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/THUDM/GLM-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文介绍&lt;strong&gt;GLM-4&lt;/strong&gt;大模型部署和使用方法，需要注意的是，&lt;strong&gt;GLM-4&lt;/strong&gt;虽然开源了，但&lt;strong&gt;GLM-4&lt;/strong&gt;大模型的权重的使用则需要遵循协议：&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;第一步下载模型文件&#34;&gt;第一步：下载模型文件&lt;/h2&gt;
&lt;p&gt;老牛同学在前面文章中，介绍了通过单一的GGUF文件在本地部署&lt;strong&gt;Llama-3-8B&lt;/strong&gt;（&lt;strong&gt;Llama3-Chinese-Chat&lt;/strong&gt;）大模型：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/idcdIr8mMWDQ_iZU5r_UEQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于Llama 3搭建中文版（Llama3-Chinese-Chat）大模型对话聊天机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GLM-4-9B&lt;/strong&gt;模板目前还没有GGUF文件，因此老牛同学通过Git下载PyTorch张量参数文件在本地部署&lt;strong&gt;GLM-4-9B-Chat-1M&lt;/strong&gt;大模型。&lt;/p&gt;
&lt;p&gt;由于模型参数文件比较大，使用Git无法直接下载到本地，需要通过&lt;strong&gt;git-lfs&lt;/strong&gt;工具包下载：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;brew install git-lfs
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;通过Git复制模型文件到笔记本电脑：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs install
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://www.modelscope.cn/ZhipuAI/glm-4-9b-chat-1m.git GLM-4-9B-Chat-1M
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;总共有10个模型参数文件，平均每个文件&lt;strong&gt;1.8GB&lt;/strong&gt;大小，总计18GB左右，因此在Git下载过程中，容易中断失败，可以通过以下命令多次尝试下载：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git lfs pull
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024060801/01.jpg&#34;
	width=&#34;1104&#34;
	height=&#34;808&#34;
	srcset=&#34;https://ntopic.cn/p/2024060801/01_hua45523be335adf4b2d3dbddd2027fd8f_162239_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024060801/01_hua45523be335adf4b2d3dbddd2027fd8f_162239_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GLM4模型参数文件列表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;327px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;第二步下线glm4代码库&#34;&gt;第二步：下线GLM4代码库&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;GLM-4&lt;/strong&gt;的官方GitHub代码库中有很多使用样例和微调等Python代码，我们可直接进行调整和使用：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;https://github.com/THUDM/GLM-4.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;第三步启动glm4客户端&#34;&gt;第三步：启动GLM4客户端&lt;/h2&gt;
&lt;p&gt;打开&lt;strong&gt;GLM-4&lt;/strong&gt;代码库中&lt;code&gt;basic_demo/trans_cli_demo.py&lt;/code&gt;文件，修改&lt;strong&gt;第18行&lt;/strong&gt;模型路径&lt;code&gt;MODEL_PATH&lt;/code&gt;参数，内容为我们通过Git复制到本地的路径，如老牛同学的路径如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#MODEL_PATH = os.environ.get(&amp;#39;MODEL_PATH&amp;#39;, &amp;#39;THUDM/glm-4-9b-chat&amp;#39;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;MODEL_PATH&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;environ&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;MODEL_PATH&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/shizihu/JupyterLab/GLM-4-9B-Chat-1M&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在启动之前，我们还需要安装几个Python工具包（当然也可以跳过，后面启动失败时在进行安装也是可以的）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install tiktoken
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install accelerate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动大模型客户端：&lt;code&gt;python trans_cli_demo.py&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;% python trans_cli_demo.py
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Loading checkpoint shards: 100%&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;██████████████████████████████████████████████&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 10/10 &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;00:09&amp;lt;00:00,  1.04it/s&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Welcome to the GLM-4-9B CLI chat. Type your messages below.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You: 介绍一下你自己。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;GLM-4:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;我是一个人工智能助手，我的名字是 ChatGLM，是基于清华大学 KEG 实验室和智谱 AI 公司
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/p/2024060801/02.jpg&#34;
	width=&#34;1778&#34;
	height=&#34;386&#34;
	srcset=&#34;https://ntopic.cn/p/2024060801/02_hu0d9468faef38b4d2a073f40ebdbf8687_278218_480x0_resize_q75_box.jpg 480w, https://ntopic.cn/p/2024060801/02_hu0d9468faef38b4d2a073f40ebdbf8687_278218_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GLM4模型对话&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;460&#34;
		data-flex-basis=&#34;1105px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结glm-4-9b比llama-3-8b慢太多了&#34;&gt;总结：GLM-4-9B比Llama-3-8B慢太多了&lt;/h2&gt;
&lt;p&gt;根据官方的评测报告，&lt;strong&gt;GLM-4-9B&lt;/strong&gt;在对话、多模态等方面要比&lt;strong&gt;Llama-3-8B&lt;/strong&gt;强不少，根据老牛同学本地部署&lt;strong&gt;对话&lt;/strong&gt;的验证结果来看，对话的输出速度实在太慢了，简直就是在挤牙膏，一个字一个字的往外输出。&lt;/p&gt;
&lt;p&gt;至于&lt;strong&gt;GLM-4-9B&lt;/strong&gt;的多模态、工具调用、代码解释等能力，老牛同学本次就不一一演示了，&lt;strong&gt;GLM-4&lt;/strong&gt;官方的GitHub代码库有很多Demo代码，大家可以对代码调整后尝试体验一下~&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关注本公众号，我们共同学习进步👇🏻👇🏻👇🏻&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ntopic.cn/WX-21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;微信公众号：老牛同学&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的本博客原地址：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/g7lDfnRRGdrHqN7WGMSkAg&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        
    </channel>
</rss>
